Component,Reference ID,Countermeasure,Description,Source,State,Test result,Priority,Expiry date,Cost,Owner,Issue ID,MITRE reference,Scope,Standard baseline,Standard baseline section
Kubernetes Cluster,C-KUBERNETES-CLUSTER-CNT-21,Apply security context to your pods and containers,"CIS Benchmark Recommendation id: 5.7.3

Profile Applicability: Level 2 - Master Node

Description: Apply Security Context to Your Pods and Containers

Rationale: A security context defines the operating system security 
settings (uid, gid, capabilities, SELinux role, etc..) applied to a 
container. When designing your containers and pods, make sure that you 
configure the security context for your pods, containers, and volumes. A 
security context is a property defined in the deployment yaml. It controls 
the security parameters that will be assigned to the pod/container/volume. 
There are two levels of security context: pod level security context, and 
container level security context.

Impact: If you incorrectly apply security contexts, you may have trouble 
running the pods.

Audit: Review the pod definitions in your cluster and verify that you have 
security contexts defined as appropriate.

Remediation: Follow the Kubernetes documentation and apply security 
contexts to your pods. For a suggested list of security contexts, you may 
refer to the CIS Security Benchmark for Docker Containers.

Default Value: By default, no security contexts are automatically applied 
to pods.

References:

   1. <https://kubernetes.io/docs/concepts/policy/security-context/>
   2. <https://learn.cisecurity.org/benchmarks>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1050 - Exploit Protection,Application Security,NIST 800-53 v5,AC-4 Information Flow Enforcement
Kubernetes Cluster,C-KUBERNETES-CLUSTER-CNT-08,Avoid use of system:masters group,"CIS Benchmark Recommendation id: 5.1.7
Profile Applicability: Level 1 - Master Node

Description: The special group system:masters should not be used to grant 
permissions to any user or service account, except where strictly necessary 
(e.g. bootstrapping access prior to RBAC being fully available)
Rationale: The system:masters group has unrestricted access to the 
Kubernetes API hard-coded into the API server source code. An authenticated 
user who is a member of this group cannot have their access reduced, even 
if all bindings and cluster role bindings which mention it, are removed. 
When combined with client certificate authentication, use of this group can 
allow for irrevocable cluster-admin level credentials to exist for a 
cluster.
Impact: Once the RBAC system is operational in a cluster, system:masters 
should not be specifically required, as ordinary bindings from principals 
to the cluster-admin cluster role can be made where unrestricted access is 
required.
Audit: Review a list of all credentials which have access to the cluster 
and ensure that the group system:masters is not used.
Remediation: Remove the system:masters group from all users in the cluster.
Default Value: By default some clusters will create a ""break glass"" client 
certificate which is a member of this group. Access to this client 
certificate should be carefully controlled and it should not be used for 
general cluster operations.
References:

   1. 
      <https://github.com/kubernetes/kubernetes/blob/master/pkg/registry/rbac/escalation_check.go#L38>",Created by Rules Engine,Recommended,Not tested,High,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1036 - Account Use Policies,Application Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Backend,C-WEB-APPLICATION-SERVER-SIDE-CNT-11,Block or validate all outbound requests,"To reduce the risk of data exfiltration or unauthorized system 
communication, block or carefully validate all outbound requests made by 
the application. Ensure that only requests to specific, trusted domains and 
IP addresses are allowed, and that any outbound request to unapproved 
destinations is blocked or flagged for further review. This control 
prevents the application from communicating with malicious external systems 
and protects sensitive data from being leaked.

Implementation Steps:

   1. Implement Outbound Request Filtering: Use a web application firewall
      (WAF) or proxy to block or monitor any outbound requests that are not
      to trusted domains or IP addresses.
   2. Validate Outbound Requests: Before allowing outbound communication,
      validate the destination domain and IP address to ensure they are
      within an approved list of resources necessary for the application.
   3. Set Domain and IP Allowlists: Define an allowlist of specific domains
      and IP addresses that the application is authorized to interact with,
      and block all other outbound traffic.
   4. Monitor and Log Outbound Requests: Continuously monitor and log all
      outbound requests for suspicious activity or attempts to communicate
      with unapproved destinations.
   5. Review and Update Allowlist Regularly: Periodically review the
      allowlist to ensure that it remains up-to-date with the application's
      legitimate requirements.

References:

    * Security and Privacy Controls for Information Systems and
      Organizations <https://csrc.nist.gov/pubs/sp/800/53/r5/upd1/final>",Created by Rules Engine,Recommended,Not tested,Low,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1031 - Network Intrusion Prevention,Network Security,NIST 800-53 v5,SC-7 Boundary Protection
Fronend,C-WEB-APPLICATION-SERVER-SIDE-CNT-11,Block or validate all outbound requests,"To reduce the risk of data exfiltration or unauthorized system 
communication, block or carefully validate all outbound requests made by 
the application. Ensure that only requests to specific, trusted domains and 
IP addresses are allowed, and that any outbound request to unapproved 
destinations is blocked or flagged for further review. This control 
prevents the application from communicating with malicious external systems 
and protects sensitive data from being leaked.

Implementation Steps:

   1. Implement Outbound Request Filtering: Use a web application firewall
      (WAF) or proxy to block or monitor any outbound requests that are not
      to trusted domains or IP addresses.
   2. Validate Outbound Requests: Before allowing outbound communication,
      validate the destination domain and IP address to ensure they are
      within an approved list of resources necessary for the application.
   3. Set Domain and IP Allowlists: Define an allowlist of specific domains
      and IP addresses that the application is authorized to interact with,
      and block all other outbound traffic.
   4. Monitor and Log Outbound Requests: Continuously monitor and log all
      outbound requests for suspicious activity or attempts to communicate
      with unapproved destinations.
   5. Review and Update Allowlist Regularly: Periodically review the
      allowlist to ensure that it remains up-to-date with the application's
      legitimate requirements.

References:

    * Security and Privacy Controls for Information Systems and
      Organizations <https://csrc.nist.gov/pubs/sp/800/53/r5/upd1/final>",Created by Rules Engine,Recommended,Not tested,Low,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1031 - Network Intrusion Prevention,Network Security,NIST 800-53 v5,SC-7 Boundary Protection
Kubernetes Cluster,C-KUBERNETES-CLUSTER-CNT-03,Bootstrap token authentication should not be used for users,"CIS Benchmark Recommendation id: 3.1.3

Profile Applicability: Level 1 - Master Node

Description: Kubernetes provides bootstrap tokens which are intended for 
use by new nodes joining the cluster. These tokens are not designed for use 
by end-users; they are specifically designed for the purpose of 
bootstrapping new nodes and not for general authentication.

Rationale: Bootstrap tokens are not intended for use as a general 
authentication mechanism and impose constraints on user and group naming 
that do not facilitate good RBAC design. They also cannot be used with MFA 
resulting in a weak authentication mechanism being available.

Impact: External mechanisms for authentication generally require additional 
software to be deployed.

Audit: Review user access to the cluster and ensure that users are not 
making use of bootstrap token authentication.

Remediation: Alternative mechanisms provided by Kubernetes such as the use 
of OIDC should be implemented in place of bootstrap tokens.

Default Value: Bootstrap token authentication is not enabled by default and 
requires an API server parameter to be set.

References: N/A",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1021 - Restrict Web-Based Content,Application Security,NIST 800-53 v5,AC-21 Information Sharing
Backend,C-WEB-APPLICATION-SERVER-SIDE-CNT-09,Capture and monitor detailed logs for critical actions,"To ensure comprehensive visibility into system activities, capture detailed 
logs for all critical actions within the web application. These logs should 
include data such as user actions, system changes, and access to sensitive 
resources. Additionally, proactively monitor these logs to detect 
suspicious behavior, unauthorized access, or anomalous activity, enabling 
timely detection of security incidents and faster response to potential 
threats.

Implementation Steps:

   1. Enable Logging for Critical Actions: Ensure that all key actions
      (e.g., login attempts, data access, configuration changes) are logged
      in detail, including relevant metadata such as timestamps, user
      identifiers, and source IP addresses.
   2. Use Centralized Logging: Store logs in a centralized location for
      easier access and analysis. Integrate with a log management or SIEM
      system for real-time monitoring.
   3. Set Up Automated Alerts: Configure automated alerts for suspicious or
      unauthorized actions, such as failed login attempts, unexpected
      configuration changes, or access to sensitive data by unauthorized
      users.
   4. Regularly Review Logs: Conduct regular log reviews and audits to
      ensure that logging mechanisms are functioning correctly and that
      logs provide the necessary level of detail to identify security
      incidents.

References:

    * OWASP Logging Best Practices
      <https://cheatsheetseries.owasp.org/cheatsheets/Logging_Cheat_Sheet.html>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1047 - Audit,Operational Security,NIST 800-53 v5,AU-12 Audit Record Generation
Fronend,C-WEB-APPLICATION-SERVER-SIDE-CNT-09,Capture and monitor detailed logs for critical actions,"To ensure comprehensive visibility into system activities, capture detailed 
logs for all critical actions within the web application. These logs should 
include data such as user actions, system changes, and access to sensitive 
resources. Additionally, proactively monitor these logs to detect 
suspicious behavior, unauthorized access, or anomalous activity, enabling 
timely detection of security incidents and faster response to potential 
threats.

Implementation Steps:

   1. Enable Logging for Critical Actions: Ensure that all key actions
      (e.g., login attempts, data access, configuration changes) are logged
      in detail, including relevant metadata such as timestamps, user
      identifiers, and source IP addresses.
   2. Use Centralized Logging: Store logs in a centralized location for
      easier access and analysis. Integrate with a log management or SIEM
      system for real-time monitoring.
   3. Set Up Automated Alerts: Configure automated alerts for suspicious or
      unauthorized actions, such as failed login attempts, unexpected
      configuration changes, or access to sensitive data by unauthorized
      users.
   4. Regularly Review Logs: Conduct regular log reviews and audits to
      ensure that logging mechanisms are functioning correctly and that
      logs provide the necessary level of detail to identify security
      incidents.

References:

    * OWASP Logging Best Practices
      <https://cheatsheetseries.owasp.org/cheatsheets/Logging_Cheat_Sheet.html>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1047 - Audit,Operational Security,NIST 800-53 v5,AU-12 Audit Record Generation
Backend,C-WEB-APPLICATION-SERVER-SIDE-CNT-03,Check user roles and permissions on every request,"To ensure secure access control, check the user's roles and permissions on 
every request for protected resources or functions. This prevents 
unauthorized access by verifying that the user has the correct privileges 
to perform the requested action, helping to enforce the principle of least 
privilege across the application. This should be done dynamically on each 
request to minimize the risk of privilege escalation or unauthorized 
resource access.

Implementation Steps:

   1. Role-Based Access Control (RBAC): Implement RBAC to define user roles
      and assign permissions based on the user’s role. Ensure that only
      authorized roles can access specific resources or functions.
   2. Permission Validation: For every incoming request, validate that the
      user’s assigned roles have the necessary permissions to access or
      modify the requested resource or function.
   3. Enforce Fine-Grained Access Control: Implement fine-grained
      permission checks for sensitive actions and resources, ensuring that
      access is granted based on the exact permissions needed.
   4. Session Management: Use session or token-based management to persist
      user identity and permissions, and ensure that permissions are
      checked against current session data on each request.
   5. Audit Logs: Record and review access attempts, especially for
      sensitive resources, to detect potential unauthorized access or
      misuse of roles and permissions.

References:

    * OWASP Access Control Cheat Sheet
      <https://cheatsheetseries.owasp.org/cheatsheets/Authorization_Cheat_Sheet.html>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1015 - Active Directory Configuration,Application Security,NIST 800-53 v5,PM-10 Authorization Process
Fronend,C-WEB-APPLICATION-SERVER-SIDE-CNT-03,Check user roles and permissions on every request,"To ensure secure access control, check the user's roles and permissions on 
every request for protected resources or functions. This prevents 
unauthorized access by verifying that the user has the correct privileges 
to perform the requested action, helping to enforce the principle of least 
privilege across the application. This should be done dynamically on each 
request to minimize the risk of privilege escalation or unauthorized 
resource access.

Implementation Steps:

   1. Role-Based Access Control (RBAC): Implement RBAC to define user roles
      and assign permissions based on the user’s role. Ensure that only
      authorized roles can access specific resources or functions.
   2. Permission Validation: For every incoming request, validate that the
      user’s assigned roles have the necessary permissions to access or
      modify the requested resource or function.
   3. Enforce Fine-Grained Access Control: Implement fine-grained
      permission checks for sensitive actions and resources, ensuring that
      access is granted based on the exact permissions needed.
   4. Session Management: Use session or token-based management to persist
      user identity and permissions, and ensure that permissions are
      checked against current session data on each request.
   5. Audit Logs: Record and review access attempts, especially for
      sensitive resources, to detect potential unauthorized access or
      misuse of roles and permissions.

References:

    * OWASP Access Control Cheat Sheet
      <https://cheatsheetseries.owasp.org/cheatsheets/Authorization_Cheat_Sheet.html>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1015 - Active Directory Configuration,Application Security,NIST 800-53 v5,PM-10 Authorization Process
Kubernetes Cluster,C-KUBERNETES-CLUSTER-CNT-01,Client certificate authentication should not be used for users,"CIS Benchmark Recommendation id: 3.1.1
Profile Applicability: Level 1 - Master Node
Description: Kubernetes provides the option to use client certificates for 
user authentication. However, as there is no way to revoke these 
certificates when a user leaves an organization or loses their credential, 
they are not suitable for this purpose. It is not possible to fully disable 
client certificate use within a cluster as it is used for component to 
component authentication.
Rationale: With any authentication mechanism, the ability to revoke 
credentials if they are compromised or no longer required is a key control. 
Kubernetes client certificate authentication does not allow for this due to 
a lack of support for certificate revocation.
Impact: External mechanisms for authentication generally require additional 
software to be deployed.
Audit: Review user access to the cluster and ensure that users are not 
making use of Kubernetes client certificate authentication.
Remediation: Alternative mechanisms provided by Kubernetes such as the use 
of OIDC should be implemented in place of client certificates.
Default Value: Client certificate authentication is enabled by default.
Additional Information: The lack of certificate revocation was flagged up 
as a high-risk issue in the recent Kubernetes security audit. Without this 
feature, client certificate authentication is not suitable for end users.
References:
N/A",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1018 - User Account Management,Application Security,NIST 800-53 v5,IA-5 AUTHENTICATOR MANAGEMENT
"*.beep,ovh",C-COMPREHENSIVE-DDOS-MITIGATION-AND-SERVICE-PROTECTION,Comprehensive DDoS Mitigation and Service Protection,"Denial of Service (DoS) and Distributed Denial of Service (DDoS) attacks 
pose significant threats to the availability of DNS services. These attacks 
aim to overwhelm DNS servers with a flood of requests, making the service 
slow or completely unavailable to legitimate users. To safeguard DNS 
infrastructure and ensure continuous availability, it's essential to deploy 
a comprehensive DDoS mitigation strategy. This strategy involves several 
key components:

Specialized DDoS Protection Services:

Utilize dedicated DDoS protection solutions that monitor DNS traffic in 
real-time to detect and mitigate attack patterns. These services can 
distinguish between legitimate user traffic and malicious requests, 
enabling the immediate filtering out of attack traffic before it reaches 
your DNS servers. Implementing such services often involves configuring DNS 
routing to pass through DDoS protection scrubbing centers, ensuring that 
only clean traffic reaches your infrastructure.

Rate Limiting:

Apply rate limiting controls on incoming DNS requests to prevent any single 
source from flooding the server with excessive queries. Rate limiting can 
help in minimizing the impact of volumetric attacks, ensuring that server 
resources are not exhausted by malicious requests. Configure thresholds 
based on normal traffic patterns and adjust as needed to accommodate 
legitimate spikes in DNS queries.

Load Balancing:

Employ load balancing techniques to distribute DNS requests evenly across 
multiple servers, enhancing the overall resilience and scalability of DNS 
services. Load balancing can help in absorbing the traffic volume during an 
attack, reducing the risk of any single point of failure and maintaining 
service availability for legitimate requests.

Adaptive Mitigation Strategies:

Ensure that DDoS mitigation strategies are capable of adapting to varying 
load conditions without impacting normal operations. This involves 
dynamically adjusting rate limiting thresholds and load balancing 
configurations in response to observed traffic patterns. Regular testing 
and tuning of mitigation strategies are crucial for ensuring preparedness 
against evolving DDoS attack vectors.

By implementing these measures, developers and network administrators can 
enhance the defense of their DNS infrastructure against DDoS attacks. It's 
essential to regularly review and update these strategies to keep pace with 
the evolving landscape of cyber threats, ensuring the DNS service remains 
robust and reliable for users.",Created by Rules Engine,Recommended,Not tested,High,N/A,High,Hugo Ponthieu,,ATT&CK Enterprise - M1021 - Restrict Web-Based Content||ATT&CK Enterprise - M1030 - Network Segmentation,Network Security,NIST 800-53 v5,SC-5 DENIAL-OF-SERVICE PROTECTION||SI-4 System Monitoring
"*.beep,ovh",C-COMPREHENSIVE-DNS-AND-SUBDOMAIN-AUDITING-AND-MANAGEMENT,Comprehensive DNS and Subdomain Auditing and Management,"Effective management and regular auditing of DNS and subdomain 
configurations are crucial for maintaining the security and integrity of 
your web presence. This countermeasure involves systematic reviews and 
enhancements to DNS settings and subdomain management practices to ensure 
they are secure and comply with best practices.

Steps to Implement Comprehensive DNS and Subdomain Auditing and Management

Inventory DNS Records and Subdomains:

    * Document all existing DNS records and subdomains. This inventory
      should include details about their purpose, associated services, and
      responsible parties.
    * Ensure every entry is necessary and correctly configured according to
      its intended use.

Implement Access Controls:

    * Restrict access to DNS management tools and configuration settings to
      authorized personnel only.
    * Employ role-based access controls (RBAC) to limit who can view,
      modify, or delete DNS and subdomain settings based on their role and
      necessity.

Regular Auditing:

    * Schedule regular audits of DNS configurations and subdomain settings
      to ensure they remain aligned with current operational requirements
      and security policies.
    * Use automated tools to detect misconfigurations or unauthorized
      changes.

Secure DNS Management Interfaces:

    * Ensure that all management interfaces (such as web-based DNS control
      panels) are accessible only via secure connections (HTTPS).
    * Implement strong authentication measures, including multi-factor
      authentication (MFA), for accessing DNS management systems.

Review and Update DNS Security Settings:

    * Implement DNSSEC (DNS Security Extensions) to protect DNS data with
      cryptographic signatures and help prevent DNS spoofing and cache
      poisoning.
    * Configure DNS settings to minimize the risk of unauthorized zone
      transfers or information leakage. Allow zone transfers only to
      authorized secondary DNS servers.

Monitoring and Alerting:

    * Set up monitoring systems to track changes in DNS and subdomain
      configurations. Use DNS query logging to detect unusual patterns that
      could indicate malicious activities.
    * Establish alerting mechanisms to notify administrators of suspicious
      activities or deviations from established configurations.

Educate and Train Staff:

    * Conduct regular training sessions for staff involved in DNS
      management to ensure they are aware of current threats and best
      practices.
    * Encourage staff to stay informed about the latest DNS security
      threats and mitigation strategies.

Develop and Enforce Policies:

    * Create and enforce policies that dictate how DNS and subdomains
      should be managed, audited, and secured.
    * Ensure that these policies include guidelines for handling and
      responding to security incidents related to DNS.

Backup DNS Records:

    * Regularly back up DNS records and ensure that backups are stored
      securely.
    * Test restoration procedures to confirm that DNS settings can be
      quickly restored to a known good state in the event of corruption or
      loss.

Good Security Practices Reference

    * Follow best practices and guidelines from organizations such as the
      Internet Corporation for Assigned Names and Numbers (ICANN) and the
      Internet Engineering Task Force (IETF) regarding DNS management and
      security.
    * Consult resources like the Open Web Application Security Project
      (OWASP) for general web security practices that include DNS security
      considerations.

By diligently implementing these steps, developers can significantly 
enhance the security of DNS and subdomain configurations, reducing the risk 
of attacks and ensuring stable and reliable domain name resolution 
services.",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Hugo Ponthieu,,ATT&CK Enterprise - M1026 - Privileged Account Management||ATT&CK Enterprise - M1047 - Audit||ATT&CK Enterprise - M1051 - Update Software||ATT&CK Enterprise - M1054 - Software Configuration,Network Security,NIST 800-53 v5,SC-20 Secure Name/address Resolution Service (authoritative Source)
VPN (Virtual Private Network),C-VPN-VIRTUAL-PRIVATE-NETWORK-CNT-09,Conduct routine audits and reviews of VPN configurations to ensure compliance with security standards,"Perform regular audits and reviews of VPN configurations to verify they 
align with best practices and security standards. This proactive approach 
minimizes misconfigurations, strengthens the VPN’s security posture, and 
ensures adherence to evolving organizational and regulatory requirements.

Establish an Audit Schedule:

    * Define a regular cadence for configuration reviews, such as quarterly
      or after significant updates.
    * Conduct additional audits following security incidents or
      infrastructure changes.

Define Audit Scope:

    * Include key configurations such as authentication mechanisms,
      encryption settings, allowed protocols, access controls, and logging
      settings.
    * Verify compliance with organizational policies and industry standards
      (e.g., NIST, CIS Benchmarks).

Review Authentication Settings:

    * Ensure multifactor authentication (MFA) is enforced for all users.
    * Check for unused or outdated user accounts and remove them promptly.

Validate Encryption Standards:

    * Confirm the VPN uses secure encryption protocols like TLS 1.2 or TLS
      1.3.
    * Disable weak or deprecated protocols such as PPTP or L2TP without
      IPsec.

Assess Access Controls:

    * Verify that access is restricted to authorized users and devices
      only.
    * Review and update firewall rules and traffic segmentation policies.

Check Logging and Monitoring:

    * Ensure comprehensive logging is enabled and integrated with a SIEM
      system for real-time analysis.
    * Verify logs are retained securely and accessible for audits or
      investigations.

Document Findings and Remediate Issues:

    * Record audit results, highlighting any deviations from best
      practices.
    * Assign remediation tasks to address identified issues and track their
      resolution.

Continuous Improvement:

    * Update configurations and policies based on audit findings, threat
      intelligence, and industry developments.
    * Train administrators on emerging best practices and common
      configuration pitfalls.

By conducting routine VPN configuration audits, developers and DevOps 
engineers can proactively identify and address security gaps, ensuring the 
VPN remains resilient against threats and compliant with security 
standards.

References:

    * NIST SP 800-41: Guidelines on VPN Security
      <https://csrc.nist.gov/publications/detail/sp/800-41/rev-1/final>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Hugo Ponthieu,,ATT&CK Enterprise - M1047 - Audit,Network Security,NIST 800-53 v5,AU-12 Audit Record Generation
Bare Metal Server,C-BARE-METAL-SERVER-CNT-04,Conduct thorough supply chain risk assessments,"Engaging in rigorous supply chain validation processes is vital for 
securing bare metal servers against compromised components. The following 
step-by-step guidance outlines how to implement effective supply chain 
validation:

   1. Partner Vetting:
         1. Research and compile a list of potential suppliers and
            manufacturers.
         2. Conduct background checks to ensure partners have a history of
            adhering to security standards.
         3. Require partners to disclose any past incidents of hardware
            tampering or data breaches.
         4. Implement a system to routinely evaluate and audit partner
            security practices to ensure ongoing compliance with security
            standards.
   2. Vulnerability Assessments:
         1. Adopt a framework to regularly assess hardware components for
            vulnerabilities, such as CVE databases.
         2. Perform threat modeling to identify potential security risks
            specific to the bare metal servers.
         3. Employ third-party security experts to conduct independent
            evaluations of hardware components.
         4. Utilize automated scanning tools tailored to identify known
            vulnerabilities in hardware components.
   3. Tracking Provenance of Hardware Components:
         1. Implement a supply chain management system to log and track the
            origin and history of all components used in the servers.
         2. Introduce hardware authenticity checks that verify component
            integrity at each stage of the supply chain.
         3. Utilize blockchain technology to secure the traceability
            records, ensuring immutability and transparency.
   4. Continuous Improvement:
         1. Stay updated with the latest industry trends and incorporate
            new security technologies as they become available.
         2. Regularly review and update the supply chain validation
            processes to adapt to evolving threats.
         3. Encourage a culture of security awareness across all
            stakeholders involved in the supply chain.

References

    * NIST Special Publication 800-161 Rev. 1 (Draft): Cybersecurity Supply
      Chain Risk Management Practices for Systems and Organizations
      <https://csrc.nist.gov/publications/detail/sp/800-161/rev-1/draft>",Created by Rules Engine,Recommended,Not tested,Very high,N/A,High,Hugo Ponthieu,,EMB3D - MID-025 - End-of-Life Management Features,Hardware Security,NIST 800-53 v5,SR-2 Supply Chain Risk Management Plan
Bare Metal Server,C-BARE-METAL-SERVER-CNT-04,Conduct thorough supply chain risk assessments,"Engaging in rigorous supply chain validation processes is vital for 
securing bare metal servers against compromised components. The following 
step-by-step guidance outlines how to implement effective supply chain 
validation:

   1. Partner Vetting:
         1. Research and compile a list of potential suppliers and
            manufacturers.
         2. Conduct background checks to ensure partners have a history of
            adhering to security standards.
         3. Require partners to disclose any past incidents of hardware
            tampering or data breaches.
         4. Implement a system to routinely evaluate and audit partner
            security practices to ensure ongoing compliance with security
            standards.
   2. Vulnerability Assessments:
         1. Adopt a framework to regularly assess hardware components for
            vulnerabilities, such as CVE databases.
         2. Perform threat modeling to identify potential security risks
            specific to the bare metal servers.
         3. Employ third-party security experts to conduct independent
            evaluations of hardware components.
         4. Utilize automated scanning tools tailored to identify known
            vulnerabilities in hardware components.
   3. Tracking Provenance of Hardware Components:
         1. Implement a supply chain management system to log and track the
            origin and history of all components used in the servers.
         2. Introduce hardware authenticity checks that verify component
            integrity at each stage of the supply chain.
         3. Utilize blockchain technology to secure the traceability
            records, ensuring immutability and transparency.
   4. Continuous Improvement:
         1. Stay updated with the latest industry trends and incorporate
            new security technologies as they become available.
         2. Regularly review and update the supply chain validation
            processes to adapt to evolving threats.
         3. Encourage a culture of security awareness across all
            stakeholders involved in the supply chain.

References

    * NIST Special Publication 800-161 Rev. 1 (Draft): Cybersecurity Supply
      Chain Risk Management Practices for Systems and Organizations
      <https://csrc.nist.gov/publications/detail/sp/800-161/rev-1/draft>",Created by Rules Engine,Recommended,Not tested,Very high,N/A,High,Hugo Ponthieu,,EMB3D - MID-025 - End-of-Life Management Features,Hardware Security,NIST 800-53 v5,SR-2 Supply Chain Risk Management Plan
React.js,C-REACT-JS-CNT-REACTJS-06,Configure content security policy (CSP) in ReactJS,"Configure a Content Security Policy (CSP) in your React.js application to 
mitigate the risk of cross-site scripting (XSS) and other malicious content 
injection attacks. By specifying allowed sources for scripts, styles, 
images, and other resources, you can control what external resources are 
trusted and prevent unauthorized scripts from executing in the browser. CSP 
should be implemented by adding the appropriate HTTP headers to your 
React.js application, either via the server or through a meta tag. 
Regularly review and update the policy to reflect new security needs and 
ensure that all external dependencies are trusted.

References

    * Securing Your React App with Content Security Policy
      <https://betterreact.dev/insights/securing-react-applications-best-practices-and-tools/>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1047 - Audit,Application Security,NIST 800-53 v5,CM-6 Configuration Settings
Kubernetes Pod,C-KUBERNETES-POD-CNT-01,Configure Image Provenance using ImagePolicyWebhook admission controller,"CIS Benchmark Recommendation id: 5.5.1
Profile Applicability: Level 2 - Master Node
Description: Configure Image Provenance for your deployment.
Rationale: Kubernetes supports plugging in provenance rules to accept or 
reject the images in your deployments. You could configure such rules to 
ensure that only approved images are deployed in the cluster.
Impact: You need to regularly maintain your provenance configuration based 
on container image updates.
Audit: Review the pod definitions in your cluster and verify that image 
provenance is configured as appropriate.
Remediation: Follow the Kubernetes documentation and setup image 
provenance.
Default Value: By default, image provenance is not set.
References:

   1. 
      <https://kubernetes.io/docs/admin/admission-controllers/#imagepolicywebhook>
   2. 
      <https://github.com/kubernetes/community/blob/master/contributors/designproposals/image-provenance.md>
   3. <https://hub.docker.com/r/dnurmi/anchore-toolbox/>
   4. <https://github.com/kubernetes/kubernetes/issues/22888>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1056 - Pre-compromise,Application Security,NIST 800-53 v5,"SI-7 Software, Firmware, and Information Integrity"
Kubernetes Pod,C-KUBERNETES-POD-CNT-01,Configure Image Provenance using ImagePolicyWebhook admission controller,"CIS Benchmark Recommendation id: 5.5.1
Profile Applicability: Level 2 - Master Node
Description: Configure Image Provenance for your deployment.
Rationale: Kubernetes supports plugging in provenance rules to accept or 
reject the images in your deployments. You could configure such rules to 
ensure that only approved images are deployed in the cluster.
Impact: You need to regularly maintain your provenance configuration based 
on container image updates.
Audit: Review the pod definitions in your cluster and verify that image 
provenance is configured as appropriate.
Remediation: Follow the Kubernetes documentation and setup image 
provenance.
Default Value: By default, image provenance is not set.
References:

   1. 
      <https://kubernetes.io/docs/admin/admission-controllers/#imagepolicywebhook>
   2. 
      <https://github.com/kubernetes/community/blob/master/contributors/designproposals/image-provenance.md>
   3. <https://hub.docker.com/r/dnurmi/anchore-toolbox/>
   4. <https://github.com/kubernetes/kubernetes/issues/22888>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1056 - Pre-compromise,Application Security,NIST 800-53 v5,"SI-7 Software, Firmware, and Information Integrity"
Kubernetes Pod,C-KUBERNETES-POD-CNT-01,Configure Image Provenance using ImagePolicyWebhook admission controller,"CIS Benchmark Recommendation id: 5.5.1
Profile Applicability: Level 2 - Master Node
Description: Configure Image Provenance for your deployment.
Rationale: Kubernetes supports plugging in provenance rules to accept or 
reject the images in your deployments. You could configure such rules to 
ensure that only approved images are deployed in the cluster.
Impact: You need to regularly maintain your provenance configuration based 
on container image updates.
Audit: Review the pod definitions in your cluster and verify that image 
provenance is configured as appropriate.
Remediation: Follow the Kubernetes documentation and setup image 
provenance.
Default Value: By default, image provenance is not set.
References:

   1. 
      <https://kubernetes.io/docs/admin/admission-controllers/#imagepolicywebhook>
   2. 
      <https://github.com/kubernetes/community/blob/master/contributors/designproposals/image-provenance.md>
   3. <https://hub.docker.com/r/dnurmi/anchore-toolbox/>
   4. <https://github.com/kubernetes/kubernetes/issues/22888>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1056 - Pre-compromise,Application Security,NIST 800-53 v5,"SI-7 Software, Firmware, and Information Integrity"
Kubernetes Pod,C-KUBERNETES-POD-CNT-01,Configure Image Provenance using ImagePolicyWebhook admission controller,"CIS Benchmark Recommendation id: 5.5.1
Profile Applicability: Level 2 - Master Node
Description: Configure Image Provenance for your deployment.
Rationale: Kubernetes supports plugging in provenance rules to accept or 
reject the images in your deployments. You could configure such rules to 
ensure that only approved images are deployed in the cluster.
Impact: You need to regularly maintain your provenance configuration based 
on container image updates.
Audit: Review the pod definitions in your cluster and verify that image 
provenance is configured as appropriate.
Remediation: Follow the Kubernetes documentation and setup image 
provenance.
Default Value: By default, image provenance is not set.
References:

   1. 
      <https://kubernetes.io/docs/admin/admission-controllers/#imagepolicywebhook>
   2. 
      <https://github.com/kubernetes/community/blob/master/contributors/designproposals/image-provenance.md>
   3. <https://hub.docker.com/r/dnurmi/anchore-toolbox/>
   4. <https://github.com/kubernetes/kubernetes/issues/22888>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1056 - Pre-compromise,Application Security,NIST 800-53 v5,"SI-7 Software, Firmware, and Information Integrity"
Kubernetes Pod,C-KUBERNETES-POD-CNT-01,Configure Image Provenance using ImagePolicyWebhook admission controller,"CIS Benchmark Recommendation id: 5.5.1
Profile Applicability: Level 2 - Master Node
Description: Configure Image Provenance for your deployment.
Rationale: Kubernetes supports plugging in provenance rules to accept or 
reject the images in your deployments. You could configure such rules to 
ensure that only approved images are deployed in the cluster.
Impact: You need to regularly maintain your provenance configuration based 
on container image updates.
Audit: Review the pod definitions in your cluster and verify that image 
provenance is configured as appropriate.
Remediation: Follow the Kubernetes documentation and setup image 
provenance.
Default Value: By default, image provenance is not set.
References:

   1. 
      <https://kubernetes.io/docs/admin/admission-controllers/#imagepolicywebhook>
   2. 
      <https://github.com/kubernetes/community/blob/master/contributors/designproposals/image-provenance.md>
   3. <https://hub.docker.com/r/dnurmi/anchore-toolbox/>
   4. <https://github.com/kubernetes/kubernetes/issues/22888>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1056 - Pre-compromise,Application Security,NIST 800-53 v5,"SI-7 Software, Firmware, and Information Integrity"
Backend,C-WEB-APPLICATION-SERVER-SIDE-CNT-10,Configure XML parsers to disallow external entities and DTD processing,"To prevent XML-based attacks such as XML External Entity (XXE) and Denial 
of Service (DoS) attacks, configure XML parsers to disallow external 
entities and Document Type Definition (DTD) processing by default. This 
ensures that any incoming XML documents cannot trigger external requests or 
load external data that could compromise the system, leak sensitive data, 
or cause resource exhaustion.

Implementation Steps:

   1. Disable External Entity Resolution: Configure XML parsers to
      explicitly disable the resolution of external entities by setting
      options or flags that prevent the parser from fetching external
      resources.
   2. Disable DTD Processing: Ensure that the XML parser does not process
      DTDs, which can be used to define and reference external entities or
      cause denial-of-service attacks via large or nested DTDs.
   3. Use Secure Parsers: Ensure that you are using updated and secure XML
      parsing libraries that offer built-in protections against XXE and
      other XML-based vulnerabilities.
   4. Validate XML Input: Before parsing, validate XML input to ensure it
      conforms to a known schema or structure, mitigating any unexpected or
      malicious data.

References:

    * OWASP XML External Entity (XXE) Prevention Cheat Sheet
      <https://cheatsheetseries.owasp.org/cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1055 - Do Not Mitigate,Application Security,NIST 800-53 v5,CM-6 Configuration Settings
Fronend,C-WEB-APPLICATION-SERVER-SIDE-CNT-10,Configure XML parsers to disallow external entities and DTD processing,"To prevent XML-based attacks such as XML External Entity (XXE) and Denial 
of Service (DoS) attacks, configure XML parsers to disallow external 
entities and Document Type Definition (DTD) processing by default. This 
ensures that any incoming XML documents cannot trigger external requests or 
load external data that could compromise the system, leak sensitive data, 
or cause resource exhaustion.

Implementation Steps:

   1. Disable External Entity Resolution: Configure XML parsers to
      explicitly disable the resolution of external entities by setting
      options or flags that prevent the parser from fetching external
      resources.
   2. Disable DTD Processing: Ensure that the XML parser does not process
      DTDs, which can be used to define and reference external entities or
      cause denial-of-service attacks via large or nested DTDs.
   3. Use Secure Parsers: Ensure that you are using updated and secure XML
      parsing libraries that offer built-in protections against XXE and
      other XML-based vulnerabilities.
   4. Validate XML Input: Before parsing, validate XML input to ensure it
      conforms to a known schema or structure, mitigating any unexpected or
      malicious data.

References:

    * OWASP XML External Entity (XXE) Prevention Cheat Sheet
      <https://cheatsheetseries.owasp.org/cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1055 - Do Not Mitigate,Application Security,NIST 800-53 v5,CM-6 Configuration Settings
API Gateway,C-API-GATEWAY-CNT-02,Connectors should be provided for integrating with identity providers (IdPs),"To ensure seamless integration with identity providers and strengthen 
authentication mechanisms for your API gateway, follow these detailed 
steps:

   1. Evaluate and Choose an Identity Provider (IdP): Begin by evaluating
      well-known IdPs such as Auth0, Okta, Google Identity Platform, or
      Azure Active Directory. Consider factors like compatibility with your
      API gateway, support for OAuth 2.0 and OpenID Connect, scalability,
      and security features.
   2. Configure the API Gateway: Update your API gateway to support the
      identity standards endorsed by your chosen IdP. This often involves
      configuring the gateway to handle OAuth 2.0 authorization flows such
      as authorization code, implicit, or client credentials.
         1. Access your API gateway management console.
         2. Navigate to the security settings or authentication section.
         3. Enable support for JWT tokens or SAML assertions if applicable.
   3. Set Up Communication with the IdP: Establish a connection between
      your API gateway and the IdP by registering your API gateway as a
      client application with the IdP. Ensure that you:
         1. Register redirect URIs that the IdP can use to send
            authorization responses back to your application.
         2. Configure client IDs and client secrets in a secure manner,
            using environment variables or a secure server setup.
   4. Implement Authentication Flows: Depending on the features offered by
      the IdP, implement appropriate authentication flows on your API
      gateway. For example, support the PKCE extension for OAuth 2.0 to
      enhance security in public applications.
         1. Ensure the API gateway can initiate the proper OAuth flow and
            handle redirects appropriately.
         2. Configure scopes, claims, and resource access policies as
            required by your applications.
   5. Test the Integration: Conduct thorough testing by simulating various
      authentication scenarios. Verify that access tokens are issued and
      validated correctly, and that user information is accurately
      retrieved if using OpenID Connect.
         1. Check logs for any authentication errors or misconfigurations.
         2. Use testing tools like Postman or Curl to simulate
            authentication requests.
   6. Monitor and Adjust: Once integration is live, continuously monitor
      authentication logs for any unusual activity or failures. Be prepared
      to adjust configurations based on changes to IdP features or security
      guidelines.

References

    * Google Identity Platform - Authenticating Users
      <https://cloud.google.com/endpoints/docs/openapi/authenticating-users-google-id>
    * Azure Active Directory - Authentication Scenarios
      <https://docs.microsoft.com/en-us/azure/active-directory/develop/active-directory-authentication-scenarios>",Created by Rules Engine,Recommended,Not tested,High,N/A,High,Hugo Ponthieu,,ATT&CK Enterprise - M1026 - Privileged Account Management,Application Security,NIST 800-53 v5,AC-21 Information Sharing
AWS S3 (Simple Storage Service),C-AWS-S3-CNT-06,Consider encryption of data at rest,"You have the following options for protecting data at rest in Amazon S3:

    * Server-side encryption – All Amazon S3 buckets have encryption
      configured by default, and all new objects that are uploaded to an S3
      bucket are automatically encrypted at rest. Server-side encryption
      with Amazon S3 managed keys (SSE-S3) is the default encryption
      configuration for every bucket in Amazon S3. To use a different type
      of encryption, you can either specify the type of server-side
      encryption to use in your S3 PUT requests, or you can set the default
      encryption configuration in the destination bucket.

Amazon S3 also provides these server-side encryption options:

    * Server-side encryption with AWS Key Management Service (AWS KMS) keys
      (SSE-KMS)
    * Dual-layer server-side encryption with AWS Key Management Service
      (AWS KMS) keys (DSSE-KMS)
    * Server-side encryption with customer-provided keys (SSE-C)

For more information, see Protecting data with server-side encryption
<https://docs.aws.amazon.com/AmazonS3/latest/userguide/serv-side-encryption.html> 
.

    * Client-side encryption – Encrypt data client-side and upload the
      encrypted data to Amazon S3. In this case, you manage the encryption
      process, the encryption keys, and related tools. As with server-side
      encryption, client-side encryption can help reduce risk by encrypting
      the data with a key that is stored in a different mechanism than the
      mechanism that stores the data itself.

Amazon S3 provides multiple client-side encryption options. For more 
information, see Protecting data by using client-side encryption
<https://docs.aws.amazon.com/AmazonS3/latest/userguide/UsingClientSideEncryption.html> 
.",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1041 - Encrypt Sensitive Information,Data Security,NIST 800-53 v5,SC-28 PROTECTION OF INFORMATION AT REST
Kubernetes Pod,C-KUBERNETES-POD-CNT-03,Consider external secret storage,"CIS Benchmark Recommendation id: 5.4.2 
Profile Applicability: Level 2 - Master Node 

Description: Consider the use of an external secrets storage and management 
system, instead of using Kubernetes Secrets directly, if you have more 
complex secret management needs. Ensure the solution requires 
authentication to access secrets, has auditing of access to and use of 
secrets, and encrypts secrets. Some solutions also make it easier to rotate 
secrets. 

Rationale: Kubernetes supports secrets as first-class objects, but care 
needs to be taken to ensure that access to secrets is carefully limited. 
Using an external secrets provider can ease the management of access to 
secrets, especially where secrets are used across both Kubernetes and 
non-Kubernetes environments. 

Impact: None 

Audit: Review your secrets management implementation.

Remediation: Refer to the secrets management options offered by your cloud 
provider or a third-party secrets management solution. 

Default Value: By default, no external secret management is configured.

References: 
N/A",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1043 - Credential Access Protection,Cloud Security,NIST 800-53 v5,SC-28 PROTECTION OF INFORMATION AT REST
Kubernetes Pod,C-KUBERNETES-POD-CNT-03,Consider external secret storage,"CIS Benchmark Recommendation id: 5.4.2 
Profile Applicability: Level 2 - Master Node 

Description: Consider the use of an external secrets storage and management 
system, instead of using Kubernetes Secrets directly, if you have more 
complex secret management needs. Ensure the solution requires 
authentication to access secrets, has auditing of access to and use of 
secrets, and encrypts secrets. Some solutions also make it easier to rotate 
secrets. 

Rationale: Kubernetes supports secrets as first-class objects, but care 
needs to be taken to ensure that access to secrets is carefully limited. 
Using an external secrets provider can ease the management of access to 
secrets, especially where secrets are used across both Kubernetes and 
non-Kubernetes environments. 

Impact: None 

Audit: Review your secrets management implementation.

Remediation: Refer to the secrets management options offered by your cloud 
provider or a third-party secrets management solution. 

Default Value: By default, no external secret management is configured.

References: 
N/A",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1043 - Credential Access Protection,Cloud Security,NIST 800-53 v5,SC-28 PROTECTION OF INFORMATION AT REST
Kubernetes Pod,C-KUBERNETES-POD-CNT-03,Consider external secret storage,"CIS Benchmark Recommendation id: 5.4.2 
Profile Applicability: Level 2 - Master Node 

Description: Consider the use of an external secrets storage and management 
system, instead of using Kubernetes Secrets directly, if you have more 
complex secret management needs. Ensure the solution requires 
authentication to access secrets, has auditing of access to and use of 
secrets, and encrypts secrets. Some solutions also make it easier to rotate 
secrets. 

Rationale: Kubernetes supports secrets as first-class objects, but care 
needs to be taken to ensure that access to secrets is carefully limited. 
Using an external secrets provider can ease the management of access to 
secrets, especially where secrets are used across both Kubernetes and 
non-Kubernetes environments. 

Impact: None 

Audit: Review your secrets management implementation.

Remediation: Refer to the secrets management options offered by your cloud 
provider or a third-party secrets management solution. 

Default Value: By default, no external secret management is configured.

References: 
N/A",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1043 - Credential Access Protection,Cloud Security,NIST 800-53 v5,SC-28 PROTECTION OF INFORMATION AT REST
Kubernetes Pod,C-KUBERNETES-POD-CNT-03,Consider external secret storage,"CIS Benchmark Recommendation id: 5.4.2 
Profile Applicability: Level 2 - Master Node 

Description: Consider the use of an external secrets storage and management 
system, instead of using Kubernetes Secrets directly, if you have more 
complex secret management needs. Ensure the solution requires 
authentication to access secrets, has auditing of access to and use of 
secrets, and encrypts secrets. Some solutions also make it easier to rotate 
secrets. 

Rationale: Kubernetes supports secrets as first-class objects, but care 
needs to be taken to ensure that access to secrets is carefully limited. 
Using an external secrets provider can ease the management of access to 
secrets, especially where secrets are used across both Kubernetes and 
non-Kubernetes environments. 

Impact: None 

Audit: Review your secrets management implementation.

Remediation: Refer to the secrets management options offered by your cloud 
provider or a third-party secrets management solution. 

Default Value: By default, no external secret management is configured.

References: 
N/A",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1043 - Credential Access Protection,Cloud Security,NIST 800-53 v5,SC-28 PROTECTION OF INFORMATION AT REST
Kubernetes Pod,C-KUBERNETES-POD-CNT-03,Consider external secret storage,"CIS Benchmark Recommendation id: 5.4.2 
Profile Applicability: Level 2 - Master Node 

Description: Consider the use of an external secrets storage and management 
system, instead of using Kubernetes Secrets directly, if you have more 
complex secret management needs. Ensure the solution requires 
authentication to access secrets, has auditing of access to and use of 
secrets, and encrypts secrets. Some solutions also make it easier to rotate 
secrets. 

Rationale: Kubernetes supports secrets as first-class objects, but care 
needs to be taken to ensure that access to secrets is carefully limited. 
Using an external secrets provider can ease the management of access to 
secrets, especially where secrets are used across both Kubernetes and 
non-Kubernetes environments. 

Impact: None 

Audit: Review your secrets management implementation.

Remediation: Refer to the secrets management options offered by your cloud 
provider or a third-party secrets management solution. 

Default Value: By default, no external secret management is configured.

References: 
N/A",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1043 - Credential Access Protection,Cloud Security,NIST 800-53 v5,SC-28 PROTECTION OF INFORMATION AT REST
AWS S3 (Simple Storage Service),C-AWS-S3-CNT-18,Consider using S3 Cross-Region Replication,"Although Amazon S3 stores your data across multiple geographically diverse 
Availability Zones by default, compliance requirements might dictate that 
you store data at even greater distances. With S3 Cross-Region Replication 
(CRR), you can replicate data between distant AWS Regions to help satisfy 
these requirements. CRR enables automatic, asynchronous copying of objects 
across buckets in different AWS Regions. For more information, see 
Replicating objects
<https://docs.aws.amazon.com/AmazonS3/latest/userguide/replication.html> .

Note

CRR requires both the source and destination S3 buckets to have versioning 
enabled.

Also consider implementing ongoing detective controls by using the 
s3-bucket-replication-enabled
<https://docs.aws.amazon.com/config/latest/developerguide/s3-bucket-replication-enabled.html> 
managed AWS Config rule.",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1053 - Data Backup,Cloud Security,NIST 800-53 v5,CP-9 System Backup
AWS S3 (Simple Storage Service),C-AWS-S3-CNT-08,Consider using S3 Object Lock,"With S3 Object Lock, you can store objects by using a ""Write Once Read 
Many"" (WORM) model. S3 Object Lock can help prevent accidental or 
inappropriate deletion of data. For example, you can use S3 Object Lock to 
help protect your AWS CloudTrail logs.

For more information, see Using S3 Object Lock
<https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lock.html> .",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1036 - Account Use Policies,Cloud Security,NIST 800-53 v5,PM-24 Data Integrity Board
Kubernetes Cluster,C-KUBERNETES-CLUSTER-CNT-24,Create administrative boundaries between resources using namespaces,"CIS Benchmark Recommendation id: 5.7.1
Profile Applicability: Level 1 - Master Node
Description: Use namespaces to isolate your Kubernetes objects.
Rationale: Limiting the scope of user permissions can reduce the impact of 
mistakes or malicious activities. A Kubernetes namespace allows you to 
partition created resources into logically named groups. Resources created 
in one namespace can be hidden from other namespaces. By default, each 
resource created by a user in Kubernetes cluster runs in a default 
namespace, called default. You can create additional namespaces and attach 
resources and users to them. You can use Kubernetes Authorization plugins 
to create policies that segregate access to namespace resources between 
different users.
Impact: You need to switch between namespaces for administration.
Audit: Run the below command and review the namespaces created in the 
cluster.
kubectl get namespaces
Ensure that these namespaces are the ones you need and are adequately 
administered as per your requirements.
Remediation: Follow the documentation and create namespaces for objects in 
your deployment as you need them.
Default Value: By default, Kubernetes starts with 4 initial namespaces:

   1. default - The default namespace for objects with no other namespace
   2. kube-system - The namespace for objects created by the Kubernetes
      system
   3. kube-node-lease - Namespace used for node heartbeats
   4. kube-public - Namespace used for public information in a cluster

References:

   1. 
      <https://kubernetes.io/docs/concepts/overview/working-withobjects/namespaces/#viewing-namespaces>
   2. 
      <http://blog.kubernetes.io/2016/08/security-best-practices-kubernetesdeployment.html>
   3. 
      <https://github.com/kubernetes/enhancements/tree/master/keps/sig-node/589efficient-node-heartbeats>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1026 - Privileged Account Management,Cloud Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Cloudflare,C-CLOUDFLARE-02,Deploy rate limiting and traffic filtering,"Deploying rate limiting and traffic filtering helps protect against DDoS 
attacks by controlling the volume of incoming traffic and filtering out 
malicious traffic.

Steps to Implement:

   1. Configure rate limiting on your servers to limit the number of
      requests from a single IP address within a specified time frame.
   2. Set up traffic filtering rules to identify and block malicious
      traffic patterns.
   3. Use a Web Application Firewall (WAF) to inspect incoming traffic and
      block potential DDoS attacks.
   4. Implement load balancing to distribute traffic across multiple
      servers, reducing the impact of DDoS attacks.
   5. Regularly monitor traffic patterns and adjust rate limiting and
      filtering rules as needed.

These measures help ensure your website remains available and resilient 
against DDoS attacks.",Created by Rules Engine,Recommended,Not tested,High,N/A,High,Hugo Ponthieu,,ATT&CK Enterprise - M1037 - Filter Network Traffic,Application Security||Network Security,NIST 800-53 v5,SC-5 DENIAL-OF-SERVICE PROTECTION
AWS S3 (Simple Storage Service),C-AWS-S3-CNT-01,Disable access control lists (ACLs) and use bucket policies to manage permissions,"S3 Object Ownership is an Amazon S3 bucket-level setting that you can use 
to control ownership of objects uploaded to your bucket and to disable or 
enable ACLs. By default, Object Ownership is set to the Bucket owner 
enforced setting and all ACLs are disabled. When ACLs are disabled, the 
bucket owner owns all the objects in the bucket and manages access to data 
exclusively using access management policies.

A majority of modern use cases in Amazon S3 no longer require the use of 
access control lists (ACLs)
<https://docs.aws.amazon.com/AmazonS3/latest/userguide/acl-overview.html> 
. We recommend that you disable ACLs, except in unusual circumstances where 
you must control access for each object individually. To disable ACLs and 
take ownership of every object in your bucket, apply the bucket owner 
enforced setting for S3 Object Ownership. When you disable ACLs, you can 
easily maintain a bucket with objects uploaded by different AWS accounts.

When ACLs are disabled access control for your data is based on policies, 
such as the following:

    * AWS Identity and Access Management (IAM) user policies
    * S3 bucket policies
    * Virtual private cloud (VPC) endpoint policies
    * AWS Organizations service control policies (SCPs)

Disabling ACLs simplifies permissions management and auditing. ACLs are 
disabled for new buckets by default. You can also disable ACLs for existing 
buckets. If you have an existing bucket that already has objects in it, 
after you disable ACLs, the object and bucket ACLs are no longer part of 
the access-evaluation process. Instead, access is granted or denied on the 
basis of policies.

Before you disable ACLs, make sure that you do the following:

    * Review your bucket policy to ensure that it covers all the ways that
      you intend to grant access to your bucket outside of your account.
    * Reset your bucket ACL to the default (full control to the bucket
      owner).

After you disable ACLs, the following behaviors occur:

    * Your bucket accepts only PUT requests that do not specify an ACL or
      PUT requests with bucket owner full control ACLs. These ACLs include
      the bucket-owner-full-control canned ACL or equivalent forms of this
      ACL that are expressed in XML.
    * Existing applications that support bucket owner full control ACLs see
      no impact.
    * PUT requests that contain other ACLs (for example, custom grants to
      certain AWS accounts) fail and return an HTTP status code 400 (Bad
      Request) with the error code AccessControlListNotSupported.

For more information, see Controlling ownership of objects and disabling 
ACLs for your bucket
<https://docs.aws.amazon.com/AmazonS3/latest/userguide/about-object-ownership.html> 
.",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1035 - Limit Access to Resource Over Network,Data Security,NIST 800-53 v5,AC-24 Access Control Decisions
Backend,C-WEB-APPLICATION-SERVER-SIDE-CNT-06,"Disable unused services, remove default accounts, and apply security updates","To minimize the attack surface and enhance security, disable any unused 
services, remove default accounts, and apply security updates promptly. By 
doing so, you reduce the risk of exploitation through unneeded services or 
default credentials and ensure that the system is protected from known 
vulnerabilities. Additionally, use secure configurations to prevent 
unauthorized access and ensure that the system is optimally protected.

Implementation Steps:

   1. Disable Unused Services: Identify and disable any services that are
      not needed for the application or system to function. This limits the
      number of potential attack vectors.
   2. Remove Default Accounts: Remove or disable default accounts and
      ensure that all active accounts are assigned strong, unique
      credentials. Avoid using default settings that might be easily
      guessed by attackers.
   3. Apply Security Updates: Regularly check for and apply security
      patches to all systems and applications. Set up an automated patch
      management process to ensure that critical updates are applied as
      soon as they are released.
   4. Use Secure Configurations: Ensure that all configurations, such as
      database, server, and application settings, follow security best
      practices, including strong encryption, least privilege access, and
      secure communication protocols.

References:

    * OWASP Secure Configuration Guide
      <https://owasp.org/www-project-secure-coding-practices-quick-reference-guide/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1048 - Application Isolation and Sandboxing,Network Security,NIST 800-53 v5,CM-3 Configuration Change Control
Fronend,C-WEB-APPLICATION-SERVER-SIDE-CNT-06,"Disable unused services, remove default accounts, and apply security updates","To minimize the attack surface and enhance security, disable any unused 
services, remove default accounts, and apply security updates promptly. By 
doing so, you reduce the risk of exploitation through unneeded services or 
default credentials and ensure that the system is protected from known 
vulnerabilities. Additionally, use secure configurations to prevent 
unauthorized access and ensure that the system is optimally protected.

Implementation Steps:

   1. Disable Unused Services: Identify and disable any services that are
      not needed for the application or system to function. This limits the
      number of potential attack vectors.
   2. Remove Default Accounts: Remove or disable default accounts and
      ensure that all active accounts are assigned strong, unique
      credentials. Avoid using default settings that might be easily
      guessed by attackers.
   3. Apply Security Updates: Regularly check for and apply security
      patches to all systems and applications. Set up an automated patch
      management process to ensure that critical updates are applied as
      soon as they are released.
   4. Use Secure Configurations: Ensure that all configurations, such as
      database, server, and application settings, follow security best
      practices, including strong encryption, least privilege access, and
      secure communication protocols.

References:

    * OWASP Secure Configuration Guide
      <https://owasp.org/www-project-secure-coding-practices-quick-reference-guide/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1048 - Application Isolation and Sandboxing,Network Security,NIST 800-53 v5,CM-3 Configuration Change Control
AWS S3 (Simple Storage Service),C-AWS-S3-CNT-14,Discover sensitive data by using Amazon Macie,"Amazon Macie is a security service that discovers sensitive data by using 
machine learning and pattern matching. Macie provides visibility into data 
security risks, and enables automated protection against those risks. With 
Macie, you can automate the discovery and reporting of sensitive data in 
your Amazon S3 data estate to gain a better understanding of the data that 
your organization stores in S3.

To detect sensitive data with Macie, you can use built-in criteria and 
techniques that are designed to detect a large and growing list of 
sensitive data types for many countries and regions. These sensitive data 
types include multiple types of personally identifiable information (PII), 
financial data, and credentials data. You can also use custom criteria that 
you define—regular expressions that define text patterns to match and, 
optionally, character sequences and proximity rules that refine the 
results.

If Macie detects sensitive data in an S3 object, Macie generates a security 
finding to notify you. This finding provides information about the affected 
object, the types and number of occurrences of the sensitive data that 
Macie found, and additional details to help you investigate the affected S3 
bucket and object. For more information, see the Amazon Macie User Guide
<https://docs.aws.amazon.com/macie/latest/user/what-is-macie.html> .",Created by Rules Engine,Recommended,Not tested,High,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1029 - Remote Data Storage,Cloud Security,NIST 800-53 v5,PM-24 Data Integrity Board
API Gateway,C-API-GATEWAY-CNT-04,Distributed gateway deployments should have a token translation (exchange) service between gateways,"To facilitate secure token exchange across distributed API gateways and 
prevent unauthorized access, the following steps should be taken:

   1. Implement OAuth 2.0 and OpenID Connect:
          o Set up OAuth 2.0 to handle secure token issuance and
            validation. This protocol will manage access according to user
            authentication and application privileges.
          o Incorporate OpenID Connect to provide an identity layer on top
            of OAuth 2.0 for user verification.
   2. Use JSON Web Tokens (JWT):
          o Configure the gateways to use JWTs as a compact, URL-safe means
            of representing claims to be transferred between two parties.
            This will enhance interoperability and speed of the token
            exchange.
          o Ensure all JWTs are signed and optionally encrypted. Use
            strong, up-to-date symmetric (HS256) or asymmetric (RS256)
            algorithms to secure token data.
   3. Secure Communication Channel:
          o Mandate TLS (Transport Layer Security) for all gateway
            communications. This will encrypt the data in transit, ensuring
            tokens cannot be intercepted by unauthorized parties.
   4. Token Expiration and Refresh:
          o Ensure that issued tokens have an expiration time to minimize
            the impact of a token being compromised.
          o Implement token refresh mechanisms to allow seamless renewal of
            tokens. Consider using refresh tokens with short expiration
            times for higher security.
   5. Distributed Trust and Key Management:
          o Establish a distributed trust model by designating key
            management infrastructure for token signing and validation
            across the gateways.
          o Implement automated key rotation policies and ensure that all
            nodes in the distributed gateway system are updated promptly to
            recognize new keys.
   6. Audit and Monitoring:
          o Integrate logging and auditing mechanisms to track token usage
            across the distributed gateways.
          o Use these logs to identify any unusual or unauthorized access
            patterns, which will help in timely detection and mitigation of
            security incidents.

Following these steps can help maintain the integrity, confidentiality, and 
availability of the API gateway system.

References

    * OAuth 2.0 Framework <https://oauth.net/2/>
    * OpenID Connect Introduction <https://openid.net/connect/>
    * Introduction to JSON Web Tokens <https://jwt.io/introduction>
    * RFC 5246: The Transport Layer Security (TLS) Protocol
      <https://tools.ietf.org/html/rfc5246>
    * RFC 7523: JSON Web Token (JWT) Profile for OAuth 2.0 Client
      Authentication and Authorization Grants
      <https://datatracker.ietf.org/doc/html/rfc7523>
    * Keycloak Server Administration Guide
      <https://www.keycloak.org/docs/latest/server_admin/>",Created by Rules Engine,Recommended,Not tested,High,N/A,High,Hugo Ponthieu,,ATT&CK Enterprise - M1026 - Privileged Account Management,Network Security,NIST 800-53 v5,SC-17 Public Key Infrastructure Certificates
"*.beep,ovh",C-DNS-TRAFFIC-ENCRYPTION,DNS Traffic Encryption,"Encrypting DNS traffic is essential to protect the integrity and 
confidentiality of DNS queries and responses from eavesdropping and 
man-in-the-middle attacks. By securing DNS transactions, organizations can 
prevent attackers from intercepting or manipulating DNS data, which is 
crucial for maintaining network security and user privacy.

Steps to Implement DNS Traffic Encryption

Assess Current DNS Configuration:

    * Review your existing DNS setup to identify which servers handle DNS
      queries and how they are configured.
    * Determine the types of data transmitted and identify potential risk
      points where data could be intercepted.

Choose Appropriate DNS Encryption Technologies:

    * Implement DNS over HTTPS (DoH): Encrypts DNS queries within the HTTPS
      protocol, providing confidentiality, integrity, and increased privacy
      by blending DNS traffic with regular web traffic.
    * Implement DNS over TLS (DoT): Secures DNS queries and responses using
      the TLS (Transport Layer Security) protocol, ensuring that DNS
      transactions are encrypted between the client and the DNS resolver.

Configure DNS Resolvers and Servers:

    * Update DNS resolvers to support DoH or DoT. Ensure that they are
      configured to communicate with upstream servers that also support
      these encryption protocols.
    * If operating your own DNS servers, enable and configure DoH or DoT.
      This may involve installing updates or additional software modules
      that support these protocols.

Update Client Configuration:

    * Configure client devices and applications to use encrypted DNS
      services. This can involve changing network settings to point to DNS
      servers that support DoH or DoT.
    * Provide guidance to users on how to update their devices, or use
      network-wide settings to enforce DNS encryption.

Monitor and Validate Encryption:

    * After deployment, monitor DNS traffic to ensure that encryption is
      being applied correctly and consistently.
    * Use network monitoring tools to check that no plain DNS traffic is
      leaking outside the encrypted channels.

Create a Rollout and Incident Response Plan:

    * Develop a phased rollout plan to gradually implement DNS encryption
      across your network, starting with critical areas and expanding
      coverage as stability is confirmed.
    * Prepare an incident response plan specifically for issues related to
      DNS encryption, such as misconfigurations or performance impacts.

Educate and Train IT Staff:

    * Train IT staff on the importance of DNS encryption and the specific
      technologies used (DoH, DoT).
    * Provide technical resources and training to help troubleshoot and
      manage encrypted DNS traffic.

Regularly Update and Patch:

    * Keep DNS software, including servers and clients, regularly updated
      to protect against vulnerabilities that could undermine the
      encryption.
    * Stay informed about new developments in DNS encryption standards and
      practices.

Good Security Practices Reference

    * Adhere to best practices from authoritative bodies such as the
      Internet Engineering Task Force (IETF) that develops standards like
      DoH and DoT.
    * Consider guidelines from cybersecurity organizations, such as the
      National Institute of Standards and Technology (NIST), for
      implementing secure DNS practices.

By implementing these steps, developers and IT administrators can 
effectively encrypt DNS traffic, enhancing security and privacy for all 
network communications. This helps prevent attackers from gaining access to 
critical information or manipulating DNS responses to direct users to 
malicious sites.",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Hugo Ponthieu,,ATT&CK Enterprise - M1041 - Encrypt Sensitive Information,Data Security||Network Security,NIST 800-53 v5,SC-13 Cryptographic Protection||SC-8 TRANSMISSION CONFIDENTIALITY AND INTEGRITY||SI-4 System Monitoring
AWS S3 (Simple Storage Service),C-AWS-S3-CNT-11,Enable Amazon S3 server access logging,"Server access logging provides detailed records of the requests that are 
made to a bucket. Server access logs can assist you in security and access 
audits, help you learn about your customer base, and understand your Amazon 
S3 bill. For instructions on enabling server access logging, see Logging 
requests with server access logging
<https://docs.aws.amazon.com/AmazonS3/latest/userguide/ServerLogs.html> .

Also consider implementing ongoing detective controls by using the 
s3-bucket-logging-enabled
<https://docs.aws.amazon.com/config/latest/developerguide/s3-bucket-logging-enabled.html> 
AWS Config managed rule.",Created by Rules Engine,Recommended,Not tested,High,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1047 - Audit,Data Security,NIST 800-53 v5,AU-12 Audit Record Generation
AWS S3 (Simple Storage Service),C-AWS-S3-CNT-13,Enable AWS Config,"Several of the best practices listed in this topic suggest creating AWS 
Config rules. AWS Config helps you to assess, audit, and evaluate the 
configurations of your AWS resources. AWS Config monitors resource 
configurations so that you can evaluate the recorded configurations against 
the desired secure configurations. With AWS Config, you can do the 
following:

    * Review changes in configurations and relationships between AWS
      resources
    * Investigate detailed resource-configuration histories
    * Determine your overall compliance against the configurations
      specified in your internal guidelines

Using AWS Config can help you simplify compliance auditing, security 
analysis, change management, and operational troubleshooting. For more 
information, see Setting Up AWS Config with the Console
<https://docs.aws.amazon.com/config/latest/developerguide/gs-console.html> 
in the AWS Config Developer Guide. When specifying the resource types to 
record, ensure that you include Amazon S3 resources.

     Important

     AWS Config managed rules only supports general purpose buckets when
     evaluating Amazon S3 resources. AWS Config doesn’t record
     configuration changes for directory buckets. For more information, see 
     AWS Config Managed Rules
     <https://docs.aws.amazon.com/config/latest/developerguide/evaluate-config_use-managed-rules.html> 
     and List of AWS Config Managed Rules
     <https://docs.aws.amazon.com/config/latest/developerguide/managed-rules-by-aws-config.html> 
     in the AWS Config Developer Guide.

For an example of how to use AWS Config, see How to Use AWS Config to 
Monitor for and Respond to Amazon S3 Buckets Allowing Public Access
<https://aws.amazon.com/blogs/security/how-to-use-aws-config-to-monitor-for-and-respond-to-amazon-s3-buckets-allowing-public-access/> 
on the AWS Security Blog.",Created by Rules Engine,Recommended,Not tested,High,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1054 - Software Configuration,Cloud Security,NIST 800-53 v5,CM-8 System Component Inventory
Virtual Machine,C-VIRTUAL-MACHINE-CNT-03,Enable disk encryption for VMs and their storage,"To protect sensitive data stored on virtual machines, enable disk 
encryption for both the virtual machine (VM) disks and any attached 
storage. Disk encryption ensures that the data remains confidential and 
protected, even if the physical storage is compromised. This control should 
be applied to all VMs and storage volumes, both in on-premises environments 
and cloud-based infrastructures. Implement full-disk encryption using 
trusted encryption algorithms to prevent unauthorized access to data.

Steps to Implement:

   1. Enable disk encryption during the creation of VMs in cloud
      environments like AWS (EBS Encryption), Azure (Azure Disk
      Encryption), or VMware vSphere (VM Encryption).
   2. Ensure that encryption is applied to both primary VM disks and
      additional attached storage volumes.
   3. Use encryption tools provided by the cloud provider, such as
      Microsoft Azure's Azure Disk Encryption or AWS’s EBS volume
      encryption, which integrate seamlessly with the VM and storage
      management platforms.
   4. Regularly audit the encryption status of all VMs and storage volumes
      to ensure encryption is enabled.
   5. Store encryption keys securely using key management services like AWS
      KMS or Azure Key Vault to prevent unauthorized access.

References:

    * Microsoft Azure - Disk Encryption
      <https://learn.microsoft.com/en-us/azure/virtual-machines/windows/encrypt-disks>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Hugo Ponthieu,,ATT&CK Enterprise - M1041 - Encrypt Sensitive Information,Cloud Security,NIST 800-53 v5,SC-28 PROTECTION OF INFORMATION AT REST
VPN (Virtual Private Network),C-VPN-VIRTUAL-PRIVATE-NETWORK-CNT-05,Enable logging for VPN activity and monitor regularly to detect and respond to suspicious behavior,"Configure comprehensive logging for all VPN activity and establish 
processes to monitor logs regularly. This ensures that suspicious behavior 
can be promptly detected and addressed, enhancing the overall security 
posture of the VPN and the network.

Enable Comprehensive VPN Logging:

    * Configure the VPN server to log all activity, including user
      authentication, connection attempts, session durations, and data
      transfers.
    * Ensure logs capture sufficient detail, such as IP addresses,
      timestamps, and user identifiers, for effective analysis.

Centralize Log Management:

    * Forward VPN logs to a centralized logging solution or Security
      Information and Event Management (SIEM) system, such as Splunk,
      Elastic Stack, or AWS CloudWatch.
    * Enable log correlation with other network components to identify
      patterns indicative of threats.

Define Monitoring Processes:

    * Set up alerts for unusual VPN activity, such as multiple failed login
      attempts, connections from unusual locations, or abnormal session
      durations.
    * Assign responsibility to a security team or automated systems for
      continuous log review.

Analyze and Respond to Incidents:

    * Investigate alerts and anomalies promptly to determine the root cause
      and take appropriate action.
    * Implement automated responses, such as blocking suspicious IPs or
      disabling compromised accounts, to contain potential threats.

Retain Logs for Compliance and Forensics:

    * Store logs securely for a defined retention period to meet compliance
      requirements and support forensic investigations.
    * Use encryption to protect log data and restrict access to authorized
      personnel.

Regularly Audit Logging Configurations:

    * Periodically review and update logging settings to ensure all
      critical VPN events are captured.
    * Test monitoring tools and alert configurations to confirm they are
      functioning correctly.

By enabling and monitoring VPN logs, developers and DevOps engineers can 
proactively detect and respond to threats, ensuring the VPN remains secure 
and operational.

References:

    * NIST Guide to Security Log Management
      <https://csrc.nist.gov/publications/detail/sp/800-92/final>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Hugo Ponthieu,,ATT&CK Enterprise - M1047 - Audit,Network Security,NIST 800-53 v5,AU-12 Audit Record Generation
AWS S3 (Simple Storage Service),C-AWS-S3-CNT-09,Enable S3 versioning,"S3 Versioning is a means of keeping multiple variants of an object in the 
same bucket. You can use versioning to preserve, retrieve, and restore 
every version of every object stored in your bucket. With versioning, you 
can easily recover from both unintended user actions and application 
failures.

Also consider implementing ongoing detective controls by using the 
s3-bucket-versioning-enabled
<https://docs.aws.amazon.com/config/latest/developerguide/s3-bucket-versioning-enabled.html> 
managed AWS Config rule.

For more information, see Using versioning in S3 buckets
<https://docs.aws.amazon.com/AmazonS3/latest/userguide/Versioning.html> .",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1053 - Data Backup,Cloud Security,NIST 800-53 v5,CP-9 System Backup
AWS S3 (Simple Storage Service),C-AWS-S3-CNT-07,Enforce encryption of data in transit,"You can use HTTPS (TLS) to help prevent potential attackers from 
eavesdropping on or manipulating network traffic by using 
person-in-the-middle or similar attacks. We recommend allowing only 
encrypted connections over HTTPS (TLS) by using the aws:SecureTransport
<https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_elements_condition_operators.html#Conditions_Boolean> 
condition in your Amazon S3 bucket policies.

Important

We recommend that your application not pin Amazon S3 TLS certificates as 
AWS doesn’t support pinning of publicly-trusted certificates. S3 
automatically renews certificates and renewal can happen any time before 
certificate expiry. Renewing a certificate generates a new public-private 
key pair. If you’ve pinned an S3 certificate which has been recently 
renewed with a new public key, you won’t be able to connect to S3 until 
your application uses the new certificate.

Also consider implementing ongoing detective controls by using the 
s3-bucket-ssl-requests-only
<https://docs.aws.amazon.com/config/latest/developerguide/s3-bucket-ssl-requests-only.html> 
managed AWS Config rule.",Created by Rules Engine,Recommended,Not tested,High,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1041 - Encrypt Sensitive Information,Data Security,NIST 800-53 v5,SC-8 TRANSMISSION CONFIDENTIALITY AND INTEGRITY
Backend,C-WEB-APPLICATION-SERVER-SIDE-CNT-02,"Enforce MFA, use secure cookies, and invalidate sessions","To enhance authentication security, enforce multi-factor authentication 
(MFA) for all users, particularly for accessing sensitive resources. Use 
secure cookies to store session information and ensure they are configured 
with proper flags (e.g., HttpOnly, Secure) to prevent unauthorized access. 
Additionally, implement session invalidation after logout or inactivity to 
minimize the risk of session hijacking or unauthorized access.

Implementation Steps:

   1. Enforce MFA: Configure MFA for all user accounts, requiring an
      additional verification step (e.g., SMS, authenticator app) beyond
      just username and password. This should be applied to all sensitive
      operations and accounts with high privileges.
   2. Use Secure Cookies: Set cookies with the Secure flag (to ensure they
      are only sent over HTTPS), HttpOnly flag (to prevent access via
      JavaScript), and SameSite flag (to restrict cross-site request
      behavior), ensuring session data is protected.
   3. Invalidate Sessions on Logout or Inactivity: Implement session
      expiration or timeouts for inactivity and invalidate user sessions
      upon logout to prevent session hijacking. Ensure that tokens are
      revoked immediately when no longer needed.
   4. Monitor Session Activity: Continuously monitor and review session
      activity to detect any unauthorized access attempts or suspicious
      session behavior.

References:

    * OWASP Authentication Cheat Sheet
      <https://cheatsheetseries.owasp.org/cheatsheets/Authentication_Cheat_Sheet.html>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1056 - Pre-compromise,Application Security,NIST 800-53 v5,IA-9 Service Identification and Authentication
Fronend,C-WEB-APPLICATION-SERVER-SIDE-CNT-02,"Enforce MFA, use secure cookies, and invalidate sessions","To enhance authentication security, enforce multi-factor authentication 
(MFA) for all users, particularly for accessing sensitive resources. Use 
secure cookies to store session information and ensure they are configured 
with proper flags (e.g., HttpOnly, Secure) to prevent unauthorized access. 
Additionally, implement session invalidation after logout or inactivity to 
minimize the risk of session hijacking or unauthorized access.

Implementation Steps:

   1. Enforce MFA: Configure MFA for all user accounts, requiring an
      additional verification step (e.g., SMS, authenticator app) beyond
      just username and password. This should be applied to all sensitive
      operations and accounts with high privileges.
   2. Use Secure Cookies: Set cookies with the Secure flag (to ensure they
      are only sent over HTTPS), HttpOnly flag (to prevent access via
      JavaScript), and SameSite flag (to restrict cross-site request
      behavior), ensuring session data is protected.
   3. Invalidate Sessions on Logout or Inactivity: Implement session
      expiration or timeouts for inactivity and invalidate user sessions
      upon logout to prevent session hijacking. Ensure that tokens are
      revoked immediately when no longer needed.
   4. Monitor Session Activity: Continuously monitor and review session
      activity to detect any unauthorized access attempts or suspicious
      session behavior.

References:

    * OWASP Authentication Cheat Sheet
      <https://cheatsheetseries.owasp.org/cheatsheets/Authentication_Cheat_Sheet.html>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1056 - Pre-compromise,Application Security,NIST 800-53 v5,IA-9 Service Identification and Authentication
Bare Metal Server,C-BARE-METAL-SERVER-CNT-02,Enforce physical security controls,"To ensure that bare metal servers are physically secure from unauthorized 
access, a robust set of measures should be implemented. Each step outlined 
below will guide the deployment of a comprehensive physical security system 
which significantly mitigates the risk of unauthorized access to your 
server infrastructure.

   1. Assess the Physical Environment: Begin by thoroughly evaluating the
      current physical security infrastructure. Identify potential
      vulnerabilities around entry points, windows, or areas that may be
      susceptible to unauthorized access.
   2. Install Biometric Access Systems: Deploy biometric access systems at
      all primary entry points. Biometric systems, such as fingerprint or
      retina scanners, ensure that only authorized personnel with
      registered biometrics can gain entry.
          o Investigate compatible biometric systems that integrate
            seamlessly with existing security infrastructure.
          o Set up a database to manage and store biometric data securely,
            adhering to applicable privacy regulations.
   3. Implement Secure Key Card Systems: Establish a secure key card entry
      system to further control access. This system should have an access
      control server to manage permissions and monitor entry attempts in
      real-time.
          o Issue individual key cards to authorized personnel only, with
            levels of access controlled as needed.
          o Regularly audit access logs to ensure compliance and security
            integrity.
   4. Set Up 24/7 Surveillance: Install surveillance cameras at strategic
      locations to ensure constant monitoring of entry points and sensitive
      areas within the facility.
          o Choose cameras with night vision and motion detection
            capabilities to enhance surveillance efficiency.
          o Ensure that footage is securely stored and only accessible to
            authorized security personnel.
   5. Regular Security Drills and Training: Conduct regular security drills
      to familiarize staff with security protocols. Training should include
      recognizing and reporting suspicious behavior, and how to respond to
      security breaches.

References

    * The Ultimate Guide to Physical Security
      <https://www.lenels2.com/en/news/insights/the-ultimate-guide-to-physical-security.html>",Created by Rules Engine,Recommended,Not tested,High,N/A,High,Hugo Ponthieu,,EMB3D - MID-031 - Physical Presence Validation,Physical Security,NIST 800-53 v5,PE-2 Physical Access Authorizations
Bare Metal Server,C-BARE-METAL-SERVER-CNT-02,Enforce physical security controls,"To ensure that bare metal servers are physically secure from unauthorized 
access, a robust set of measures should be implemented. Each step outlined 
below will guide the deployment of a comprehensive physical security system 
which significantly mitigates the risk of unauthorized access to your 
server infrastructure.

   1. Assess the Physical Environment: Begin by thoroughly evaluating the
      current physical security infrastructure. Identify potential
      vulnerabilities around entry points, windows, or areas that may be
      susceptible to unauthorized access.
   2. Install Biometric Access Systems: Deploy biometric access systems at
      all primary entry points. Biometric systems, such as fingerprint or
      retina scanners, ensure that only authorized personnel with
      registered biometrics can gain entry.
          o Investigate compatible biometric systems that integrate
            seamlessly with existing security infrastructure.
          o Set up a database to manage and store biometric data securely,
            adhering to applicable privacy regulations.
   3. Implement Secure Key Card Systems: Establish a secure key card entry
      system to further control access. This system should have an access
      control server to manage permissions and monitor entry attempts in
      real-time.
          o Issue individual key cards to authorized personnel only, with
            levels of access controlled as needed.
          o Regularly audit access logs to ensure compliance and security
            integrity.
   4. Set Up 24/7 Surveillance: Install surveillance cameras at strategic
      locations to ensure constant monitoring of entry points and sensitive
      areas within the facility.
          o Choose cameras with night vision and motion detection
            capabilities to enhance surveillance efficiency.
          o Ensure that footage is securely stored and only accessible to
            authorized security personnel.
   5. Regular Security Drills and Training: Conduct regular security drills
      to familiarize staff with security protocols. Training should include
      recognizing and reporting suspicious behavior, and how to respond to
      security breaches.

References

    * The Ultimate Guide to Physical Security
      <https://www.lenels2.com/en/news/insights/the-ultimate-guide-to-physical-security.html>",Created by Rules Engine,Recommended,Not tested,High,N/A,High,Hugo Ponthieu,,EMB3D - MID-031 - Physical Presence Validation,Physical Security,NIST 800-53 v5,PE-2 Physical Access Authorizations
Kubernetes Namespace,C-KUBERNETES-NAMESPACE-02,Enforce Resource Quotas and Limits within Namespaces,"Set resource quotas and limits within each namespace to prevent any single 
user or application from consuming excessive resources.

1. Define resource quotas for CPU, memory, and storage for each namespace.

2. Enforce limits on the number of objects (e.g., pods, services) that can 
be created within a namespace.

3. Implement monitoring to alert on namespace resource usage approaching 
defined limits.

4. Regularly review and adjust quotas based on usage patterns and 
organizational needs.",Created by Rules Engine,Recommended,Not tested,High,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1052 - User Account Control,Cloud Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
PostgreSQL,C-POSTGRESQL-CNT-POSTGRES-06,Enforce secure file permissions on PostgreSQL database files,"Implement and regularly update strict file system permissions for 
PostgreSQL database files to ensure that only authorized users and 
processes can access or modify them. This control minimizes the risk of 
unauthorized data tampering and exposure by using OS-level security 
settings (such as chmod/chown on Linux) to restrict access to sensitive 
files. Developers and DevOps engineers should integrate these practices 
into their deployment procedures, using centralized configuration 
management tools to enforce and monitor secure file permissions across all 
database servers.

References:

    * OWASP Secure Coding Practices - Access Control
      <https://owasp.org/www-project-secure-coding-practices-quick-reference-guide/stable-en/02-checklist/05-checklist>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1022 - Restrict File and Directory Permissions,Data Security,NIST 800-53 v5,PT-2 Authority to Process Personally Identifiable Information
Virtual Machine,C-VIRTUAL-MACHINE-CNT-05,Enforce strict access controls and multi-factor authentication for VM migration and cloning,"To prevent unauthorized migration or cloning of virtual machines, enforce 
strict access controls and require multi-factor authentication (MFA) for 
all VM migration and cloning operations. Unauthorized cloning or migration 
of VMs can lead to data theft, service disruptions, or privilege 
escalation. Implement role-based access control (RBAC) to ensure only 
authorized administrators can perform these actions.

Steps to Implement:

   1. Configure RBAC to restrict VM migration and cloning permissions to a
      limited set of trusted administrators.
   2. Require MFA for all privileged actions related to VM migration or
      cloning to prevent unauthorized access.
   3. Enable logging and monitoring to track all VM migration and cloning
      activities.
   4. Implement approval workflows for any VM migration requests to prevent
      accidental or malicious actions.
   5. Regularly audit access policies and logs to detect and mitigate
      potential threats.

References:

    * VMware vSphere - Securing Virtual Machines
      <https://docs.vmware.com/en/VMware-vSphere/7.0/com.vmware.vsphere.security.doc/GUID-60025A18-8FCF-42D4-8E7A-BB6E14708787.html>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Hugo Ponthieu,,ATT&CK Enterprise - M1026 - Privileged Account Management,Network Security,NIST 800-53 v5,IA-2 Identification and Authentication (organizational Users)
VPN (Virtual Private Network),C-VPN-VIRTUAL-PRIVATE-NETWORK-CNT-01,Enforce the use of the latest secure TLS versions for VPN traffic encryption,"Ensure the VPN is configured to use the latest secure versions of Transport 
Layer Security (TLS), such as TLS 1.2 or TLS 1.3, to encrypt data traffic. 
This minimizes vulnerabilities, protects against eavesdropping, and ensures 
compliance with modern security standards. Follow these implementation 
steps:

Verify Supported TLS Versions:

    * Check the VPN software or appliance documentation to ensure it
      supports TLS 1.2 and TLS 1.3.
    * Disable older, insecure versions such as TLS 1.0 and TLS 1.1, which
      are susceptible to attacks like POODLE and BEAST.

Configure Encryption Settings:

    * Update the VPN server and client configurations to enforce the use of
      TLS 1.2 or higher for all encrypted communications.
    * Specify strong cipher suites, such as AES-GCM with a 256-bit key,
      while avoiding deprecated algorithms like RC4 or 3DES.

Test and Validate Configuration:

    * Use tools such as SSL Labs or OpenSSL to test the VPN's encryption
      setup and verify that only secure TLS versions and cipher suites are
      accepted.
    * Conduct regular vulnerability scans to identify and remediate any
      issues related to TLS settings.

Monitor and Maintain Security Standards:

    * Regularly review encryption settings to ensure they remain up to date
      with evolving standards.
    * Apply vendor patches and updates promptly to address potential
      vulnerabilities in TLS implementations.

By enforcing the use of secure TLS versions, developers and DevOps 
engineers can enhance the VPN’s resilience against attacks, protect 
sensitive data, and maintain the integrity of encrypted communications.

References:

    * TLS Best Practices with SSL/TLS <https://www.ssllabs.com/>",Created by Rules Engine,Recommended,Not tested,Very high,N/A,Medium,Hugo Ponthieu,,ATT&CK Enterprise - M1041 - Encrypt Sensitive Information,Network Security,NIST 800-53 v5,SC-8 TRANSMISSION CONFIDENTIALITY AND INTEGRITY
PostgreSQL,C-POSTGRESQL-CNT-POSTGRES-03,Enforce TLS encryption for all connections,"Implement and regularly update TLS encryption for all connections to 
PostgreSQL to secure data in transit against eavesdropping and 
man-in-the-middle attacks. This control mandates that all client-to-server 
and inter-node communications are encrypted using strong TLS protocols 
(e.g., TLS 1.2 or TLS 1.3) and that proper certificate management is in 
place. Developers and DevOps engineers should integrate TLS configuration 
into the PostgreSQL deployment process and enforce these settings via 
centralized management tools to maintain a secure network environment.

Implementation Steps:

Enable TLS Encryption:
Configure PostgreSQL to require TLS for all incoming connections by setting 
the appropriate parameters in the PostgreSQL configuration file (e.g., ssl 
= on).

Configure Strong Cipher Suites:
Ensure that only secure TLS versions and cipher suites (e.g., TLS 1.2/1.3) 
are enabled, and disable deprecated protocols to enhance the encryption 
strength.

Manage Certificates Securely:
Use a centralized certificate management system to issue, renew, and manage 
SSL/TLS certificates for PostgreSQL, ensuring that certificates are always 
up-to-date and trusted.

Monitor and Audit TLS Usage:
Regularly review logs and perform security audits to verify that all 
connections are using TLS encryption, and adjust configurations as 
necessary to address emerging threats.

References:

    * PostgreSQL SSL Support Documentation
      <https://www.postgresql.org/docs/current/ssl-tcp.html>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1041 - Encrypt Sensitive Information,Network Security,NIST 800-53 v5,SC-8 TRANSMISSION CONFIDENTIALITY AND INTEGRITY
Redis Server,C-REDIS-SERVER-CNT-REDIS-02,Enforce TLS encryption for all connections,"Implement and regularly update TLS encryption for all Redis connections to 
secure data in transit. This control ensures that every communication 
between Redis servers and clients is protected by robust TLS protocols, 
mitigating risks such as eavesdropping and man-in-the-middle attacks. 
Developers and DevOps engineers should integrate TLS configuration into the 
Redis deployment process, enforce strict cipher suites, and manage 
certificates through centralized tools to maintain compliance and enhance 
overall security.

Implementation Steps:

Enable TLS on Redis:
Configure Redis to require TLS for all client-server communications by 
setting appropriate configuration parameters in the Redis configuration 
file.

Configure Strong Cipher Suites:
Enforce the use of modern TLS versions (e.g., TLS 1.2/1.3) and disable 
deprecated protocols and weak cipher suites to ensure secure encryption.

Manage Certificates Securely:
Use a centralized certificate management system to issue, renew, and revoke 
certificates, ensuring that all certificates are up-to-date and properly 
validated.

Monitor and Audit TLS Usage:
Regularly review TLS logs and perform security audits to verify that 
encrypted connections are maintained and that any anomalies are promptly 
addressed.

References:

    * Redis Security Documentation
      <https://redis.io/docs/latest/operate/oss_and_stack/management/security/>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1041 - Encrypt Sensitive Information,Network Security,NIST 800-53 v5,SC-8 TRANSMISSION CONFIDENTIALITY AND INTEGRITY
VPN (Virtual Private Network),C-VPN-VIRTUAL-PRIVATE-NETWORK-CNT-07,Enforce up-to-date antivirus and endpoint protection for all VPN-connected devices,"Ensure that all devices connecting to the VPN are equipped with up-to-date 
antivirus and endpoint protection solutions. This practice minimizes the 
risk of malware infections and other security threats spreading to the VPN 
and organizational network.

Define Security Standards for Endpoints:

    * Require all devices to have antivirus and endpoint protection
      software installed, configured, and actively running.
    * Ensure these solutions are capable of real-time malware detection,
      prevention, and remediation.

Implement Compliance Checks:

    * Use network access control (NAC) or endpoint posture assessment tools
      to verify the presence and status of antivirus software before
      granting VPN access.
    * Block or quarantine devices that fail compliance checks until issues
      are resolved.

Ensure Regular Updates:

    * Configure endpoint protection tools to receive and apply virus
      definition updates and security patches automatically.
    * Periodically verify that updates are being applied to maintain
      protection against the latest threats.

Monitor and Enforce Compliance:

    * Continuously monitor connected devices for compliance with endpoint
      protection standards.
    * Generate alerts for non-compliant devices and restrict their VPN
      access if necessary.

Educate Users:

    * Provide training on the importance of antivirus software and endpoint
      security.
    * Encourage users to report issues with their security solutions
      promptly.

Integrate with Incident Response:

    * Establish processes to investigate and respond to security alerts
      generated by endpoint protection tools.
    * Correlate endpoint security incidents with VPN activity logs for
      comprehensive threat analysis.

By enforcing up-to-date antivirus and endpoint protection for all 
VPN-connected devices, developers and DevOps engineers can significantly 
reduce the risk of malware propagation and ensure the overall security of 
the VPN environment.

References:

    * NIST Endpoint Security Guidelines <https://csrc.nist.gov/>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Hugo Ponthieu,,ATT&CK Enterprise - M1050 - Exploit Protection,Network Security,NIST 800-53 v5,AC-17 Remote Access
Backend,C-WEB-APPLICATION-SERVER-SIDE-CNT-04,Ensure proper escaping/encoding of dynamic content and configure CSP,"To mitigate the risk of script injection attacks such as Cross-Site 
Scripting (XSS), ensure that all dynamic content in the web application is 
properly escaped or encoded before being rendered. This prevents malicious 
scripts from being executed in the user’s browser. Additionally, configure 
a Content Security Policy (CSP) to limit the sources of executable content, 
reducing the risk of inline script execution and script-based attacks.

Implementation Steps:

   1. Escape or Encode Dynamic Content: Ensure that any dynamic content
      included in web pages (e.g., user inputs, data from external sources)
      is properly escaped or encoded to prevent execution of potentially
      harmful scripts.
   2. Use CSP to Control Script Sources: Configure a strict Content
      Security Policy (CSP) to restrict which domains can serve executable
      content (e.g., scripts, styles). For example, disallow inline scripts
      and only allow scripts from trusted domains.
   3. Monitor and Update CSP: Regularly review and update the CSP to ensure
      it is correctly configured as new resources or third-party services
      are added to the application.
   4. Test for XSS Vulnerabilities: Conduct regular security testing to
      ensure that content is correctly sanitized and that the CSP is
      enforced.

References:

    * OWASP XSS Prevention Cheat Sheet
      <https://cheatsheetseries.owasp.org/cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1038 - Execution Prevention,Application Security,NIST 800-53 v5,SI-10 INFORMATION INPUT VALIDATION
Fronend,C-WEB-APPLICATION-SERVER-SIDE-CNT-04,Ensure proper escaping/encoding of dynamic content and configure CSP,"To mitigate the risk of script injection attacks such as Cross-Site 
Scripting (XSS), ensure that all dynamic content in the web application is 
properly escaped or encoded before being rendered. This prevents malicious 
scripts from being executed in the user’s browser. Additionally, configure 
a Content Security Policy (CSP) to limit the sources of executable content, 
reducing the risk of inline script execution and script-based attacks.

Implementation Steps:

   1. Escape or Encode Dynamic Content: Ensure that any dynamic content
      included in web pages (e.g., user inputs, data from external sources)
      is properly escaped or encoded to prevent execution of potentially
      harmful scripts.
   2. Use CSP to Control Script Sources: Configure a strict Content
      Security Policy (CSP) to restrict which domains can serve executable
      content (e.g., scripts, styles). For example, disallow inline scripts
      and only allow scripts from trusted domains.
   3. Monitor and Update CSP: Regularly review and update the CSP to ensure
      it is correctly configured as new resources or third-party services
      are added to the application.
   4. Test for XSS Vulnerabilities: Conduct regular security testing to
      ensure that content is correctly sanitized and that the CSP is
      enforced.

References:

    * OWASP XSS Prevention Cheat Sheet
      <https://cheatsheetseries.owasp.org/cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1038 - Execution Prevention,Application Security,NIST 800-53 v5,SI-10 INFORMATION INPUT VALIDATION
Kubernetes worker node (kubernetes-components),C-KUBERNETES-WORKER-NODE-CNT-23,Ensure that a limit is set on pod PIDs,"CIS Benchmark Recommendation id: 4.2.13
Profile Applicability: Level 1 - Worker Node

Description: Ensure that the Kubelet sets limits on the number of PIDs that 
can be created by pods running on the node.

Rationale: By default, pods running in a cluster can consume any number of 
PIDs, potentially exhausting the resources available on the node. Setting 
an appropriate limit reduces the risk of a denial of service attack on 
cluster nodes.

Impact: Setting this value will restrict the number of processes per pod. 
If this limit is lower than the number of PIDs required by a pod, it will 
not operate.

Audit: Review the Kubelet's start-up parameters for the value of 
--pod-max-pids, and check the Kubelet configuration file for the 
PodPidsLimit. If neither of these values is set, then there is no limit in 
place.

Remediation: Decide on an appropriate level for this parameter and set it, 
either via the --pod-maxpids command line parameter or the PodPidsLimit 
configuration file setting.

Default Value: By default, the number of PIDs is not limited.

References:

   1. 
      <https://kubernetes.io/docs/concepts/policy/pid-limiting/#pod-pid-limits>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1035 - Limit Access to Resource Over Network,Operational Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Cluster,C-KUBERNETES-CLUSTER-CNT-18,Ensure that all namespaces have network policies defined,"CIS Benchmark Recommendation id: 5.3.2

Profile Applicability: Level 2 - Master Node

Description: Use network policies to isolate traffic in your cluster 
network.

Rationale: Running different applications on the same Kubernetes cluster 
creates a risk of one compromised application attacking a neighboring 
application. Network segmentation is important to ensure that containers 
can communicate only with those they are supposed to. A network policy is a 
specification of how selections of pods are allowed to communicate with 
each other and other network endpoints. Network Policies are namespace 
scoped. When a network policy is introduced to a given namespace, all 
traffic not allowed by the policy is denied. However, if there are no 
network policies in a namespace all traffic will be allowed into and out of 
the pods in that namespace.

Impact: Once network policies are in use within a given namespace, traffic 
not explicitly allowed by a network policy will be denied. As such it is 
important to ensure that when introducing network policies, legitimate 
traffic is not blocked.

Audit: Run the below command and review the NetworkPolicy objects created 
in the cluster.

kubectl get networkpolicy --all-namespaces
Ensure that each namespace defined in the cluster has at least one Network 
Policy.

Remediation: Follow the documentation and create NetworkPolicy objects as 
you need them.

Default Value: By default, network policies are not created.

References:

   1. 
      <https://kubernetes.io/docs/concepts/services-networking/networkpolicies/>
   2. <https://octetz.com/posts/k8s-network-policy-apis>
   3. 
      <https://kubernetes.io/docs/tasks/configure-pod-container/declare-network-policy/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1030 - Network Segmentation,Network Security,NIST 800-53 v5,SC-7 Boundary Protection
Kubernetes Cluster,C-KUBERNETES-CLUSTER-CNT-19,Ensure that a minimal audit policy is created,"CIS Benchmark Recommendation id: 3.2.1
Profile Applicability: Level 1 - Master Node

Description: Kubernetes can audit the details of requests made to the API 
server. The --auditpolicy-file flag must be set for this logging to be 
enabled.
Rationale: Logging is an important detective control for all systems, to 
detect potential unauthorized access.
Impact: Audit logs will be created on the master nodes, which will consume 
disk space. Care should be taken to avoid generating too large volumes of 
log information as this could impact the availability of the cluster nodes.
Audit: Run the following command on one of the cluster master nodes: 

ps -ef | grep kube-apiserver
Verify that the --audit-policy-file is set. Review the contents of the file 
specified and ensure that it contains a valid audit policy.
Remediation: Create an audit policy file for your cluster.
Default Value: Unless the --audit-policy-file flag is specified, no 
auditing will be carried out.
References:

   1. <https://kubernetes.io/docs/tasks/debug-application-cluster/audit/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1047 - Audit,Application Security,NIST 800-53 v5,AU-12 Audit Record Generation
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-66,Ensure that a unique Certificate Authority is used for etcd,"CIS Benchmark Recommendation id: 2.7
Profile Applicability: Level 2 - Master Node

Description: Use a different certificate authority for etcd from the one 
used for Kubernetes.

Rationale: etcd is a highly available key-value store used by Kubernetes 
deployments for persistent storage of all of its REST API objects. Its 
access should be restricted to specifically designated clients and peers 
only. Authentication to etcd is based on whether the certificate presented 
was issued by a trusted certificate authority. There is no checking of 
certificate attributes such as common name or subject alternative name. As 
such, if any attackers were able to gain access to any certificate issued 
by the trusted certificate authority, they would be able to gain full 
access to the etcd database.

Impact: Additional management of the certificates and keys for the 
dedicated certificate authority will be required.

Audit: Review the CA used by the etcd environment and ensure that it does 
not match the CA certificate file used for the management of the overall 
Kubernetes cluster. Run the following command on the master node:

ps -ef | grep etcd

Note the file referenced by the --trusted-ca-file argument.

Run the following command on the master node:
ps -ef | grep apiserver

Verify that the file referenced by the --client-ca-file for apiserver is 
different from the --trusted-ca-file used by etcd.

Remediation: Follow the etcd documentation and create a dedicated 
certificate authority setup for the etcd service. Then, edit the etcd pod 
specification file /etc/kubernetes/manifests/etcd.yaml on the master node 
and set the below parameter.

--trusted-ca-file=</path/to/ca-file>

Default Value: By default, no etcd certificate is created and used.

References:

   1. <https://coreos.com/etcd/docs/latest/op-guide/security.html>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1025 - Privileged Process Integrity,Network Security,NIST 800-53 v5,SC-12 CRYPTOGRAPHIC KEY ESTABLISHMENT AND MANAGEMENT
Kubernetes Cluster,C-KUBERNETES-CLUSTER-CNT-15,Ensure that default service accounts are not actively used,"CIS Benchmark Recommendation id: 5.1.5

Profile Applicability: Level 1 - Master Node

Description: The default service account should not be used to ensure that 
rights granted to applications can be more easily audited and reviewed.

Rationale: Kubernetes provides a default service account which is used by 
cluster workloads where no specific service account is assigned to the pod. 
Where access to the Kubernetes API from a pod is required, a specific 
service account should be created for that pod, and rights granted to that 
service account. The default service account should be configured such that 
it does not provide a service account token and does not have any explicit 
rights assignments.

Impact: All workloads which require access to the Kubernetes API will 
require an explicit service account to be created.

Audit: For each namespace in the cluster, review the rights assigned to the 
default service account and ensure that it has no roles or cluster roles 
bound to it apart from the defaults. Additionally ensure that the 
automountServiceAccountToken: false setting is in place for each default 
service account.

Remediation: Create explicit service accounts wherever a Kubernetes 
workload requires specific access to the Kubernetes API server. Modify the 
configuration of each default service account to include this value 

automountServiceAccountToken: false

Default Value: By default the default service account allows for its 
service account token to be mounted in pods in its namespace.

References:

   1. 
      <https://kubernetes.io/docs/tasks/configure-pod-container/configure-serviceaccount/>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1021 - Restrict Web-Based Content,Cloud Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-49,Ensure that encryption providers are appropriately configured,"CIS Benchmark Recommendation id: 1.2.28
Profile Applicability: Level 1 - Master Node
Description: Where etcd encryption is used, appropriate providers should be 
configured.
Rationale: Where etcd encryption is used, it is important to ensure that 
the appropriate set of encryption providers is used. Currently, the aescbc, 
kms and secretbox are likely to be appropriate options.
Impact: None
Audit: Run the following command on the Control Plane node:

ps -ef | grep kube-apiserver

Get the EncryptionConfig file set for --encryption-provider-config 
argument. Verify that aescbc, kms or secretbox is set as the encryption 
provider for all the desired resources.
Remediation: Follow the Kubernetes documentation and configure a 
EncryptionConfig file. In this file, choose aescbc, kms or secretbox as the 
encryption provider.
Default Value: By default, no encryption provider is set.
References:

   1. <https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/>
   2. <https://acotten.com/post/kube17-security>
   3. <https://kubernetes.io/docs/admin/kube-apiserver/>
   4. <https://github.com/kubernetes/features/issues/92>
   5. 
      <https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/#providers>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1043 - Credential Access Protection,Data Security,NIST 800-53 v5,SC-28 PROTECTION OF INFORMATION AT REST
Kubernetes Cluster,C-KUBERNETES-CLUSTER-CNT-13,Ensure that Service Account Tokens are only mounted where necessary,"CIS Benchmark Recommendation id: 5.1.6

Profile Applicability: Level 1 - Master Node

Description: Service accounts tokens should not be mounted in pods except 
where the workload running in the pod explicitly needs to communicate with 
the API server Rationale: Mounting service account tokens inside pods can 
provide an avenue for privilege escalation attacks where an attacker is 
able to compromise a single pod in the cluster. Avoiding mounting these 
tokens removes this attack avenue. 

Impact: Pods mounted without service account tokens will not be able to 
communicate with the API server, except where the resource is available to 
unauthenticated principals. 

Audit: Review pod and service account objects in the cluster and ensure 
that the option below is set, unless the resource explicitly requires this 
access. 
automountServiceAccountToken: false 

Remediation: Modify the definition of pods and service accounts which do 
not need to mount service account tokens to disable it. 

Default Value: By default, all pods get a service account token mounted in 
them. 

References:

   1. 
      <https://kubernetes.io/docs/tasks/configure-pod-container/configure-serviceaccount/>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1043 - Credential Access Protection,Cloud Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-31,Ensure that the admission control plugin AlwaysAdmit is not set,"CIS Benchmark Recommendation id: 1.2.10
Profile Applicability: Level 1 - Master Node
Description: Do not allow all requests.
Rationale: Setting admission control plugin AlwaysAdmit allows all requests 
and do not filter any requests. The AlwaysAdmit admission controller was 
deprecated in Kubernetes v1.13. Its behavior was equivalent to turning off 
all admission controllers.
Impact: Only requests explicitly allowed by the admissions control plugins 
would be served.
Audit: Run the following command on the Control Plane node:
ps -ef | grep kube-apiserver
Verify that if the --enable-admission-plugins argument is set, its value 
does not include AlwaysAdmit.
Remediation: Edit the API server pod specification file 
/etc/kubernetes/manifests/kubeapiserver.yaml on the Control Plane node and 
either remove the --enable-admission-plugins parameter, or set it to a 
value that does not include AlwaysAdmit.
Default Value: AlwaysAdmit is not in the list of default admission plugins.
References:

   1. <https://kubernetes.io/docs/admin/kube-apiserver/>
   2. <https://kubernetes.io/docs/admin/admission-controllers/#alwaysadmit>",Created by Rules Engine,Recommended,Not tested,High,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1031 - Network Intrusion Prevention,Operational Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-32,Ensure that the admission control plugin AlwaysPullImages is set,"CIS Benchmark Recommendation id: 1.2.11
Profile Applicability: Level 1 - Master Node
Description: Always pull images.
Rationale: Setting admission control policy to AlwaysPullImages forces 
every new pod to pull the required images every time. In a multi-tenant 
cluster users can be assured that their private images can only be used by 
those who have the credentials to pull them. Without this admission control 
policy, once an image has been pulled to a node, any pod from any user can 
use it simply by knowing the image’s name, without any authorization check 
against the image ownership. When this plug-in is enabled, images are 
always pulled prior to starting containers, which means valid credentials 
are required.
Impact: Credentials would be required to pull the private images every 
time. Also, in trusted environments, this might increases load on network, 
registry, and decreases speed. This setting could impact offline or 
isolated clusters, which have images pre-loaded and do not have access to a 
registry to pull in-use images. This setting is not appropriate for 
clusters that use this configuration.
Audit: Run the following command on the Control Plane node:

ps -ef | grep kube-apiserver

Verify that the --enable-admission-plugins argument is set to a value that 
includes AlwaysPullImages.
Remediation: Edit the API server pod specification file 
/etc/kubernetes/manifests/kubeapiserver.yaml on the Control Plane node and 
set the --enable-admissionplugins parameter to include AlwaysPullImages.

--enable-admission-plugins=...,AlwaysPullImages,...
Default Value: By default, AlwaysPullImages is not set.
References:

   1. <https://kubernetes.io/docs/admin/kube-apiserver/>
   2. 
      <https://kubernetes.io/docs/admin/admission-controllers/#alwayspullimages>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1056 - Pre-compromise,Operational Security,NIST 800-53 v5,SC-7 Boundary Protection
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-30,Ensure that the admission control plugin EventRateLimit is set,"CIS Benchmark Recommendation id: 1.2.9
Profile Applicability: Level 1 - Master Node
Description: Limit the rate at which the API server accepts requests.
Rationale: Using EventRateLimit admission control enforces a limit on the 
number of events that the API Server will accept in a given time slice. A 
misbehaving workload could overwhelm and DoS the API Server, making it 
unavailable. This particularly applies to a multi-tenant cluster, where 
there might be a small percentage of misbehaving tenants which could have a 
significant impact on the performance of the cluster overall. Hence, it is 
recommended to limit the rate of events that the API server will accept.
Impact: You need to carefully tune in limits as per your environment.
Audit: Run the following command on the Control Plane node:

ps -ef | grep kube-apiserver

Verify that the --enable-admission-plugins argument is set to a value that 
includes EventRateLimit.
Remediation: Follow the Kubernetes documentation and set the desired limits 
in a configuration file. Then, edit the API server pod specification file 
/etc/kubernetes/manifests/kubeapiserver.yaml and set the below parameters.

--enable-admission-plugins=...,EventRateLimit,...

--admission-control-config-file=<path/to/configuration/file>
Default Value: By default, EventRateLimit is not set.
References:

   1. <https://kubernetes.io/docs/admin/kube-apiserver/>
   2. 
      <https://kubernetes.io/docs/admin/admission-controllers/#eventratelimit>
   3. 
      <https://github.com/staebler/community/blob/9873b632f4d99b5d99c38c9b15fe2f8b93d0a746/contributors/designproposals/admission_control_event_rate_limit.md>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1031 - Network Intrusion Prevention,Application Security,NIST 800-53 v5,SC-17 Public Key Infrastructure Certificates
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-34,Ensure that the admission control plugin NamespaceLifecycle is set,"CIS Benchmark Recommendation id: 1.2.13
Profile Applicability: Level 2 - Master Node
Description: Reject creating objects in a namespace that is undergoing 
termination.
Rationale: Setting admission control policy to NamespaceLifecycle ensures 
that objects cannot be created in non-existent namespaces, and that 
namespaces undergoing termination are not used for creating the new 
objects. This is recommended to enforce the integrity of the namespace 
termination process and also for the availability of the newer objects.
Impact: None
Audit: Run the following command on the Control Plane node:

ps -ef | grep kube-apiserver

Verify that the --disable-admission-plugins argument is set to a value that 
does not include NamespaceLifecycle.
Remediation: Edit the API server pod specification file 
/etc/kubernetes/manifests/kubeapiserver.yaml on the Control Plane node and 
set the --disable-admissionplugins parameter to ensure it does not include 
NamespaceLifecycle.
Default Value: By default, NamespaceLifecycle is set.
References:

   1. <https://kubernetes.io/docs/admin/kube-apiserver/>
   2. 
      <https://kubernetes.io/docs/admin/admission-controllers/#namespacelifecycle>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1048 - Application Isolation and Sandboxing,Operational Security,NIST 800-53 v5,AC-4 Information Flow Enforcement
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-35,Ensure that the admission control plugin NodeRestriction is set,"CIS Benchmark Recommendation id: 1.2.14
Profile Applicability: Level 2 - Master Node
Description: Limit the Node and Pod objects that a kubelet could modify.
Rationale: Using the NodeRestriction plug-in ensures that the kubelet is 
restricted to the Node and Pod objects that it could modify as defined. 
Such kubelets will only be allowed to modify their own Node API object, and 
only modify Pod API objects that are bound to their node.
Impact: None
Audit: Run the following command on the Control Plane node:

ps -ef | grep kube-apiserver

Verify that the --enable-admission-plugins argument is set to a value that 
includes NodeRestriction.
Remediation: Follow the Kubernetes documentation and configure 
NodeRestriction plug-in on kubelets. Then, edit the API server pod 
specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the 
master node and set the --enable-admission-plugins parameter to a value 
that includes NodeRestriction.

--enable-admission-plugins=...,NodeRestriction,...
Default Value: By default, NodeRestriction is not set.
References:

   1. <https://kubernetes.io/docs/admin/kube-apiserver/>
   2. 
      <https://kubernetes.io/docs/admin/admission-controllers/#noderestriction>
   3. <https://kubernetes.io/docs/admin/authorization/node/>
   4. <https://acotten.com/post/kube17-security>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1054 - Software Configuration,Operational Security,NIST 800-53 v5,SC-7 Boundary Protection
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-33,Ensure that the admission control plugin ServiceAccount is set,"CIS Benchmark Recommendation id: 1.2.12

Profile Applicability: Level 2 - Master Node

Description: Automate service accounts management.

Rationale: When you create a pod, if you do not specify a service account, 
it is automatically assigned the default service account in the same 
namespace. You should create your own service account and let the API 
server manage its security tokens.

Impact: None.

Audit: Run the following command on the Control Plane node:

ps -ef | grep kube-apiserver

Verify that the --disable-admission-plugins argument is set to a value that 
does not include ServiceAccount.

Remediation: Follow the documentation and create ServiceAccount objects as 
per your environment. Then, edit the API server pod specification file 
/etc/kubernetes/manifests/kube-apiserver.yaml on the master node and ensure 
that the --disable-admission-plugins parameter is set to a value that does 
not include ServiceAccount.

Default Value: By default, ServiceAccount is set.

References:

   1. <https://kubernetes.io/docs/admin/kube-apiserver/>
   2. 
      <https://kubernetes.io/docs/admin/admission-controllers/#serviceaccount>
   3. 
      <https://kubernetes.io/docs/tasks/configure-pod-container/configure-serviceaccount/>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1052 - User Account Control,Operational Security,NIST 800-53 v5,AC-2 ACCOUNT MANAGEMENT
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-22,Ensure that the --anonymous-auth argument is set to false,"CIS Benchmark Recommendation id: 1.2.1
Profile Applicability: Level 1 - Master Node
Description: Disable anonymous requests to the API server.
Rationale: When enabled, requests that are not rejected by other configured 
authentication methods are treated as anonymous requests. These requests 
are then served by the API server. You should rely on authentication to 
authorize access and disallow anonymous requests. If you are using RBAC 
authorization, it is generally considered reasonable to allow anonymous 
access to the API Server for health checks and discovery purposes, and 
hence this recommendation is not scored. However, you should consider 
whether anonymous discovery is an acceptable risk for your purposes.
Impact: Anonymous requests will be rejected.
Audit:

   1. Run the following command on the Control Plane node:
          o ps -ef | grep kube-apiserver
   2. Verify that the --anonymous-auth argument is set to false.
      Alternative Audit:
          o kubectl get pod -nkube-system -lcomponent=kube-apiserver
            -o=jsonpath='{range .items[]}{.spec.containers[].command}
            {""\n""}{end}' | grep '--anonymous-auth' | grep -i false
   3. If the exit code is '1', then the control isn't present / failed

Remediation:

Edit the API server pod specification file 
/etc/kubernetes/manifests/kubeapiserver.yaml on the Control Plane node and 
set the below parameter:

--anonymous-auth=false

References:

   1. <https://kubernetes.io/docs/admin/kube-apiserver/>
   2. <https://kubernetes.io/docs/admin/authentication/#anonymous-requests>",Created by Rules Engine,Recommended,Not tested,High,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1035 - Limit Access to Resource Over Network,Operational Security,NIST 800-53 v5,IA-9 Service Identification and Authentication
Kubernetes worker node (kubernetes-components),C-KUBERNETES-WORKER-NODE-CNT-11,Ensure that the --anonymous-auth argument is set to false,"CIS Benchmark Recommendation id: 4.2.1
Profile Applicability: Level 1 - Worker Node

Description: Disable anonymous requests to the Kubelet server.
Rationale: When enabled, requests that are not rejected by other configured 
authentication methods are treated as anonymous requests. These requests 
are then served by the Kubelet server. You should rely on authentication to 
authorize access and disallow anonymous requests.
Impact: Anonymous requests will be rejected.
Audit: If using a Kubelet configuration file, check that there is an entry 
for authentication: anonymous: enabled set to false. Run the following 
command on each node: 
ps -ef | grep kubelet
Verify that the --anonymous-auth argument is set to false. 

This executable argument may be omitted, provided there is a corresponding 
entry set to false in the Kubelet config file.
Remediation: If using a Kubelet config file, edit the file to set 
authentication: anonymous: enabled to false. If using executable arguments, 
edit the kubelet service file /etc/kubernetes/kubelet.conf on each worker 
node and set the below parameter in KUBELET_SYSTEM_PODS_ARGS variable. 
--anonymous-auth=false
Based on your system, restart the kubelet service. For example:
systemctl daemon-reload 

systemctl restart kubelet.service
Default Value: By default, anonymous access is enabled.
References:

   1. <https://kubernetes.io/docs/admin/kubelet/>
   2. 
      <https://kubernetes.io/docs/admin/kubelet-authentication-authorization/#kubeletauthentication>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1026 - Privileged Account Management,Application Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-50,Ensure that the API Server only makes use of Strong Cryptographic Ciphers,"CIS Benchmark Recommendation id: 1.2.29
Profile Applicability: Level 1 - Master Node
Description: Ensure that the API server is configured to only use strong 
cryptographic ciphers.
Rationale: TLS ciphers have had a number of known vulnerabilities and 
weaknesses, which can reduce the protection provided by them. By default 
Kubernetes supports a number of TLS ciphersuites including some that have 
security concerns, weakening the protection provided.
Impact: API server clients that cannot support modern cryptographic ciphers 
will not be able to make connections to the API server.
Audit: Run the following command on the Control Plane node:
ps -ef | grep kube-apiserver
Verify that the --tls-cipher-suites argument is set as outlined in the 
remediation procedure below.
Remediation: Edit the API server pod specification file 
/etc/kubernetes/manifests/kube-apiserver.yaml on the Control Plane node and 
set the below parameter.
--tls-cipher-suites=
TLS_AES_128_GCM_SHA256, TLS_AES_256_GCM_SHA384, 
TLS_CHACHA20_POLY1305_SHA256, TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA, 
TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256, 
TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA, 
TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384, 
TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305, 
TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256, 
TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA, TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256, 
TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA, TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384, 
TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305, 
TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256.
Default Value: By default the Kubernetes API server supports a wide range 
of TLS ciphers
References:

   1. 
      <https://kubernetes.io/docs/reference/command-line-tools-reference/kubeapiserver/>
   2. 
      <https://github.com/ssllabs/research/wiki/SSL-and-TLS-Deployment-BestPractices#23-use-secure-cipher-suites>

 ",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1043 - Credential Access Protection,Operational Security,NIST 800-53 v5,SC-13 Cryptographic Protection
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-02,Ensure that the API server pod specification file ownership is set to root:root,"CIS Benchmark Recommendation id: 1.1.2
Profile Applicability: Level 1 - Master Node
Description: Ensure that the API server pod specification file ownership is 
set to root:root.
Rationale: The API server pod specification file controls various 
parameters that set the behavior of the API server. You should set its file 
ownership to maintain the integrity of the file. The file should be owned 
by root:root.
Impact: None
Audit: Run the below command (based on the file location on your system) on 
the Control Plane node. For example,

stat -c %U:%G /etc/kubernetes/manifests/kube-apiserver.yaml

Verify that the ownership is set to root:root.
Remediation: Run the below command (based on the file location on your 
system) on the Control Plane node. For example,

chown root:root /etc/kubernetes/manifests/kube-apiserver.yaml
Default Value: By default, the kube-apiserver.yaml file ownership is set to 
root:root.
References:

   1. <https://kubernetes.io/docs/admin/kube-apiserver/>",Created by Rules Engine,Recommended,Not tested,High,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1022 - Restrict File and Directory Permissions,Operational Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-01,Ensure that the API server pod specification file permissions are set to 600 or more restrictive,"CIS Benchmark Recommendation id: 1.1.1
Profile Applicability: Level 1 - Master Node
Description: Ensure that the API server pod specification file has 
permissions of 600 or more restrictive.
Rationale: The API server pod specification file controls various 
parameters that set the behavior of the API server. You should restrict its 
file permissions to maintain the integrity of the file. The file should be 
writable by only the administrators on the system.
Impact: None
Audit: Run the below command (based on the file location on your system) on 
the Control Plane node. For example,

stat -c %a /etc/kubernetes/manifests/kube-apiserver.yaml
Verify that the permissions are 600 or more restrictive.
Remediation: Run the below command (based on the file location on your 
system) on the Control Plane node. For example,

chmod 600 /etc/kubernetes/manifests/kube-apiserver.yaml
Default Value: By default, the kube-apiserver.yaml file has permissions of 
640.
References:

   1. <https://kubernetes.io/docs/admin/kube-apiserver/>",Created by Rules Engine,Recommended,Not tested,High,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1022 - Restrict File and Directory Permissions,Operational Security,NIST 800-53 v5,CM-6 Configuration Settings
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-38,Ensure that the --audit-log-maxage argument is set to 30 or as appropriate,"CIS Benchmark Recommendation id: 1.2.17
Profile Applicability: Level 1 - Master Node
Description: Retain the logs for at least 30 days or as appropriate.
Rationale: Retaining logs for at least 30 days ensures that you can go back 
in time and investigate or correlate any events. Set your audit log 
retention period to 30 days or as per your business requirements.
Impact: None
Audit: Run the following command on the Control Plane node:
ps -ef | grep kube-apiserver
Verify that the --audit-log-maxage argument is set to 30 or as appropriate.
Remediation: Edit the API server pod specification file 
/etc/kubernetes/manifests/kubeapiserver.yaml on the Control Plane node and 
set the --audit-log-maxage parameter to 30 or as an appropriate number of 
days:
--audit-log-maxage=30
Default Value: By default, auditing is not enabled.
References:

   1. <https://kubernetes.io/docs/admin/kube-apiserver/>
   2. <https://kubernetes.io/docs/concepts/cluster-administration/audit/>
   3. <https://github.com/kubernetes/features/issues/22>",Created by Rules Engine,Recommended,Not tested,High,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1047 - Audit,Operational Security,NIST 800-53 v5,AU-11 Audit Record Retention
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-39,Ensure that the --audit-log-maxbackup argument is set to 10 or as appropriate,"CIS Benchmark Recommendation id: 1.2.18

Profile Applicability: Level 1 - Master Node

Description: Retain 10 or an appropriate number of old log files.

Rationale: Kubernetes automatically rotates the log files. Retaining old 
log files ensures that you would have sufficient log data available for 
carrying out any investigation or correlation. For example, if you have set 
file size of 100 MB and the number of old log files to keep as 10, you 
would approximate have 1 GB of log data that you could potentially use for 
your analysis.

Impact: None

Audit: Run the following command on the Control Plane node: 

ps -ef | grep kube-apiserver

Verify that the --audit-log-maxbackup argument is set to 10 or as 
appropriate.

Remediation: Edit the API server pod specification file 
/etc/kubernetes/manifests/kubeapiserver.yaml on the Control Plane node and 
set the --audit-log-maxbackup parameter to 10 or to an appropriate value. 

--audit-log-maxbackup=10

Default Value: By default, auditing is not enabled.

References:

   1. <https://kubernetes.io/docs/admin/kube-apiserver/>
   2. <https://kubernetes.io/docs/concepts/cluster-administration/audit/>
   3. <https://github.com/kubernetes/features/issues/22>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1053 - Data Backup,Operational Security,NIST 800-53 v5,AU-4 Audit Log Storage Capacity
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-40,Ensure that the --audit-log-maxsize argument is set to 100 or as appropriate,"CIS Benchmark Recommendation id: 1.2.19

Profile Applicability:  Level 1 - Master Node

Description: Rotate log files on reaching 100 MB or as appropriate.

Rationale: Kubernetes automatically rotates the log files. Retaining old 
log files ensures that you would have sufficient log data available for 
carrying out any investigation or correlation. If you have set file size of 
100 MB and the number of old log files to keep as 10, you would approximate 
have 1 GB of log data that you could potentially use for your analysis.

Impact: None

Audit: Run the following command on the Control Plane node: 

ps -ef | grep kube-apiserver
Verify that the --audit-log-maxsize argument is set to 100 or as 
appropriate.

Remediation: Edit the API server pod specification file 
/etc/kubernetes/manifests/kubeapiserver.yaml on the Control Plane node and 
set the --audit-log-maxsize parameter to an appropriate size in MB. For 
example, to set it as 100 MB: 

--audit-log-maxsize=100

Default Value: By default, auditing is not enabled.

References:

   1. <https://kubernetes.io/docs/admin/kube-apiserver/>
   2. <https://kubernetes.io/docs/concepts/cluster-administration/audit/>
   3. <https://github.com/kubernetes/features/issues/22>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1047 - Audit,Operational Security,NIST 800-53 v5,AU-9 Protection of Audit Information
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-37,Ensure that the --audit-log-path argument is set,"CIS Benchmark Recommendation id: 1.2.16

Profile Applicability: Level 1 - Master Node

Description: Enable auditing on the Kubernetes API Server and set the 
desired audit log path.

Rationale: Auditing the Kubernetes API Server provides a security-relevant 
chronological set of records documenting the sequence of activities that 
have affected the system by individual users, administrators, or other 
components of the system. Even though currently, Kubernetes provides only 
basic audit capabilities, it should be enabled. You can enable it by 
setting an appropriate audit log path.

Impact: None

Audit: Run the following command on the Control Plane node: 
ps -ef | grep kube-apiserver
Verify that the --audit-log-path argument is set as appropriate.

Remediation: Edit the API server pod specification file 
/etc/kubernetes/manifests/kubeapiserver.yaml on the Control Plane node and 
set the --audit-log-path parameter to a suitable path and file where you 
would like audit logs to be written, for example: 
--audit-log-path=/var/log/apiserver/audit.log

Default Value: By default, auditing is not enabled.

References:

   1. <https://kubernetes.io/docs/admin/kube-apiserver/>
   2. <https://kubernetes.io/docs/concepts/cluster-administration/audit/>
   3. <https://github.com/kubernetes/features/issues/22>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1047 - Audit,Operational Security,NIST 800-53 v5,AU-12 Audit Record Generation
Kubernetes Cluster,C-KUBERNETES-CLUSTER-CNT-20,Ensure that the audit policy covers key security concerns,"CIS Benchmark Recommendation id: 3.2.2
Profile Applicability: Level 2 - Master Node

Description: Ensure that the audit policy created for the cluster covers 
key security concerns.
Rationale: Security audit logs should cover access and modification of key 
resources in the cluster, to enable them to form an effective part of a 
security environment.
Impact: Increasing audit logging will consume resources on the nodes or 
other log destination.
Audit: Review the audit policy provided for the cluster and ensure that it 
covers at least the following areas:

    * Access to Secrets managed by the cluster. Care should be taken to
      only log Metadata for requests to Secrets, ConfigMaps, and
      TokenReviews, in order to avoid the risk of logging sensitive data.
    * Modification of pod and deployment objects. 
    * Use of pods/exec, pods/portforward, pods/proxy and services/proxy.

For most requests, minimally logging at the Metadata level is recommended 
(the most basic level of logging).
Remediation: Consider modification of the audit policy in use on the 
cluster to include these items, at a minimum.
Default Value: By default Kubernetes clusters do not log audit information.
References:

   1. 
      <https://github.com/k8scop/k8s-securitydashboard/blob/master/configs/kubernetes/adv-audit.yaml>
   2. 
      <https://kubernetes.io/docs/tasks/debug-application-cluster/audit/#audit-policy>
   3. 
      <https://github.com/falcosecurity/falco/blob/master/examples/k8s_audit_config/aud>
   4. 
      <https://github.com/kubernetes/kubernetes/blob/master/cluster/gce/gci/configurehelper.sh#L735>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1047 - Audit,Application Security,NIST 800-53 v5,AU-12 Audit Record Generation
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-28,Ensure that the --authorization-mode argument includes Node,"CIS Benchmark Recommendation id: 1.2.7

Profile Applicability: Level 1 - Master Node

Description: Restrict kubelet nodes to reading only objects associated with 
them.

Rationale: The Node authorization mode only allows kubelets to read Secret, 
ConfigMap, PersistentVolume, and PersistentVolumeClaim objects associated 
with their nodes.

Impact: None

Audit: Run the following command on the Control Plane node: 

ps -ef | grep kube-apiserver
Verify that the --authorization-mode argument exists and is set to a value 
to include Node.

Remediation: Edit the API server pod specification file 
/etc/kubernetes/manifests/kubeapiserver.yaml on the Control Plane node and 
set the --authorization-mode parameter to a value that includes Node.
--authorization-mode=Node,RBAC

Default Value: By default, Node authorization is not enabled.

References:

   1. <https://kubernetes.io/docs/admin/kube-apiserver/>
   2. <https://kubernetes.io/docs/admin/authorization/node/>
   3. <https://github.com/kubernetes/kubernetes/pull/46076>
   4. <https://acotten.com/post/kube17-security>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1054 - Software Configuration,Operational Security,NIST 800-53 v5,SC-17 Public Key Infrastructure Certificates
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-29,Ensure that the --authorization-mode argument includes RBAC,"CIS Benchmark Recommendation id: 1.2.8

Profile Applicability: Level 1 - Master Node

Description: Turn on Role Based Access Control.

Rationale: Role Based Access Control (RBAC) allows fine-grained control 
over the operations that different entities can perform on different 
objects in the cluster. It is recommended to use the RBAC authorization 
mode.

Impact: When RBAC is enabled you will need to ensure that appropriate RBAC 
settings (including Roles, RoleBindings and ClusterRoleBindings) are 
configured to allow appropriate access.

Audit: Run the following command on the Control Plane node:
ps -ef | grep kube-apiserver
Verify that the --authorization-mode argument exists and is set to a value 
to include RBAC.

Remediation: Edit the API server pod specification file 
/etc/kubernetes/manifests/kubeapiserver.yaml on the Control Plane node and 
set the --authorization-mode parameter to a value that includes RBAC, for 
example: 

--authorization-mode=Node,RBAC

Default Value: By default, RBAC authorization is not enabled.

References:

   1. <https://kubernetes.io/docs/reference/access-authn-authz/rbac/>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1026 - Privileged Account Management,Operational Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-27,Ensure that the --authorization-mode argument is not set to AlwaysAllow,"CIS Benchmark Recommendation id: 1.2.6

Profile Applicability: Level 1 - Master Node

Description: Do not always authorize all requests.

Rationale: The API Server, can be configured to allow all requests. This 
mode should not be used on any production cluster.

Impact: Only authorized requests will be served.

Audit: Run the following command on the Control Plane node: 
ps -ef | grep kube-apiserver

Verify that the --authorization-mode argument exists and is not set to 
AlwaysAllow.

Remediation: Edit the API server pod specification file 
/etc/kubernetes/manifests/kubeapiserver.yaml on the Control Plane node and 
set the --authorization-mode parameter to values other than AlwaysAllow. 
One such example could be as below. 
--authorization-mode=RBAC

Default Value: By default, AlwaysAllow is not enabled.

References:

   1. <https://kubernetes.io/docs/admin/kube-apiserver/>
   2. <https://kubernetes.io/docs/admin/authorization/>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1021 - Restrict Web-Based Content,Operational Security,NIST 800-53 v5,AC-3 ACCESS ENFORCEMENT
Kubernetes worker node (kubernetes-components),C-KUBERNETES-WORKER-NODE-CNT-12,Ensure that the --authorization-mode argument is not set to AlwaysAllow,"CIS Benchmark Recommendation id: 4.2.2

Profile Applicability: Level 1 - Worker Node

Description: Do not allow all requests. Enable explicit authorization.

Rationale: Kubelets, by default, allow all authenticated requests (even 
anonymous ones) without needing explicit authorization checks from the 
apiserver. You should restrict this behavior and only allow explicitly 
authorized requests.

Impact: Unauthorized requests will be denied.

Audit: Run the following command on each node: 

ps -ef | grep kubelet

If the --authorization-mode argument is present, check that it is not set 
to AlwaysAllow. If it is not present, check that there is a Kubelet config 
file specified by -config, and that file sets authorization: mode to 
something other than AlwaysAllow. It is also possible to review the running 
configuration of a Kubelet via the /configz endpoint on the Kubelet API 
port (typically 10250/TCP). Accessing these with appropriate credentials 
will provide details of the Kubelet's configuration.

Remediation: If using a Kubelet config file, edit the file to set 
authorization: mode to Webhook. If using executable arguments, edit the 
kubelet service file /etc/kubernetes/kubelet.conf on each worker node and 
set the below parameter in KUBELET_AUTHZ_ARGS variable. 

--authorization-mode=Webhook

Based on your system, restart the kubelet service. For example: 
systemctl daemon-reload
systemctl restart kubelet.service

Default Value: By default, --authorization-mode argument is set to 
AlwaysAllow.

References:

   1. <https://kubernetes.io/docs/admin/kubelet/>
   2. 
      <https://kubernetes.io/docs/admin/kubelet-authentication-authorization/#kubeletauthentication>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1025 - Privileged Process Integrity,Operational Security,NIST 800-53 v5,AC-3 ACCESS ENFORCEMENT
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-62,Ensure that the --auto-tls argument is not set to true,"CIS Benchmark Recommendation id: 2.3

Profile Applicability: Level 1 - Master Node
Description: Do not use self-signed certificates for TLS.
Rationale: etcd is a highly-available key value store used by Kubernetes 
deployments for persistent storage of all of its REST API objects. These 
objects are sensitive in nature and should not be available to 
unauthenticated clients. You should enable the client authentication via 
valid certificates to secure the access to the etcd service.
Impact: Clients will not be able to use self-signed certificates for TLS.
Audit: Run the following command on the etcd server node: 
ps -ef | grep etcd
Verify that if the --auto-tls argument exists, it is not set to true.
Remediation: Edit the etcd pod specification file 
/etc/kubernetes/manifests/etcd.yaml on the master node and either remove 
the --auto-tls parameter or set it to false.

--auto-tls=false
Default Value: By default, --auto-tls is set to false.
References:

   1. <https://coreos.com/etcd/docs/latest/op-guide/security.html>
   2. <https://kubernetes.io/docs/admin/etcd/>
   3. 
      <https://coreos.com/etcd/docs/latest/op-guide/configuration.html#auto-tls>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1054 - Software Configuration,Network Security,NIST 800-53 v5,SC-12 CRYPTOGRAPHIC KEY ESTABLISHMENT AND MANAGEMENT
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-57,Ensure that the --bind-address argument is set to 127.0.0.1 (Controller Manager),"CIS Benchmark Recommendation id: 1.3.7
Profile Applicability:  Level 1 - Master Node

Description: Do not bind the Controller Manager service to non-loopback 
insecure addresses.
Rationale: The Controller Manager API service which runs on port 10252/TCP 
by default is used for health and metrics information and is available 
without authentication or encryption. As such it should only be bound to a 
localhost interface, to minimize the cluster's attack surface
Impact: None
Audit: Run the following command on the Control Plane node: 

ps -ef | grep kube-controller-manager
Verify that the --bind-address argument is set to 127.0.0.1
Remediation: Edit the Controller Manager pod specification file 
/etc/kubernetes/manifests/kubecontroller-manager.yaml on the Control Plane 
node and ensure the correct value for the --bind-address parameter
Default Value: By default, the --bind-address parameter is set to 0.0.0.0
References:

   1. 
      <https://kubernetes.io/docs/reference/command-line-tools-reference/kubecontroller-manager/>",Created by Rules Engine,Recommended,Not tested,High,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1035 - Limit Access to Resource Over Network,Network Security,NIST 800-53 v5,AC-24 Access Control Decisions
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-59,Ensure that the --bind-address argument is set to 127.0.0.1 (Scheduler),"CIS Benchmark Recommendation id: 1.4.2

Profile Applicability: Level 1 - Master Node

Description: Do not bind the scheduler service to non-loopback insecure 
addresses.

Rationale: The Scheduler API service which runs on port 10251/TCP by 
default is used for health and metrics information and is available without 
authentication or encryption. As such it should only be bound to a 
localhost interface, to minimize the cluster's attack surface.

Impact: None

Audit: Run the following command on the Control Plane node:
ps -ef | grep kube-scheduler
Verify that the --bind-address argument is set to 127.0.0.1

Remediation: Edit the Scheduler pod specification file 
/etc/kubernetes/manifests/kubescheduler.yaml on the Control Plane node and 
ensure the correct value for the --bind-address parameter.

Default Value: By default, the --bind-address parameter is set to 0.0.0.0

References:

   1. 
      <https://kubernetes.io/docs/reference/command-line-tools-reference/kubescheduler/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1035 - Limit Access to Resource Over Network,Network Security,NIST 800-53 v5,SC-7 Boundary Protection
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-60,Ensure that the --cert-file and --key-file arguments are set as appropriate,"CIS Benchmark Recommendation id: 2.1

Profile Applicability: Level 1 - Master Node

Description: Configure TLS encryption for the etcd service.

Rationale: etcd is a highly-available key value store used by Kubernetes 
deployments for persistent storage of all of its REST API objects. These 
objects are sensitive in nature and should be encrypted in transit.

Impact: Client connections only over TLS would be served.

Audit: Run the following command on the etcd server node: 
ps -ef | grep etcd

Verify that the --cert-file and the --key-file arguments are set as 
appropriate.

Remediation: Follow the etcd service documentation and configure TLS 
encryption. Then, edit the etcd pod specification file 
/etc/kubernetes/manifests/etcd.yaml on the master node and set the below 
parameters. 
--cert-file=<path/to/ca-file> 
--key-file=<path/to/key-file>

Default Value: By default, TLS encryption is not set.

References:

   1. <https://coreos.com/etcd/docs/latest/op-guide/security.html>
   2. <https://kubernetes.io/docs/admin/etcd/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1054 - Software Configuration,Network Security,NIST 800-53 v5,SC-12 CRYPTOGRAPHIC KEY ESTABLISHMENT AND MANAGEMENT
Kubernetes worker node (kubernetes-components),C-KUBERNETES-WORKER-NODE-CNT-07,Ensure that the certificate authorities file permissions are set to 600 or more restrictive,"CIS Benchmark Recommendation id: 4.1.7
Profile Applicability: Level 1 - Worker Node 

Description: Ensure that the certificate authorities file has permissions 
of 600 or more restrictive.
Rationale: The certificate authorities file controls the authorities used 
to validate API requests. You should restrict its file permissions to 
maintain the integrity of the file. The file should be writable by only the 
administrators on the system.
Impact: None
Audit: Run the following command: 
ps -ef | grep kubelet

Find the file specified by the --client-ca-file argument. Run the following 
command: 
stat -c %a filename

Verify that the permissions are 644 or more restrictive.

Remediation: Run the following command to modify the file permissions of 
the --client-ca-file 

chmod 600 filename
Default Value: By default no --client-ca-file is specified.
References:

   1. <https://kubernetes.io/docs/admin/authentication/#x509-client-certs>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1022 - Restrict File and Directory Permissions,Operational Security,NIST 800-53 v5,CM-6 Configuration Settings
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-46,Ensure that the --client-ca-file argument is set as appropriate,"CIS Benchmark Recommendation id: 1.2.25
Profile Applicability: Level 1 - Master Node

Description: Setup TLS connection on the API server.
Rationale: API server communication contains sensitive parameters that 
should remain encrypted in transit. Configure the API server to serve only 
HTTPS traffic. If --client-ca-file argument is set, any request presenting 
a client certificate signed by one of the authorities in the client-ca-file 
is authenticated with an identity corresponding to the CommonName of the 
client certificate.
Impact: TLS and client certificate authentication must be configured for 
your Kubernetes cluster deployment.
Audit: Run the following command on the Control Plane node: 
ps -ef | grep kube-apiserver
Verify that the --client-ca-file argument exists and it is set as 
appropriate.
Remediation: Follow the Kubernetes documentation and set up the TLS 
connection on the apiserver. Then, edit the API server pod specification 
file /etc/kubernetes/manifests/kubeapiserver.yaml on the master node and 
set the client certificate authority file. 

--client-ca-file=<path/to/client-ca-file>
Default Value: By default, --client-ca-file argument is not set.
References:

   1. <https://kubernetes.io/docs/admin/kube-apiserver/>
   2. <http://rootsquash.com/2016/05/10/securing-the-kubernetes-api/>
   3. <https://github.com/kelseyhightower/docker-kubernetes-tls-guide>",Created by Rules Engine,Recommended,Not tested,High,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1054 - Software Configuration,Network Security,NIST 800-53 v5,SC-23 SESSION AUTHENTICITY
Kubernetes worker node (kubernetes-components),C-KUBERNETES-WORKER-NODE-CNT-13,Ensure that the --client-ca-file argument is set as appropriate,"CIS Benchmark Recommendation id: 4.2.3

Profile Applicability: Level 1 - Worker Node 

Description: Enable Kubelet authentication using certificates. 

Rationale: The connections from the apiserver to the kubelet are used for 
fetching logs for pods, attaching (through kubectl) to running pods, and 
using the kubelet’s port-forwarding functionality. These connections 
terminate at the kubelet’s HTTPS endpoint. By default, the apiserver does 
not verify the kubelet’s serving certificate, which makes the connection 
subject to man-in-the-middle attacks, and unsafe to run over untrusted 
and/or public networks. Enabling Kubelet certificate authentication ensures 
that the apiserver could authenticate the Kubelet before submitting any 
requests. 

Impact: You require TLS to be configured on apiserver as well as kubelets. 

Audit: Run the following command on each node: 
ps -ef | grep kubelet 
Verify that the --client-ca-file argument exists and is set to the location 
of the client certificate authority file. If the --client-ca-file argument 
is not present, check that there is a Kubelet config file specified by 
--config, and that the file sets authentication: x509: clientCAFile to the 
location of the client certificate authority file. Remediation: If using a 
Kubelet config file, edit the file to set authentication: x509: 
clientCAFile to the location of the client CA file. If using command line 
arguments, edit the kubelet service file /etc/kubernetes/kubelet.conf on 
each worker node and set the below parameter in KUBELET_AUTHZ_ARGS 
variable. 
--client-ca-file=path/to/client-ca-file
Based on your system, restart the kubelet service. For example: 
systemctl daemon-reload 
systemctl restart kubelet.service Default Value: By default, 
--client-ca-file argument is not set. 

References:

   1. <https://kubernetes.io/docs/admin/kubelet/>
   2. 
      <https://kubernetes.io/docs/reference/command-line-tools-reference/kubeletauthentication-authorization/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1054 - Software Configuration,Network Security,NIST 800-53 v5,SC-12 CRYPTOGRAPHIC KEY ESTABLISHMENT AND MANAGEMENT
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-61,Ensure that the --client-cert-auth argument is set to true,"CIS Benchmark Recommendation id: 2.2

Profile Applicability: • Level 1 - Master Node

Description: Enable client authentication on etcd service.

Rationale: etcd is a highly-available key value store used by Kubernetes 
deployments for persistent storage of all of its REST API objects. These 
objects are sensitive in nature and should not be available to 
unauthenticated clients. You should enable the client authentication via 
valid certificates to secure the access to the etcd service.

Impact: All clients attempting to access the etcd server will require a 
valid client certificate.

Audit: Run the following command on the etcd server node: 
ps -ef | grep etcd

Verify that the --client-cert-auth argument is set to true.

Remediation: Edit the etcd pod specification file 
/etc/kubernetes/manifests/etcd.yaml on the master node and set the below 
parameter.

--client-cert-auth=""true""

Default Value: By default, the etcd service can be queried by 
unauthenticated clients.

References:

   1. <https://coreos.com/etcd/docs/latest/op-guide/security.html>
   2. <https://kubernetes.io/docs/admin/etcd/>
   3. 
      <https://coreos.com/etcd/docs/latest/op-guide/configuration.html#client-cert-auth>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1054 - Software Configuration,Operational Security,NIST 800-53 v5,SC-17 Public Key Infrastructure Certificates
Kubernetes worker node (kubernetes-components),C-KUBERNETES-WORKER-NODE-CNT-08,Ensure that the client certificate authorities file ownership is set to root:root,"CIS Benchmark Recommendation id: 4.1.8

Profile Applicability: Level 1 - Worker Node

Description: Ensure that the certificate authorities file ownership is set 
to root:root.

Rationale: The certificate authorities file controls the authorities used 
to validate API requests. You should set its file ownership to maintain the 
integrity of the file. The file should be owned by root:root.

Impact: None

Audit: Run the following command:

ps -ef | grep kubelet
Find the file specified by the --client-ca-file argument.
stat -c %U:%G filename
Verify that the ownership is set to root:root.

Remediation: Run the following command to modify the ownership of the 
--client-ca-file. 

chown root:root filename

Default Value: By default no --client-ca-file is specified.

References:

   1. <https://kubernetes.io/docs/admin/authentication/#x509-client-certs>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1022 - Restrict File and Directory Permissions,Operational Security,NIST 800-53 v5,CM-6 Configuration Settings
Kubernetes Cluster,C-KUBERNETES-CLUSTER-CNT-07,Ensure that the cluster-admin role is only used where required,"CIS Benchmark Recommendation id: 5.1.1

Profile Applicability:  Level 1 - Master Node

Description: The RBAC role cluster-admin provides wide-ranging powers over 
the environment and should be used only where and when needed.

Rationale: Kubernetes provides a set of default roles where RBAC is used. 
Some of these roles such as cluster-admin provide wide-ranging privileges 
which should only be applied where absolutely necessary. Roles such as 
cluster-admin allow super-user access to perform any action on any 
resource. When used in a ClusterRoleBinding, it gives full control over 
every resource in the cluster and in all namespaces. When used in a 
RoleBinding, it gives full control over every resource in the role 
binding's namespace, including the namespace itself.

Impact: Care should be taken before removing any clusterrolebindings from 
the environment to ensure they were not required for the operation of the 
cluster. Specifically, modifications should not be made to 
clusterrolebindings with the system: prefix as they are required for the 
operation of system components.

Audit: Obtain a list of the principals who have access to the 
cluster-admin role by reviewing the clusterrolebinding output for each role 
binding that has access to the clusteradmin role.

kubectl get clusterrolebindings 
-o=customcolumns=NAME:.metadata.name,ROLE:.roleRef.name,SUBJECT:.subjects[*].name

Review each principal listed and ensure that cluster-admin privilege is 
required for it.

Remediation: Identify all clusterrolebindings to the cluster-admin role. 
Check if they are used and if they need this role or if they could use a 
role with fewer privileges. Where possible, first bind users to a lower 
privileged role and then remove the clusterrolebinding to the 
cluster-admin role:

kubectl delete clusterrolebinding [name]

Default Value: By default a single clusterrolebinding called cluster-admin 
is provided with the system:masters group as its principal.

References:

   1. 
      <https://kubernetes.io/docs/admin/authorization/rbac/#user-facing-roles>",Created by Rules Engine,Recommended,Not tested,High,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1026 - Privileged Account Management,Cloud Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Pod,C-KUBERNETES-POD-CNT-05,Ensure that the cluster has at least one active policy control mechanism in place,"CIS Benchmark Recommendation id: 5.2.1 
Profile Applicability: Level 1 - Master Node 

Description: Every Kubernetes cluster should have at least one policy 
control mechanism in place to enforce the other requirements in this 
section. This could be the in-built Pod Security Admission controller, or a 
third-party policy control system.

Rationale: Without an active policy control mechanism, it is not possible 
to limit the use of containers with access to underlying cluster nodes, via 
mechanisms like privileged containers, or the use of hostPath volume 
mounts.

Impact: Where policy control systems are in place, there is a risk that 
workloads required for the operation of the cluster may be stopped from 
running. Care is required when implementing admission control policies to 
ensure that this does not occur.

Audit: Review the workloads deployed to the cluster to understand if Pod 
Security Admission or external admission control systems are in place.

Remediation: Ensure that either Pod Security Admission or an external 
policy control system is in place for every namespace which contains user 
workloads.

Default Value: By default, Pod Security Admission is enabled but no 
policies are in place.

References:

   1. <https://kubernetes.io/docs/concepts/security/pod-security-admission>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1056 - Pre-compromise,Cloud Security,NIST 800-53 v5,SC-4 Information in Shared System Resources
Kubernetes Pod,C-KUBERNETES-POD-CNT-05,Ensure that the cluster has at least one active policy control mechanism in place,"CIS Benchmark Recommendation id: 5.2.1 
Profile Applicability: Level 1 - Master Node 

Description: Every Kubernetes cluster should have at least one policy 
control mechanism in place to enforce the other requirements in this 
section. This could be the in-built Pod Security Admission controller, or a 
third-party policy control system.

Rationale: Without an active policy control mechanism, it is not possible 
to limit the use of containers with access to underlying cluster nodes, via 
mechanisms like privileged containers, or the use of hostPath volume 
mounts.

Impact: Where policy control systems are in place, there is a risk that 
workloads required for the operation of the cluster may be stopped from 
running. Care is required when implementing admission control policies to 
ensure that this does not occur.

Audit: Review the workloads deployed to the cluster to understand if Pod 
Security Admission or external admission control systems are in place.

Remediation: Ensure that either Pod Security Admission or an external 
policy control system is in place for every namespace which contains user 
workloads.

Default Value: By default, Pod Security Admission is enabled but no 
policies are in place.

References:

   1. <https://kubernetes.io/docs/concepts/security/pod-security-admission>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1056 - Pre-compromise,Cloud Security,NIST 800-53 v5,SC-4 Information in Shared System Resources
Kubernetes Pod,C-KUBERNETES-POD-CNT-05,Ensure that the cluster has at least one active policy control mechanism in place,"CIS Benchmark Recommendation id: 5.2.1 
Profile Applicability: Level 1 - Master Node 

Description: Every Kubernetes cluster should have at least one policy 
control mechanism in place to enforce the other requirements in this 
section. This could be the in-built Pod Security Admission controller, or a 
third-party policy control system.

Rationale: Without an active policy control mechanism, it is not possible 
to limit the use of containers with access to underlying cluster nodes, via 
mechanisms like privileged containers, or the use of hostPath volume 
mounts.

Impact: Where policy control systems are in place, there is a risk that 
workloads required for the operation of the cluster may be stopped from 
running. Care is required when implementing admission control policies to 
ensure that this does not occur.

Audit: Review the workloads deployed to the cluster to understand if Pod 
Security Admission or external admission control systems are in place.

Remediation: Ensure that either Pod Security Admission or an external 
policy control system is in place for every namespace which contains user 
workloads.

Default Value: By default, Pod Security Admission is enabled but no 
policies are in place.

References:

   1. <https://kubernetes.io/docs/concepts/security/pod-security-admission>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1056 - Pre-compromise,Cloud Security,NIST 800-53 v5,SC-4 Information in Shared System Resources
Kubernetes Pod,C-KUBERNETES-POD-CNT-05,Ensure that the cluster has at least one active policy control mechanism in place,"CIS Benchmark Recommendation id: 5.2.1 
Profile Applicability: Level 1 - Master Node 

Description: Every Kubernetes cluster should have at least one policy 
control mechanism in place to enforce the other requirements in this 
section. This could be the in-built Pod Security Admission controller, or a 
third-party policy control system.

Rationale: Without an active policy control mechanism, it is not possible 
to limit the use of containers with access to underlying cluster nodes, via 
mechanisms like privileged containers, or the use of hostPath volume 
mounts.

Impact: Where policy control systems are in place, there is a risk that 
workloads required for the operation of the cluster may be stopped from 
running. Care is required when implementing admission control policies to 
ensure that this does not occur.

Audit: Review the workloads deployed to the cluster to understand if Pod 
Security Admission or external admission control systems are in place.

Remediation: Ensure that either Pod Security Admission or an external 
policy control system is in place for every namespace which contains user 
workloads.

Default Value: By default, Pod Security Admission is enabled but no 
policies are in place.

References:

   1. <https://kubernetes.io/docs/concepts/security/pod-security-admission>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1056 - Pre-compromise,Cloud Security,NIST 800-53 v5,SC-4 Information in Shared System Resources
Kubernetes Pod,C-KUBERNETES-POD-CNT-05,Ensure that the cluster has at least one active policy control mechanism in place,"CIS Benchmark Recommendation id: 5.2.1 
Profile Applicability: Level 1 - Master Node 

Description: Every Kubernetes cluster should have at least one policy 
control mechanism in place to enforce the other requirements in this 
section. This could be the in-built Pod Security Admission controller, or a 
third-party policy control system.

Rationale: Without an active policy control mechanism, it is not possible 
to limit the use of containers with access to underlying cluster nodes, via 
mechanisms like privileged containers, or the use of hostPath volume 
mounts.

Impact: Where policy control systems are in place, there is a risk that 
workloads required for the operation of the cluster may be stopped from 
running. Care is required when implementing admission control policies to 
ensure that this does not occur.

Audit: Review the workloads deployed to the cluster to understand if Pod 
Security Admission or external admission control systems are in place.

Remediation: Ensure that either Pod Security Admission or an external 
policy control system is in place for every namespace which contains user 
workloads.

Default Value: By default, Pod Security Admission is enabled but no 
policies are in place.

References:

   1. <https://kubernetes.io/docs/concepts/security/pod-security-admission>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1056 - Pre-compromise,Cloud Security,NIST 800-53 v5,SC-4 Information in Shared System Resources
Kubernetes Cluster,C-KUBERNETES-CLUSTER-CNT-17,Ensure that the CNI in use supports Network Policies,"CIS Benchmark Recommendation id: 5.3.1
Profile Applicability: Level 1 - Master Node

Description: There are a variety of CNI plugins available for Kubernetes. 
If the CNI in use does not support Network Policies it may not be possible 
to effectively restrict traffic in the cluster.
Rationale: Kubernetes network policies are enforced by the CNI plugin in 
use. As such it is important to ensure that the CNI plugin supports both 
Ingress and Egress network policies.
Impact: None
Audit: Review the documentation of CNI plugin in use by the cluster, and 
confirm that it supports Ingress and Egress network policies.
Remediation: If the CNI plugin in use does not support network policies, 
consideration should be given to making use of a different plugin, or 
finding an alternate mechanism for restricting traffic in the Kubernetes 
cluster.
Default Value: This will depend on the CNI plugin in use.
References:

   1. 
      <https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storagenet/network-plugins/>
   2. <https://github.com/coreos/flannel)>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1054 - Software Configuration,Network Security,NIST 800-53 v5,SC-7 Boundary Protection
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-10,Ensure that the Container Network Interface file ownership is set to root:root,"CIS Benchmark Recommendation id: 1.1.10
Profile Applicability: Level 1 - Master Node

Description: Ensure that the Container Network Interface files have 
ownership set to root:root.

Rationale: Container Network Interface provides various networking options 
for overlay networking. You should consult their documentation and restrict 
their respective file permissions to maintain the integrity of those files. 
Those files should be owned by root:root.

Impact: None

Audit: Run the below command (based on the file location on your system) on 
the Control Plane node. For example, 

stat -c %U:%G /path/to/cni/files

Verify that the ownership is set to root:root.

Remediation: Run the below command (based on the file location on your 
system) on the Control Plane node. For example, 

chown root:root /path/to/cni/files

Default Value: NA

References:

   1. 
      <https://kubernetes.io/docs/concepts/cluster-administration/networking/>",Created by Rules Engine,Recommended,Not tested,High,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1022 - Restrict File and Directory Permissions,Network Security,NIST 800-53 v5,"SI-7 Software, Firmware, and Information Integrity"
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-09,Ensure that the Container Network Interface file permissions are set to 600 or more restrictive,"CIS Benchmark Recommendation id: 1.1.9

Profile Applicability: Level 1 - Master Node

Description: Ensure that the Container Network Interface files have 
permissions of 600 or more restrictive.

Rationale: Container Network Interface provides various networking options 
for overlay networking. You should consult their documentation and restrict 
their respective file permissions to maintain the integrity of those files. 
Those files should be writable by only the administrators on the system.

Impact: None

Audit: Run the below command (based on the file location on your system) on 
the Control Plane node. For example, 

stat -c %a <path/to/cni/files>

Verify that the permissions are 600 or more restrictive.

Remediation: Run the below command (based on the file location on your 
system) on the Control Plane node. For example, 

chmod 600 <path/to/cni/files>

Default Value: NA

References:

   1. 
      <https://kubernetes.io/docs/concepts/cluster-administration/networking/>",Created by Rules Engine,Recommended,Not tested,High,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1022 - Restrict File and Directory Permissions,Operational Security,NIST 800-53 v5,CM-6 Configuration Settings
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-18,Ensure that the controller-manager.conf file ownership is set to root:root,"CIS Benchmark Recommendation id: 1.1.18 
Profile Applicability: Level 1 - Master Node

Description: Ensure that the controller-manager.conf file ownership is set 
to root:root. 
Rationale: The controller-manager.conf file is the kubeconfig file for the 
Controller Manager. You should set its file ownership to maintain the 
integrity of the file. The file should be owned by root:root. 
Impact: None 
Audit: Run the below command (based on the file location on your system) on 
the Control Plane node. For example, 

stat -c %U:%G /etc/kubernetes/controller-manager.conf 
Verify that the ownership is set to root:root. 
Remediation: Run the below command (based on the file location on your 
system) on the Control Plane node. For example, 

chown root:root /etc/kubernetes/controller-manager.conf 
Default Value: By default, controller-manager.conf file ownership is set to 
root:root. 
References:

   1. <https://kubernetes.io/docs/admin/kube-controller-manager/>",Created by Rules Engine,Recommended,Not tested,High,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1022 - Restrict File and Directory Permissions,Operational Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-17,Ensure that the controller-manager.conf file permissions are set to 600 or more restrictive,"CIS Benchmark Recommendation id: 1.1.17

Profile Applicability: Level 1 - Master Node

Description: Ensure that the controller-manager.conf file has permissions 
of 600 or more restrictive.

Rationale: The controller-manager.conf file is the kubeconfig file for the 
Controller Manager. You should restrict its file permissions to maintain 
the integrity of the file. The file should be writable by only the 
administrators on the system.

Impact: None

Audit: Run the following command (based on the file location on your 
system) on the Control Plane node. For example, 

stat -c %a /etc/kubernetes/controller-manager.conf

Verify that the permissions are 600 or more restrictive.

Remediation: Run the below command (based on the file location on your 
system) on the Control Plane node. For example, 

chmod 600 /etc/kubernetes/controller-manager.conf

Default Value: By default, controller-manager.conf has permissions of 640.

References:

   1. <https://kubernetes.io/docs/admin/kube-controller-manager/>",Created by Rules Engine,Recommended,Not tested,High,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1022 - Restrict File and Directory Permissions,Operational Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-04,Ensure that the controller manager pod specification file ownership is set to root:root,"CIS Benchmark Recommendation id: 1.1.4

Profile Applicability: Level 1 - Master Node

Description: Ensure that the controller manager pod specification file 
ownership is set to root:root.

Rationale: The controller manager pod specification file controls various 
parameters that set the behavior of various components of the master node. 
You should set its file ownership to maintain the integrity of the file. 
The file should be owned by root:root.

Impact: None

Audit: Run the below command (based on the file location on your system) on 
the Control Plane node. For example, 
stat -c %U:%G /etc/kubernetes/manifests/kube-controller-manager.yaml

Verify that the ownership is set to root:root.

Remediation: Run the below command (based on the file location on your 
system) on the Control Plane node. For example, 
chown root:root /etc/kubernetes/manifests/kube-controller-manager.yaml

Default Value: By default, kube-controller-manager.yaml file ownership is 
set to root:root.

References:

   1. <https://kubernetes.io/docs/admin/kube-controller-manager>",Created by Rules Engine,Recommended,Not tested,High,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1022 - Restrict File and Directory Permissions,Operational Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-03,Ensure that the controller manager pod specification file permissions are set to 600 or more restrictive,"CIS Benchmark Recommendation id: 1.1.3
Profile Applicability: Level 1 - Master Node
Description: Ensure that the controller manager pod specification file has 
permissions of 600 or more restrictive.
Rationale: The controller manager pod specification file controls various 
parameters that set the behavior of the Controller Manager on the master 
node. You should restrict its file permissions to maintain the integrity of 
the file. The file should be writable by only the administrators on the 
system.
Impact: None
Audit: Run the below command (based on the file location on your system) on 
the Control Plane node. For example,
stat -c %a /etc/kubernetes/manifests/kube-controller-manager.yaml
Verify that the permissions are 600 or more restrictive.
Remediation: Run the below command (based on the file location on your 
system) on the Control Plane node. For example,
chmod 600 /etc/kubernetes/manifests/kube-controller-manager.yaml
Default Value: By default, the kube-controller-manager.yaml file has 
permissions of 640.
References:

   1. <https://kubernetes.io/docs/admin/kube-apiserver/>",Created by Rules Engine,Recommended,Not tested,High,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1022 - Restrict File and Directory Permissions,Operational Security,NIST 800-53 v5,"SI-7 Software, Firmware, and Information Integrity"
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-14,Ensure that the default administrative credential file ownership is set to root:root,"CIS Benchmark Recommendation id: 1.1.14

Profile Applicability: Level 1 - Master Node

Description: Ensure that the admin.conf (and super-admin.conf file, where 
it exists) file ownership is set to root:root.

Rationale: As part of initial cluster setup, default kubeconfig files are 
created to be used by the administrator of the cluster. These files contain 
private keys and certificates which allow for privileged access to the 
cluster. You should set their file ownership to maintain the integrity and 
confidentiality of the file. The file(s) should be owned by root:root.

Impact: None.

Audit: Run the below command (based on the file location on your system) on 
the Control Plane node. For example, 

stat -c %U:%G /etc/kubernetes/admin.conf

On Kubernetes version 1.29 and higher run the following command as well: 

stat -c %U:%G /etc/kubernetes/super-admin.conf

Verify that the ownership is set to root:root.

Remediation: Run the below command (based on the file location on your 
system) on the Control Plane node. For example, 

chown root:root /etc/kubernetes/admin.conf

On Kubernetes 1.29+ the super-admin.conf file should also be modified, if 
present. For example, 

chown root:root /etc/kubernetes/super-admin.conf

Default Value: By default, admin.conf and super-admin.conf file ownership 
is set to root:root.

References:

    * <https://kubernetes.io/docs/admin/kubeadm/>
    * <https://raesene.github.io/blog/2024/01/06/when-is-admin-not-admin/>",Created by Rules Engine,Recommended,Not tested,High,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1022 - Restrict File and Directory Permissions,Operational Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-13,Ensure that the default administrative credential file permissions are set to 600,"CIS Benchmark Recommendation id: 1.1.13

Profile Applicability: Level 1 - Master Node

Description: Ensure that the admin.conf file (and super-admin.conf file, 
where it exists) have permissions of 600.

Rationale: As part of initial cluster setup, default kubeconfig files are 
created to be used by the administrator of the cluster. These files contain 
private keys and certificates which allow for privileged access to the 
cluster. You should restrict their file permissions to maintain the 
integrity and confidentiality of the file(s). The file(s) should be 
readable and writable by only the administrators on the system.

Impact: None.

Audit: Run the following command (based on the file location on your 
system) on the Control Plane node. For example, 

stat -c %a /etc/kubernetes/admin.conf

On Kubernetes version 1.29 and higher run the following command as well: 

stat -c %a /etc/kubernetes/super-admin.conf

Verify that the permissions are 600 or more restrictive.

Remediation: Run the below command (based on the file location on your 
system) on the Control Plane node. For example, 

chmod 600 /etc/kubernetes/admin.conf

On Kubernetes 1.29+ the super-admin.conf file should also be modified, if 
present. For example, 

chmod 600 /etc/kubernetes/super-admin.conf

Default Value: By default, admin.conf and super-admin.conf have permissions 
of 600.

References:

   1. 
      <https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/>
   2. <https://raesene.github.io/blog/2024/01/06/when-is-admin-not-admin/>",Created by Rules Engine,Recommended,Not tested,High,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1022 - Restrict File and Directory Permissions,Operational Security,NIST 800-53 v5,SC-16 Transmission of Security and Privacy Attributes
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-24,Ensure that the DenyServiceExternalIPs is set,"CIS Benchmark Recommendation id: 1.2.3

Profile Applicability: Level 1 - Master Node

Description: This admission controller rejects all net-new usage of the 
Service field externalIPs.

Rationale: Most users do not need the ability to set the externalIPs field 
for a Service at all, and cluster admins should consider disabling this 
functionality by enabling the DenyServiceExternalIPs admission controller. 
Clusters that do need to allow this functionality should consider using 
some custom policy to manage its usage.

Impact: When enabled, users of the cluster may not create new Services 
which use externalIPs and may not add new values to externalIPs on existing 
Service objects.

Audit: Run the following command on the Control Plane node: 
ps -ef | grep kube-apiserver

Verify that the DenyServiceExternalIPs argument exists as a string value in 
--enable-admission-plugins.

Remediation: Edit the API server pod specification file 
/etc/kubernetes/manifests/kube-apiserver.yaml on the master node and append 
the Kubernetes API server flag --enable-admission-plugins with the 
DenyServiceExternalIPs plugin. Note, the Kubernetes API server flag 
--enable-admission-plugins takes a comma-delimited list of admission 
control plugins to be enabled, even if they are in the list of plugins 
enabled by default. 
kube-apiserver --enable-admission-plugins=DenyServiceExternalIPs

Default Value: By default, --enable-admission-plugins=DenyServiceExternalIP 
argument is not set, and the use of externalIPs is authorized.

References:

   1. 
      <https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/>
   2. <https://kubernetes.io/docs/admin/kube-apiserver/>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1035 - Limit Access to Resource Over Network,Network Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-48,Ensure that the --encryption-provider-config argument is set as appropriate,"CIS Benchmark Recommendation id: 1.2.27

Profile Applicability: Level 1 - Master Node

Description: Encrypt etcd key-value store.

Rationale: etcd is a highly available key-value store used by Kubernetes 
deployments for persistent storage of all of its REST API objects. These 
objects are sensitive in nature and should be encrypted at rest to avoid 
any disclosures.

Impact: None

Audit: Run the following command on the Control Plane node: 
ps -ef | grep kube-apiserver

Verify that the --encryption-provider-config argument is set to a 
EncryptionConfig file. Additionally, ensure that the EncryptionConfig file 
has all the desired resources covered especially any secrets.

Remediation: Follow the Kubernetes documentation and configure an 
EncryptionConfig file. Then, edit the API server pod specification file 
/etc/kubernetes/manifests/kubeapiserver.yaml on the master node and set the 
--encryption-provider-config parameter to the path of that file: 

--encryption-provider-config=/path/to/EncryptionConfig/File

Default Value: By default, --encryption-provider-config is not set.

References:

   1. <https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/>
   2. <https://acotten.com/post/kube17-security>
   3. <https://kubernetes.io/docs/admin/kube-apiserver/>
   4. <https://github.com/kubernetes/features/issues/92>",Created by Rules Engine,Recommended,Not tested,High,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1043 - Credential Access Protection,Operational Security,NIST 800-53 v5,SC-28 PROTECTION OF INFORMATION AT REST
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-47,Ensure that the --etcd-cafile argument is set as appropriate,"CIS Benchmark Recommendation id: 1.2.26

Profile Applicability: Level 1 - Master Node

Description: etcd should be configured to make use of TLS encryption for 
client connections.

Rationale: etcd is a highly-available key value store used by Kubernetes 
deployments for persistent storage of all of its REST API objects. These 
objects are sensitive in nature and should be protected by client 
authentication. This requires the API server to identify itself to the etcd 
server using a SSL Certificate Authority file.

Impact: TLS and client certificate authentication must be configured for 
etcd.

Audit: Run the following command on the Control Plane node: 

ps -ef | grep kube-apiserver
Verify that the --etcd-cafile argument exists and it is set as appropriate.

Remediation: Follow the Kubernetes documentation and set up the TLS 
connection between the apiserver and etcd. Then, edit the API server pod 
specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the 
master node and set the etcd certificate authority file parameter. 

--etcd-cafile=<path/to/ca-file>

Default Value: By default, --etcd-cafile is not set.

References:

   1. <https://kubernetes.io/docs/admin/kube-apiserver/>
   2. <https://coreos.com/etcd/docs/latest/op-guide/security.html>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1054 - Software Configuration,Network Security,NIST 800-53 v5,SC-16 Transmission of Security and Privacy Attributes
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-44,Ensure that the --etcd-certfile and --etcd-keyfile arguments are set as appropriate,"CIS Benchmark Recommendation id: 1.2.23

Profile Applicability: Level 1 - Master Node

Description: etcd should be configured to make use of TLS encryption for 
client connections.

Rationale: etcd is a highly-available key value store used by Kubernetes 
deployments for persistent storage of all of its REST API objects. These 
objects are sensitive in nature and should be protected by client 
authentication. This requires the API server to identify itself to the etcd 
server using a client certificate and key.

Impact: TLS and client certificate authentication must be configured for 
etcd.

Audit: Run the following command on the Control Plane node: 
ps -ef | grep kube-apiserver

Verify that the --etcd-certfile and --etcd-keyfile arguments exist and they 
are set as appropriate.

Remediation: Follow the Kubernetes documentation and set up the TLS 
connection between the apiserver and etcd. Then, edit the API server pod 
specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the 
master node and set the etcd certificate and key file parameters. 
--etcd-certfile=<path/to/client-certificate-file> 
--etcd-keyfile=<path/to/client-key-file>

Default Value: By default, --etcd-certfile and --etcd-keyfile arguments are 
not set

References:

   1. <https://kubernetes.io/docs/admin/kube-apiserver/>
   2. <https://coreos.com/etcd/docs/latest/op-guide/security.html>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1043 - Credential Access Protection,Operational Security,NIST 800-53 v5,SC-12 CRYPTOGRAPHIC KEY ESTABLISHMENT AND MANAGEMENT
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-12,Ensure that the etcd data directory ownership is set to etcd:etcd,"CIS Benchmark Recommendation id: 1.1.12

Profile Applicability: Level 1 - Master Node

Description: Ensure that the etcd data directory ownership is set to 
etcd:etcd.

Rationale: etcd is a highly-available key-value store used by Kubernetes 
deployments for persistent storage of all of its REST API objects. This 
data directory should be protected from any unauthorized reads or writes. 
It should be owned by etcd:etcd.

Impact: None

Audit: On the etcd server node, get the etcd data directory, passed as an 
argument --datadir, from the below command:
ps -ef | grep etcd

Run the below command (based on the etcd data directory found above). For 
example,
stat -c %U:%G /var/lib/etcd

Verify that the ownership is set to etcd:etcd.

Remediation: On the etcd server node, get the etcd data directory, passed 
as an argument --datadir, from the below command:
ps -ef | grep etcd

Run the below command (based on the etcd data directory found above). For 
example,
chown etcd:etcd /var/lib/etcd

Default Value: By default, etcd data directory ownership is set to 
etcd:etcd.

References:

   1. 
      <https://coreos.com/etcd/docs/latest/op-guide/configuration.html#data-dir>
   2. <https://kubernetes.io/docs/admin/etcd/>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1026 - Privileged Account Management,Operational Security,NIST 800-53 v5,CM-6 Configuration Settings
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-11,Ensure that the etcd data directory permissions are set to 700 or more restrictive,"CIS Benchmark Recommendation id: 1.1.11
Profile Applicability: Level 1 - Master Node

Description: Ensure that the etcd data directory has permissions of 700 or 
more restrictive.

Rationale: etcd is a highly-available key-value store used by Kubernetes 
deployments for persistent storage of all of its REST API objects. This 
data directory should be protected from any unauthorized reads or writes. 
It should not be readable or writable by any group members or the world.

Impact: None

Audit: On the etcd server node, get the etcd data directory, passed as an 
argument --datadir, from the below command: 
ps -ef | grep etcd

Run the below command (based on the etcd data directory found above). For 
example, 
stat -c %a /var/lib/etcd

Verify that the permissions are 700 or more restrictive.

Remediation: On the etcd server node, get the etcd data directory, passed 
as an argument --datadir, from the below command: 
ps -ef | grep etcd

Run the below command (based on the etcd data directory found above). For 
example, 
chmod 700 /var/lib/etcd

Default Value:

By default, etcd data directory has permissions of 755.

References:

   1. 
      <https://coreos.com/etcd/docs/latest/op-guide/configuration.html#data-dir>
   2. <https://kubernetes.io/docs/admin/etcd/>",Created by Rules Engine,Recommended,Not tested,High,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1022 - Restrict File and Directory Permissions,Data Security,NIST 800-53 v5,CM-6 Configuration Settings
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-08,Ensure that the etcd pod specification file ownership is set to root:root,"CIS Benchmark Recommendation id: 1.1.8 
Profile Applicability: Level 1 - Master Node

Description: Ensure that the /etc/kubernetes/manifests/etcd.yaml file 
ownership is set to root:root.

Rationale: The etcd pod specification file 
/etc/kubernetes/manifests/etcd.yaml controls various parameters that set 
the behavior of the etcd service in the master node. etcd is a 
highly-available key-value store which Kubernetes uses for persistent 
storage of all of its REST API objects. You should set its file ownership 
to maintain the integrity of the file. The file should be owned by 
root:root.

Impact: None

Audit: Run the below command (based on the file location on your system) on 
the Control Plane node. For example,

stat -c %U:%G /etc/kubernetes/manifests/etcd.yaml

Verify that the ownership is set to root:root.

Remediation: Run the below command (based on the file location on your 
system) on the Control Plane node. For example, 

chown root:root /etc/kubernetes/manifests/etcd.yaml

Default Value: By default, /etc/kubernetes/manifests/etcd.yaml file 
ownership is set to root:root.

References:

   1. <https://coreos.com/etcd>
   2. <https://kubernetes.io/docs/admin/etcd/>",Created by Rules Engine,Recommended,Not tested,High,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1022 - Restrict File and Directory Permissions,Operational Security,NIST 800-53 v5,"SI-7 Software, Firmware, and Information Integrity"
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-07,Ensure that the etcd pod specification file permissions are set to 600 or more restrictive,"CIS Benchmark Recommendation id: 1.1.7

Profile Applicability: Level 1 - Master Node

Description: Ensure that the /etc/kubernetes/manifests/etcd.yaml file has 
permissions of 600 or more restrictive.

Rationale: The etcd pod specification file 
/etc/kubernetes/manifests/etcd.yaml controls various parameters that set 
the behavior of the etcd service in the master node. etcd is a 
highly-available key-value store which Kubernetes uses for persistent 
storage of all of its REST API objects. You should restrict its file 
permissions to maintain the integrity of the file. The file should be 
writable by only the administrators on the system.

Impact: None

Audit: Run the below command (based on the file location on your system) on 
the Control Plane node. For example,

stat -c %a /etc/kubernetes/manifests/etcd.yaml

Verify that the permissions are 600 or more restrictive.

Remediation: Run the below command (based on the file location on your 
system) on the Control Plane node. For example, 

chmod 600 /etc/kubernetes/manifests/etcd.yaml

Default Value: By default, /etc/kubernetes/manifests/etcd.yaml file has 
permissions of 640.

References:

   1. <https://coreos.com/etcd>
   2. <https://kubernetes.io/docs/admin/etcd/>",Created by Rules Engine,Recommended,Not tested,High,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1022 - Restrict File and Directory Permissions,Operational Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes worker node (kubernetes-components),C-KUBERNETES-WORKER-NODE-CNT-18,Ensure that the eventRecordQPS argument is set to a level which ensures appropriate event capture,"CIS Benchmark Recommendation id: 4.2.8

Profile Applicability: Level 2 - Worker Node

Description: Security relevant information should be captured. The 
eventRecordQPS on the Kubelet configuration can be used to limit the rate 
at which events are gathered and sets the maximum event creations per 
second. Setting this too low could result in relevant events not being 
logged, however the unlimited setting of 0 could result in a denial of 
service on the kubelet.

Rationale: It is important to capture all events and not restrict event 
creation. Events are an important source of security information and 
analytics that ensure that your environment is consistently monitored using 
the event data.

Impact: Setting this parameter to 0 could result in a denial of service 
condition due to excessive events being created. The cluster's event 
processing and storage systems should be scaled to handle expected event 
loads.

Audit: Run the following command on each node: 
sudo grep ""eventRecordQPS"" 
/etc/systemd/system/kubelet.service.d/10kubeadm.conf

or If using command line arguments, kubelet service file is located 
/etc/systemd/system/kubelet.service.d/10-kubelet-args.conf 

sudo grep ""eventRecordQPS"" 
/etc/systemd/system/kubelet.service.d/10-kubeletargs.conf

Review the value set for the argument and determine whether this has been 
set to an appropriate level for the cluster. If the argument does not 
exist, check that there is a Kubelet config file specified by -config and 
review the value in this location. If using command line arguments

Remediation: If using a Kubelet config file, edit the file to set 
eventRecordQPS to an appropriate level. If using command line arguments, 
edit the kubelet service file 
/etc/systemd/system/kubelet.service.d/10-kubeadm.conf on each worker node 
and set the below parameter in KUBELET_ARGS variable. Based on your system, 
restart the kubelet service. For example: 
systemctl daemon-reload
systemctl restart kubelet.service

Default Value: By default, eventRecordQPS argument is set to 5.

References:

   1. <https://kubernetes.io/docs/admin/kubelet/>
   2. 
      <https://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/apis/kubeletconfig/v1beta1/types.go>

 ",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1047 - Audit,Network Security,NIST 800-53 v5,SI-4 System Monitoring
Kubernetes worker node (kubernetes-components),C-KUBERNETES-WORKER-NODE-CNT-17,Ensure that the --hostname-override argument is not set,"CIS Benchmark Recommendation id: 4.2.7

Profile Applicability: Level 1 - Worker Node

Description: Do not override node hostnames.

Rationale: Overriding hostnames could potentially break TLS setup between 
the kubelet and the apiserver. Additionally, with overridden hostnames, it 
becomes increasingly difficult to associate logs with a particular node and 
process them for security analytics. Hence, you should setup your kubelet 
nodes with resolvable FQDNs and avoid overriding the hostnames with IPs.

Impact: Some cloud providers may require this flag to ensure that hostname 
matches names issued by the cloud provider. In these environments, this 
recommendation should not apply.

Audit: Run the following command on each node: 
ps -ef | grep kubelet

Verify that --hostname-override argument does not exist. Note This setting 
is not configurable via the Kubelet config file.

Remediation: Edit the kubelet service file 
/etc/systemd/system/kubelet.service.d/10kubeadm.conf on each worker node 
and remove the --hostname-override argument from the 
KUBELET_SYSTEM_PODS_ARGS variable. Based on your system, restart the 
kubelet service. For example: 

systemctl daemon-reload
systemctl restart kubelet.service

Default Value: By default, --hostname-override argument is not set.

References:

   1. <https://kubernetes.io/docs/admin/kubelet/>
   2. <https://github.com/kubernetes/kubernetes/issues/22063>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1054 - Software Configuration,Network Security,NIST 800-53 v5,SC-17 Public Key Infrastructure Certificates
Kubernetes worker node (kubernetes-components),C-KUBERNETES-WORKER-NODE-CNT-06,Ensure that the --kubeconfig kubelet.conf file ownership is set to root:root,"CIS Benchmark Recommendation id: 4.1.6 
Profile Applicability: Level 1 - Worker Node 

Description: Ensure that the kubelet.conf file ownership is set to 
root:root. 

Rationale: The kubelet.conf file is the kubeconfig file for the node, and 
controls various parameters that set the behavior and identity of the 
worker node. You should set its file ownership to maintain the integrity of 
the file. The file should be owned by root:root. 

Impact: None 

Audit: Automated AAC auditing has been modified to allow CIS-CAT to input a 
variable for the <PATH>/<FILENAME> of the kubelet config file. Please set 
$kubelet_config=<PATH> based on the file location on your system for 
example: 

export kubelet_config=/etc/kubernetes/kubelet.conf

To perform the audit manually: Run the below command (based on the file 
location on your system) on the each worker node. For example, 

stat -c %U:%G /etc/kubernetes/kubelet.conf

Verify that the ownership is set to root:root.

Remediation: Run the below command (based on the file location on your 
system) on the each worker node. For example, 

chown root:root /etc/kubernetes/kubelet.conf 

Default Value: By default, kubelet.conf file ownership is set to root:root.

References:

   1. <https://kubernetes.io/docs/admin/kubelet/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1026 - Privileged Account Management,Operational Security,NIST 800-53 v5,CM-6 Configuration Settings
Kubernetes worker node (kubernetes-components),C-KUBERNETES-WORKER-NODE-CNT-05,Ensure that the --kubeconfig kubelet.conf file permissions are set to 600 or more restrictive,"CIS Benchmark Recommendation id: 4.1.5
Profile Applicability: Level 1 - Worker Node
Description: Ensure that the kubelet.conf file has permissions of 600 or 
more restrictive.
Rationale: The kubelet.conf file is the kubeconfig file for the node, and 
controls various parameters that set the behavior and identity of the 
worker node. You should restrict its file permissions to maintain the 
integrity of the file. The file should be writable by only the 
administrators on the system.
Impact: None
Audit: Automated AAC auditing has been modified to allow CIS-CAT to input a 
variable for the PATH/FILENAME of the kubelet config file. Please set 
$kubelet_config=PATH based on the file location on your system, for 
example: 

export kubelet_config=/etc/kubernetes/kubelet.conf
To perform the audit manually: Run the below command (based on the file 
location on your system) on each worker node. For example: 
stat -c %a /etc/kubernetes/kubelet.conf
Verify that the ownership is set to root:root. Verify that the permissions 
are 600 or more restrictive.
Remediation: Run the below command (based on the file location on your 
system) on each worker node. For example: 
chmod 600 /etc/kubernetes/kubelet.conf
Default Value: By default, kubelet.conf file has permissions of 600.
References:

   1. <https://kubernetes.io/docs/admin/kubelet/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1022 - Restrict File and Directory Permissions,Operational Security,NIST 800-53 v5,CM-6 Configuration Settings
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-26,Ensure that the --kubelet-certificate-authority argument is set as appropriate,"CIS Benchmark Recommendation id: 1.2.5
Profile Applicability: Level 1 - Master Node
Description: Verify kubelet's certificate before establishing connection.
Rationale: The connections from the apiserver to the kubelet are used for 
fetching logs for pods, attaching (through kubectl) to running pods, and 
using the kubelet’s port-forwarding functionality. These connections 
terminate at the kubelet’s HTTPS endpoint. By default, the apiserver does 
not verify the kubelet’s serving certificate, which makes the connection 
subject to man-in-the-middle attacks, and unsafe to run over untrusted 
and/or public networks.
Impact: You require TLS to be configured on apiserver as well as kubelets.
Audit: Run the following command on the Control Plane node: 

ps -ef | grep kube-apiserver

Verify that the --kubelet-certificate-authority argument exists and is set 
as appropriate.

Alternative Audit:
kubectl get pod -n kube-system -l component=kube-apiserver 
-o=jsonpath='{range .items[]}{.spec.containers[].command} {""\n""}{end}' | 
grep '--kubelet-certificate-Authority' | grep -i false
If the exit code is '1', then the control isn't present/failed.
Remediation: Follow the Kubernetes documentation and set up the TLS 
connection between the apiserver and kubelets. Then, edit the API server 
pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the 
Control Plane node and set the --kubelet-certificate-authority parameter to 
the path to the cert file for the certificate authority.
--kubelet-certificate-authority=ca-string
Default Value: By default, --kubelet-certificate-authority argument is not 
set.
References:

   1. <https://kubernetes.io/docs/admin/kube-apiserver/>
   2. 
      <https://kubernetes.io/docs/admin/kubelet-authentication-authorization/>
   3. 
      <https://kubernetes.io/docs/concepts/cluster-administration/master-nodecommunication/#apiserver---kubelet>",Created by Rules Engine,Recommended,Not tested,High,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1054 - Software Configuration,Network Security,NIST 800-53 v5,SC-7 Boundary Protection
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-25,Ensure that the --kubelet-client-certificate and --kubeletclient-key arguments are set as appropriate,"CIS Benchmark Recommendation id: 1.2.4

Profile Applicability: Level 1 - Master Node

Description: Enable certificate based kubelet authentication.

Rationale: The apiserver, by default, does not authenticate itself to the 
kubelet's HTTPS endpoints. The requests from the apiserver are treated 
anonymously. You should set up certificate-based kubelet authentication to 
ensure that the apiserver authenticates itself to kubelets when submitting 
requests.

Impact: You require TLS to be configured on apiserver as well as kubelets.

Audit: Run the following command on the Control Plane node: 
ps -ef | grep kube-apiserver

Verify that the --kubelet-client-certificate and --kubelet-client-key 
arguments exist and they are set as appropriate. 
Alternative Audit: 
kubectl get pod -nkube-system -lcomponent=kube-apiserver 
-o=jsonpath='{range .items[]}{.spec.containers[].command} {""\n""}{end}' | 
grep '--kubelet-client-certificate' | grep -i false If the exit code is 
'1', then the control isn't present / failed

Remediation: Follow the Kubernetes documentation and set up the TLS 
connection between the apiserver and kubelets. Then, edit API server pod 
specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the 
Control Plane node and set the kubelet client certificate and key 
parameters as below. 
--kubelet-client-certificate=<path/to/client-certificate-file>

--kubelet-client-key=<path/to/client-key-file>

Default Value: By default, certificate-based kubelet authentication is not 
set.

References:

    * <https://kubernetes.io/docs/admin/kube-apiserver/>
    * 
      <https://kubernetes.io/docs/admin/kubelet-authentication-authorization/>
    * 
      <https://kubernetes.io/docs/concepts/cluster-administration/master-nodecommunication/#apiserver---kubelet>

 ",Created by Rules Engine,Recommended,Not tested,High,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1027 - Password Policies,Network Security,NIST 800-53 v5,SC-12 CRYPTOGRAPHIC KEY ESTABLISHMENT AND MANAGEMENT
Kubernetes worker node (kubernetes-components),C-KUBERNETES-WORKER-NODE-CNT-22,Ensure that the Kubelet only makes use of Strong Cryptographic Ciphers,"CIS Benchmark Recommendation id: 4.2.12

Profile Applicability: Level 1 - Worker Node

Description: Ensure that the Kubelet is configured to only use strong 
cryptographic ciphers.

Rationale: TLS ciphers have had a number of known vulnerabilities and 
weaknesses, which can reduce the protection provided by them. By default 
Kubernetes supports a number of TLS ciphersuites including some that have 
security concerns, weakening the protection provided.

Impact: Kubelet clients that cannot support modern cryptographic ciphers 
will not be able to make connections to the Kubelet API.

Audit: The set of cryptographic ciphers currently considered secure is the 
following:

    * TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256
    * TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256
    * TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305
    * TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384
    * TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305
    * TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384
    * TLS_RSA_WITH_AES_256_GCM_SHA384
    * TLS_RSA_WITH_AES_128_GCM_SHA256

Run the following command on each node:

ps -ef | grep kubelet

If the --tls-cipher-suites argument is present, ensure it only contains 
values included in this set. If it is not present check that there is a 
Kubelet config file specified by --config, and that file sets 
TLSCipherSuites: to only include values from this set.

Remediation: If using a Kubelet config file, edit the file to set 
TLSCipherSuites to: 
TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_128_GCM_SHA256 
or to a subset of these values. 

If using executable arguments, edit the kubelet service file 
/etc/kubernetes/kubelet.conf on each worker node and set the 
--tls-ciphersuites parameter as follows, or to a subset of these values. 

--tls-ciphersuites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_128_GCM_SHA256

Based on your system, restart the kubelet service. For example: 

systemctl daemon-reload 

systemctl restart kubelet.service

Default Value: By default the Kubernetes API server supports a wide range 
of TLS ciphers.

Additional Information: The list chosen above should be fine for modern 
clients. It's essentially the list from the Mozilla ""Modern cipher"" option 
with the ciphersuites supporting CBC mode removed, as CBC has traditionally 
had a lot of issues.

References: N/A",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1041 - Encrypt Sensitive Information,Application Security,NIST 800-53 v5,SC-12 CRYPTOGRAPHIC KEY ESTABLISHMENT AND MANAGEMENT
Kubernetes worker node (kubernetes-components),C-KUBERNETES-WORKER-NODE-CNT-02,Ensure that the kubelet service file ownership is set to root:root,"CIS Benchmark Recommendation id: 4.1.2

Profile Applicability: Level 1 - Worker Node

Description: Ensure that the kubelet service file ownership is set to 
root:root.

Rationale: The kubelet service file controls various parameters that set 
the behavior of the kubelet service in the worker node. You should set its 
file ownership to maintain the integrity of the file. The file should be 
owned by root:root.

Impact: None

Audit: Automated AAC auditing has been modified to allow CIS-CAT to input a 
variable for the <PATH>/<FILENAME> of the kubelet service config file. 
Please set $kubelet_service_config=<PATH> based on the file location on 
your system for example: 

export 
kubelet_service_config=/etc/systemd/system/kubelet.service.d/kubeadm.conf

To perform the audit manually: Run the below command (based on the file 
location on your system) on the each worker node. For example, 

stat -c %U:%G /etc/systemd/system/kubelet.service.d/10-kubeadm.conf

Verify that the ownership is set to root:root.

Remediation: Run the below command (based on the file location on your 
system) on the each worker node. For example, 

chown root:root /etc/systemd/system/kubelet.service.d/kubeadm.conf

Default Value: By default, kubelet service file ownership is set to 
root:root.

References:

   1. <https://kubernetes.io/docs/admin/kubelet/>
   2. 
      <https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/#44joining-your-nodes>
   3. <https://kubernetes.io/docs/admin/kubeadm/#kubelet-drop-in>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1026 - Privileged Account Management,Operational Security,NIST 800-53 v5,CM-6 Configuration Settings
Kubernetes worker node (kubernetes-components),C-KUBERNETES-WORKER-NODE-CNT-01,Ensure that the kubelet service file permissions are set to 600 or more restrictive,"CIS Benchmark Recommendation id: 4.1.1

Profile Applicability: Level 1 - Master Node

Description: Ensure that the kubelet service file has permissions of 600 or 
more restrictive.

Rationale: The kubelet service file controls various parameters that set 
the behavior of the kubelet service in the worker node. You should restrict 
its file permissions to maintain the integrity of the file. The file should 
be writable by only the administrators on the system.

Impact: None

Audit: Automated AAC auditing has been modified to allow CIS-CAT to input a 
variable for the <PATH>/<FILENAME> of the kubelet service config file. 
Please set $kubelet_service_config=<PATH> based on the file location on 
your system for example: 

export 
kubelet_service_config=/etc/systemd/system/kubelet.service.d/kubeadm.conf

To perform the audit manually: Run the below command (based on the file 
location on your system) on the each worker node. For example, 

stat -c %a /etc/systemd/system/kubelet.service.d/10-kubeadm.conf

Verify that the permissions are 600 or more restrictive.

Remediation: Run the below command (based on the file location on your 
system) on the each worker node. For example, 

chmod 600 /etc/systemd/system/kubelet.service.d/kubeadm.conf

Default Value: By default, the kubelet service file has permissions of 640.

References:

   1. <https://kubernetes.io/docs/admin/kubelet/>
   2. 
      <https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/#44joining-your-nodes>
   3. <https://kubernetes.io/docs/admin/kubeadm/#kubelet-drop-in>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1022 - Restrict File and Directory Permissions,Operational Security,NIST 800-53 v5,CM-6 Configuration Settings
Kubernetes worker node (kubernetes-components),C-KUBERNETES-WORKER-NODE-CNT-24,Ensure that the kube-proxy metrics service is bound to localhost,"CIS Benchmark Recommendation id: 4.3.1
Profile Applicability: Level 1 - Worker Node 

Description: Do not bind the kube-proxy metrics port to non-loopback 
addresses.
Rationale: kube-proxy has two APIs which provide access to information 
about the service and can be bound to network ports. The metrics API 
service includes endpoints (/metrics and /configz) which disclose 
information about the configuration and operation of kube-proxy. These 
endpoints should not be exposed to untrusted networks as they do not 
support encryption or authentication to restrict access to the data they 
provide.
Impact: 3rd party services which try to access metrics or configuration 
information related to kube-proxy will require access to the localhost 
interface of the node.
Audit: Review the start-up flags provided to kube proxy:
ps -ef | grep -i kube-proxy
Ensure that the --metrics-bind-address parameter is not set to a value 
other than 127.0.0.1. From the output of this command gather the location 
specified in the -config parameter. Review any file stored at that location 
and ensure that it does not specify a value other than 127.0.0.1 for 
metricsBindAddress.
Remediation: Modify or remove any values which bind the metrics service to 
a non-localhost address.
Default Value: The default value is 127.0.0.1:10249
References:

   1. 
      <https://kubernetes.io/docs/reference/command-line-tools-reference/kube-proxy/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1030 - Network Segmentation,Network Security,NIST 800-53 v5,SI-6 Security and Privacy Function Verification
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-20,Ensure that the Kubernetes PKI certificate file permissions are set to 600 or more restrictive,"CIS Benchmark Recommendation id: 1.1.20

Profile Applicability: • Level 1 - Master Node

Description: Ensure that Kubernetes PKI certificate files have permissions 
of 600 or more restrictive.

Rationale: Kubernetes makes use of a number of certificate files as part of 
the operation of its components. The permissions on these files should be 
set to 600 or more restrictive to protect their integrity and 
confidentiality.

Impact: None

Audit: Run the below command (based on the file location on your system) on 
the Control Plane node. For example, 

stat -c '%a' /etc/kubernetes/pki/*.crt

Verify that the permissions are 600 or more restrictive. or 

ls -l /etc/kubernetes/pki/*.crt

Verify -rw-----

Remediation: Run the below command (based on the file location on your 
system) on the Control Plane node. For example, 

chmod -R 600 /etc/kubernetes/pki/*.crt

Default Value: By default, the certificates used by Kubernetes are set to 
have permissions of 644

References:

   1. <https://kubernetes.io/docs/admin/kube-apiserver/>",Created by Rules Engine,Recommended,Not tested,High,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1022 - Restrict File and Directory Permissions,Operational Security,NIST 800-53 v5,SC-28 PROTECTION OF INFORMATION AT REST
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-19,Ensure that the Kubernetes PKI directory and file ownership is set to root:root,"CIS Benchmark Recommendation id: 1.1.19

Profile Applicability: Level 1 - Master Node

Description: Ensure that the Kubernetes PKI directory and file ownership is 
set to root:root.

Rationale: Kubernetes makes use of a number of certificates as part of its 
operation. You should set the ownership of the directory containing the PKI 
information and all files in that directory to maintain their integrity. 
The directory and files should be owned by root:root.

Impact: None

Audit: Run the below command (based on the file location on your system) on 
the Control Plane node. For example, 

ls -laR /etc/kubernetes/pki/

Verify that the ownership of all files and directories in this hierarchy is 
set to root:root.

Remediation: Run the below command (based on the file location on your 
system) on the Control Plane node. For example, 

chown -R root:root /etc/kubernetes/pki/

Default Value: By default, the /etc/kubernetes/pki/ directory and all of 
the files and directories contained within it, are set to be owned by the 
root user.

References:

   1. <https://kubernetes.io/docs/admin/kube-apiserver/>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1022 - Restrict File and Directory Permissions,Operational Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-21,Ensure that the Kubernetes PKI key file permissions are set to 600,"CIS Benchmark Recommendation id: 1.1.21 
Profile Applicability: Level 1 - Master Node

Description: Ensure that Kubernetes PKI key files have permissions of 600. 
Rationale: Kubernetes makes use of a number of key files as part of the 
operation of its components. The permissions on these files should be set 
to 600 to protect their integrity and confidentiality. 
Impact: None 
Audit: Run the below command (based on the file location on your system) on 
the Control Plane node. For example, 
stat -c '%a' /etc/kubernetes/pki/*.key 
Verify that the permissions are 600 or more restrictive. or 
ls -l /etc/kubernetes/pki/.key
Verify -rw----- 
Remediation: Run the below command (based on the file location on your 
system) on the Control Plane node. For example, 
chmod -R 600 /etc/kubernetes/pki/.key 
Default Value: By default, the keys used by Kubernetes are set to have 
permissions of 600 
References:

   1. <https://kubernetes.io/docs/admin/kube-apiserver/>",Created by Rules Engine,Recommended,Not tested,High,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1022 - Restrict File and Directory Permissions,Operational Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes worker node (kubernetes-components),C-KUBERNETES-WORKER-NODE-CNT-16,Ensure that the --make-iptables-util-chains argument is set to true,"CIS Benchmark Recommendation id: 4.2.6
Profile Applicability: Level 1 - Worker Node 

Description: Allow Kubelet to manage iptables.
Rationale: Kubelets can automatically manage the required changes to 
iptables based on how you choose your networking options for the pods. It 
is recommended to let kubelets manage the changes to iptables. This ensures 
that the iptables configuration remains in sync with pods networking 
configuration. Manually configuring iptables with dynamic pod network 
configuration changes might hamper the communication between 
pods/containers and to the outside world. You might have iptables rules too 
restrictive or too open.

Impact: Kubelet would manage the iptables on the system and keep it in 
sync. If you are using any other iptables management solution, then there 
might be some conflicts.

Audit: Run the following command on each node: 
ps -ef | grep kubelet 
Verify that if the --make-iptables-util-chains argument exists then it is 
set to true. If the --make-iptables-util-chains argument does not exist, 
and there is a Kubelet config file specified by --config, verify that the 
file does not set makeIPTablesUtilChains to false.

Remediation:

If using a Kubelet config file, edit the file to set 
makeIPTablesUtilChains: true. If using command line arguments, edit the 
kubelet service file /etc/kubernetes/kubelet.conf on each worker node and 
remove the --makeiptables-util-chains argument from the 
KUBELET_SYSTEM_PODS_ARGS variable. Based on your system, restart the 
kubelet service. For example:

systemctl daemon-reload 
systemctl restart kubelet.service 

Default Value: By default, --make-iptables-util-chains argument is set to 
true.
References:

   1. <https://kubernetes.io/docs/admin/kubelet/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1030 - Network Segmentation,Network Security,NIST 800-53 v5,SI-4 System Monitoring
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-65,Ensure that the --peer-auto-tls argument is not set to true,"CIS Benchmark Recommendation id: 2.6

Profile Applicability: Level 1 - Master Node

Description: Do not use automatically generated self-signed certificates 
for TLS connections between peers.

Rationale: etcd is a highly-available key value store used by Kubernetes 
deployments for persistent storage of all of its REST API objects. These 
objects are sensitive in nature and should be accessible only by 
authenticated etcd peers in the etcd cluster. Hence, do not use self-signed 
certificates for authentication.

Impact: All peers attempting to communicate with the etcd server will 
require a valid client certificate for authentication.

Audit: Run the following command on the etcd server node: 
ps -ef | grep etcd

Verify that if the --peer-auto-tls argument exists, it is not set to true. 
Note: This recommendation is applicable only for etcd clusters. If you are 
using only one etcd server in your environment then this recommendation is 
not applicable.

Remediation: Edit the etcd pod specification file 
/etc/kubernetes/manifests/etcd.yaml on the master node and either remove 
the --peer-auto-tls parameter or set it to false. 

--peer-auto-tls=false

Default Value: Note: This recommendation is applicable only for etcd 
clusters. If you are using only one etcd server in your environment then 
this recommendation is not applicable. By default, --peer-auto-tls argument 
is set to false.

References:

   1. <https://coreos.com/etcd/docs/latest/op-guide/security.html>
   2. <https://kubernetes.io/docs/admin/etcd/>
   3. 
      <https://coreos.com/etcd/docs/latest/op-guide/configuration.html#peer-auto-tls>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1054 - Software Configuration,Network Security,NIST 800-53 v5,SC-8 TRANSMISSION CONFIDENTIALITY AND INTEGRITY
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-63,Ensure that the --peer-cert-file and --peer-key-file arguments are set as appropriate,"CIS Benchmark Recommendation id: 2.4

Profile Applicability: Level 1 - Master Node

Description: etcd should be configured to make use of TLS encryption for 
peer connections.

Rationale: etcd is a highly-available key value store used by Kubernetes 
deployments for persistent storage of all of its REST API objects. These 
objects are sensitive in nature and should be encrypted in transit and also 
amongst peers in the etcd clusters.

Impact: etcd cluster peers would need to set up TLS for their 
communication.

Audit: Run the following command on the etcd server node:
ps -ef | grep etcd

Verify that the --peer-cert-file and --peer-key-file arguments are set as 
appropriate. Note: This recommendation is applicable only for etcd 
clusters. If you are using only one etcd server in your environment then 
this recommendation is not applicable.

Remediation: Follow the etcd service documentation and configure peer TLS 
encryption as appropriate for your etcd cluster. Then, edit the etcd pod 
specification file /etc/kubernetes/manifests/etcd.yaml on the master node 
and set the below parameters. 
--peer-client-file=/path/to/peer-cert-file
--peer-key-file=/path/to/peer-key-file

Default Value: Note: This recommendation is applicable only for etcd 
clusters. If you are using only one etcd server in your environment then 
this recommendation is not applicable. By default, peer communication over 
TLS is not configured.

References:

   1. <https://coreos.com/etcd/docs/latest/op-guide/security.html>
   2. <https://kubernetes.io/docs/admin/etcd/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1041 - Encrypt Sensitive Information,Network Security,NIST 800-53 v5,SC-8 TRANSMISSION CONFIDENTIALITY AND INTEGRITY
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-64,Ensure that the --peer-client-cert-auth argument is set to true,"CIS Benchmark Recommendation id: 2.5
Profile Applicability: Level 1 - Master Node

Description: etcd should be configured for peer authentication.
Rationale: etcd is a highly-available key value store used by Kubernetes 
deployments for persistent storage of all of its REST API objects. These 
objects are sensitive in nature and should be accessible only by 
authenticated etcd peers in the etcd cluster.
Impact: All peers attempting to communicate with the etcd server will 
require a valid client certificate for authentication.
Audit: Run the following command on the etcd server node:
ps -ef | grep etcd
Verify that the --peer-client-cert-auth argument is set to true. Note: This 
recommendation is applicable only for etcd clusters. If you are using only 
one etcd server in your environment then this recommendation is not 
applicable.
Remediation: Edit the etcd pod specification file 
/etc/kubernetes/manifests/etcd.yaml on the master node and set the below 
parameter. 

--peer-client-cert-auth=true
Default Value: Note: This recommendation is applicable only for etcd 
clusters. If you are using only one etcd server in your environment then 
this recommendation is not applicable. By default, --peer-client-cert-auth 
argument is set to false.
References:

   1. <https://coreos.com/etcd/docs/latest/op-guide/security.html>
   2. <https://kubernetes.io/docs/admin/etcd/>
   3. 
      <https://coreos.com/etcd/docs/latest/op-guide/configuration.html#peer-client-certauth>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1054 - Software Configuration,Network Security,NIST 800-53 v5,SC-17 Public Key Infrastructure Certificates
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-36,Ensure that the --profiling argument is set to false (API Server),"CIS Benchmark Recommendation id: 1.2.15
Profile Applicability: Level 1 - Master Node
Description: Disable profiling, if not needed.
Rationale: Profiling allows for the identification of specific performance 
bottlenecks. It generates a significant amount of program data that could 
potentially be exploited to uncover system and program details. If you are 
not experiencing any bottlenecks and do not need the profiler for 
troubleshooting purposes, it is recommended to turn it off to reduce the 
potential attack surface.
Impact: Profiling information would not be available.
Audit: Run the following command on the Control Plane node:
ps -ef | grep kube-apiserver
Verify that the --profiling argument is set to false.
Remediation: Edit the API server pod specification file 
/etc/kubernetes/manifests/kubeapiserver.yaml on the Control Plane node and 
set the below parameter. 

--profiling=false
Default Value: By default, profiling is enabled.
References:

   1. <https://kubernetes.io/docs/admin/kube-apiserver/>
   2. 
      <https://github.com/kubernetes/community/blob/master/contributors/devel/profiling.>",Created by Rules Engine,Recommended,Not tested,High,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1042 - Disable or Remove Feature or Program,Operational Security,NIST 800-53 v5,PM-17 Protecting Controlled Unclassified Information on External Systems
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-52,Ensure that the --profiling argument is set to false (Controller Manager),"CIS Benchmark Recommendation id: 1.3.2

Profile Applicability: Level 1 - Master Node

Description: Disable profiling, if not needed.

Rationale: Profiling allows for the identification of specific performance 
bottlenecks. It generates a significant amount of program data that could 
potentially be exploited to uncover system and program details. If you are 
not experiencing any bottlenecks and do not need the profiler for 
troubleshooting purposes, it is recommended to turn it off to reduce the 
potential attack surface.

Impact: Profiling information would not be available.

Audit: Run the following command on the Control Plane node: 
ps -ef | grep kube-controller-manager
Verify that the --profiling argument is set to false.

Remediation: Edit the Controller Manager pod specification file 
/etc/kubernetes/manifests/kube-controller-manager.yaml on the Control Plane 
node and set the below parameter. 

--profiling=false

Default Value: By default, profiling is enabled.

References:

   1. <https://kubernetes.io/docs/admin/kube-controller-manager/>
   2. 
      <https://github.com/kubernetes/community/blob/master/contributors/devel/profiling.>",Created by Rules Engine,Recommended,Not tested,High,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1057 - Data Loss Prevention,Operational Security,NIST 800-53 v5,CM-7 Least Functionality
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-58,Ensure that the --profiling argument is set to false (Scheduler),"CIS Benchmark Recommendation id: 1.4.1
Profile Applicability: Level 1 - Master Node
Description: Disable profiling, if not needed.
Rationale: Profiling allows for the identification of specific performance 
bottlenecks. It generates a significant amount of program data that could 
potentially be exploited to uncover system and program details. If you are 
not experiencing any bottlenecks and do not need the profiler for 
troubleshooting purposes, it is recommended to turn it off to reduce the 
potential attack surface.
Impact: Profiling information would not be available.
Audit: Run the following command on the Control Plane node: 
ps -ef | grep kube-scheduler
Verify that the --profiling argument is set to false.
Remediation: Edit the Scheduler pod specification file 
/etc/kubernetes/manifests/kubescheduler.yaml file on the Control Plane node 
and set the below parameter.
--profiling=false
Default Value: By default, profiling is enabled.
References:

   1. <https://kubernetes.io/docs/admin/kube-scheduler/>
   2. 
      <https://github.com/kubernetes/community/blob/master/contributors/devel/profiling.>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1042 - Disable or Remove Feature or Program,Operational Security,NIST 800-53 v5,"SI-7 Software, Firmware, and Information Integrity"
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-41,Ensure that the --request-timeout argument is set as appropriate,"CIS Benchmark Recommendation id: 1.2.20

Profile Applicability: Level 1 - Master Node

Description: Set global request timeout for API server requests as 
appropriate.

Rationale: Setting global request timeout allows extending the API server 
request timeout limit to a duration appropriate to the user's connection 
speed. By default, it is set to 60 seconds which might be problematic on 
slower connections making cluster resources inaccessible once the data 
volume for requests exceeds what can be transmitted in 60 seconds. But, 
setting this timeout limit to be too large can exhaust the API server 
resources making it prone to Denial-of-Service attack. Hence, it is 
recommended to set this limit as appropriate and change the default limit 
of 60 seconds only if needed.

Impact: None

Audit: Run the following command on the Control Plane node: 
ps -ef | grep kube-apiserver

Verify that the --request-timeout argument is either not set or set to an 
appropriate value.

Remediation: Edit the API server pod specification file 
/etc/kubernetes/manifests/kubeapiserver.yaml and set the below parameter as 
appropriate and if needed. For example, 

--request-timeout=300s

Default Value: By default, --request-timeout is set to 60 seconds.

References:

   1. <https://kubernetes.io/docs/admin/kube-apiserver/>
   2. <https://github.com/kubernetes/kubernetes/pull/51415>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1031 - Network Intrusion Prevention,Network Security,NIST 800-53 v5,SC-5 DENIAL-OF-SERVICE PROTECTION
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-55,Ensure that the --root-ca-file argument is set as appropriate,"CIS Benchmark Recommendation id: 1.3.5

Profile Applicability: Level 1 - Master Node

Description: Allow pods to verify the API server's serving certificate 
before establishing connections.

Rationale: Processes running within pods that need to contact the API 
server must verify the API server's serving certificate. Failing to do so 
could be subject to man-in-the-middle attacks. Providing the root 
certificate for the API server's serving certificate to the controller 
manager with the --root-ca-file argument allows the controller manager to 
inject the trusted bundle into pods so that they can verify TLS connections 
to the API server.

Impact: You need to set up and maintain a root certificate authority file.

Audit: Run the following command on the Control Plane node: 

ps -ef | grep kube-controller-manager

Verify that the --root-ca-file argument exists and is set to a certificate 
bundle file containing the root certificate for the API server's serving 
certificate.

Remediation: Edit the Controller Manager pod specification file 
/etc/kubernetes/manifests/kubecontroller-manager.yaml on the Control Plane 
node and set the --root-ca-file parameter to the certificate bundle file`. 

--root-ca-file=<path/to/file>

Default Value: By default, --root-ca-file is not set.

References:

   1. <https://kubernetes.io/docs/admin/kube-controller-manager/>
   2. <https://github.com/kubernetes/kubernetes/issues/11000>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1054 - Software Configuration,Network Security,NIST 800-53 v5,SC-23 SESSION AUTHENTICITY
Kubernetes worker node (kubernetes-components),C-KUBERNETES-WORKER-NODE-CNT-20,Ensure that the --rotate-certificates argument is not set to false,"CIS Benchmark Recommendation id: 4.2.10 
Profile Applicability: Level 1 - Worker Node 

Description: Enable kubelet client certificate rotation. 

Rationale: The --rotate-certificates setting causes the kubelet to rotate 
its client certificates by creating new CSRs as its existing credentials 
expire. This automated periodic rotation ensures that there is no downtime 
due to expired certificates and thus addresses availability in the CIA 
security triad. 
Note: This recommendation only applies if you let kubelets get their 
certificates from the API server. In case your kubelet certificates come 
from an outside authority/tool (e.g. Vault) then you need to take care of 
rotation yourself. 
Note: This feature also requires the RotateKubeletClientCertificate feature 
gate to be enabled (which is the default since Kubernetes v1.7). 

Impact: None 

Audit: Run the following command on each node: 
ps -ef | grep kubelet 
Verify that the RotateKubeletServerCertificate argument is not present, or 
is set to true. If the RotateKubeletServerCertificate argument is not 
present, verify if there is a Kubelet config file specified by --config, 
that file does not contain RotateKubeletServerCertificate: false. 

Remediation: If using a Kubelet config file, edit the file to add the line 
rotateCertificates: true or remove it altogether to use the default value. 
If using command line arguments, edit the kubelet service file 
/etc/kubernetes/kubelet.conf on each worker node and remove 
--rotatecertificates=false argument from the KUBELET_CERTIFICATE_ARGS 
variable or set --rotate-certificates=true. 
Based on your system, restart the kubelet service. 
For example: 
systemctl daemon-reload 
systemctl restart kubelet.service 

Default Value: By default, kubelet client certificate rotation is enabled. 

References:

   1. <https://github.com/kubernetes/kubernetes/pull/41912>
   2. 
      <https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet-tlsbootstrapping/#kubelet-configuration>
   3. <https://kubernetes.io/docs/imported/release/notes/>
   4. 
      <https://kubernetes.io/docs/reference/command-line-tools-reference/feature-gates/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1043 - Credential Access Protection,Network Security,NIST 800-53 v5,SC-12 CRYPTOGRAPHIC KEY ESTABLISHMENT AND MANAGEMENT
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-56,Ensure that the RotateKubeletServerCertificate argument is set to true,"CIS Benchmark Recommendation id: 1.3.6

Profile Applicability: Level 1 - Master Node

Description: Enable kubelet server certificate rotation on 
controller-manager.

Rationale: RotateKubeletServerCertificate causes the kubelet to both 
request a serving certificate after bootstrapping its client credentials 
and rotate the certificate as its existing credentials expire. This 
automated periodic rotation ensures that there are no downtimes due to 
expired certificates and thus addressing availability in the CIA security 
triad. Note: This recommendation only applies if you let kubelets get their 
certificates from the API server. In case your kubelet certificates come 
from an outside authority/tool (e.g. Vault) then you need to take care of 
rotation yourself.

Impact: None

Audit: Run the following command on the Control Plane node: 

ps -ef | grep kube-controller-manager
Verify that RotateKubeletServerCertificate argument exists and is set to 
true.

Remediation: Edit the Controller Manager pod specification file 
/etc/kubernetes/manifests/kubecontroller-manager.yaml on the Control Plane 
node and set the --feature-gates parameter to include 
RotateKubeletServerCertificate=true. 
--feature-gates=RotateKubeletServerCertificate=true

Default Value: By default, RotateKubeletServerCertificate is set to ""true"" 
this recommendation verifies that it has not been disabled.

References:

   1. 
      <https://kubernetes.io/docs/admin/kubelet-tls-bootstrapping/#approval-controller>
   2. <https://github.com/kubernetes/features/issues/267>
   3. <https://github.com/kubernetes/kubernetes/pull/45059>
   4. <https://kubernetes.io/docs/admin/kube-controller-manager/>",Created by Rules Engine,Recommended,Not tested,High,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1054 - Software Configuration,Operational Security,NIST 800-53 v5,AC-4 Information Flow Enforcement
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-16,Ensure that the scheduler.conf file ownership is set to root:root,"CIS Benchmark Recommendation id: 1.1.16

Profile Applicability: Level 1 - Master Node

Description: Ensure that the scheduler.conf file ownership is set to 
root:root.

Rationale: The scheduler.conf file is the kubeconfig file for the 
Scheduler. You should set its file ownership to maintain the integrity of 
the file. The file should be owned by root:root.

Impact: None

Audit: Run the below command (based on the file location on your system) on 
the Control Plane node. For example, 

stat -c %U:%G /etc/kubernetes/scheduler.conf

Verify that the ownership is set to root:root.

Remediation: Run the below command (based on the file location on your 
system) on the Control Plane node. For example, 

chown root:root /etc/kubernetes/scheduler.conf

Default Value: By default, scheduler.conf file ownership is set to 
root:root.

References:

   1. <https://kubernetes.io/docs/admin/kubeadm/>",Created by Rules Engine,Recommended,Not tested,High,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1022 - Restrict File and Directory Permissions,Operational Security,NIST 800-53 v5,CM-6 Configuration Settings
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-15,Ensure that the scheduler.conf file permissions are set to 600 or more restrictive,"CIS Benchmark Recommendation id: 1.1.15
Profile Applicability: Level 1 - Master Node

Description: Ensure that the scheduler.conf file has permissions of 600 or 
more restrictive.
Rationale: The scheduler.conf file is the kubeconfig file for the 
Scheduler. You should restrict its file permissions to maintain the 
integrity of the file. The file should be writable by only the 
administrators on the system.
Impact: None
Audit: Run the following command (based on the file location on your 
system) on the Control Plane node. For example, 

stat -c %a /etc/kubernetes/scheduler.conf
Verify that the permissions are 600 or more restrictive.
Remediation: Run the below command (based on the file location on your 
system) on the Control Plane node. For example, 

chmod 600 /etc/kubernetes/scheduler.conf
Default Value: By default, scheduler.conf has permissions of 640.
References:

   1. 
      <https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/>",Created by Rules Engine,Recommended,Not tested,High,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1022 - Restrict File and Directory Permissions,Operational Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-06,Ensure that the scheduler pod specification file ownership is set to root:root,"CIS Benchmark Recommendation id: 1.1.6

Profile Applicability: Level 1 - Master Node

Description: Ensure that the scheduler pod specification file ownership is 
set to root:root.

Rationale: The scheduler pod specification file controls various parameters 
that set the behavior of the kube-scheduler service in the master node. You 
should set its file ownership to maintain the integrity of the file. The 
file should be owned by root:root.

Impact: None

Audit: Run the below command (based on the file location on your system) on 
the Control Plane node. For example, 

stat -c %U:%G /etc/kubernetes/manifests/kube-scheduler.yaml

Verify that the ownership is set to root:root.

Remediation: Run the below command (based on the file location on your 
system) on the Control Plane node. For example, 

chown root:root /etc/kubernetes/manifests/kube-scheduler.yaml

Default Value: By default, kube-scheduler.yaml file ownership is set to 
root:root.

References:

   1. <https://kubernetes.io/docs/admin/kube-scheduler/>",Created by Rules Engine,Recommended,Not tested,High,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1026 - Privileged Account Management,Operational Security,NIST 800-53 v5,CM-6 Configuration Settings
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-05,Ensure that the scheduler pod specification file permissions are set to 600 or more restrictive,"CIS Benchmark Recommendation id: 1.1.5

Profile Applicability: Level 1 - Master Node

Description: Ensure that the scheduler pod specification file has 
permissions of 600 or more restrictive.

Rationale: The scheduler pod specification file controls various parameters 
that set the behavior of the Scheduler service in the master node. You 
should restrict its file permissions to maintain the integrity of the file. 
The file should be writable by only the administrators on the system.

Impact: None

Audit: Run the below command (based on the file location on your system) on 
the Control Plane node. For example, 

stat -c %a /etc/kubernetes/manifests/kube-scheduler.yaml
Verify that the permissions are 600 or more restrictive.

Remediation: Run the below command (based on the file location on your 
system) on the Control Plane node. For example, 

chmod 600 /etc/kubernetes/manifests/kube-scheduler.yaml

Default Value: By default, kube-scheduler.yaml file has permissions of 640.

References:

   1. <https://kubernetes.io/docs/admin/kube-scheduler/>",Created by Rules Engine,Recommended,Not tested,High,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1022 - Restrict File and Directory Permissions,Operational Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Cluster,C-KUBERNETES-CLUSTER-CNT-22,Ensure that the seccomp profile is set to docker/default in your pod definitions,"CIS Benchmark Recommendation id: 5.7.2

Profile Applicability: Level 2 - Master Node

Description: Enable docker/default seccomp profile in your pod definitions.

Rationale: Seccomp (secure computing mode) is used to restrict the set of 
system calls applications can make, allowing cluster administrators greater 
control over the security of workloads running in the cluster. Kubernetes 
disables seccomp profiles by default for historical reasons. You should 
enable it to ensure that the workloads have restricted actions available 
within the container.

Impact: If the docker/default seccomp profile is too restrictive for you, 
you would have to create/manage your own seccomp profiles.

Audit: Review the pod definitions in your cluster. It should create a line 
as below: 

securityContext: 

  seccompProfile: 

    type: RuntimeDefault

Remediation: Use security context to enable the docker/default seccomp 
profile in your pod definitions. An example is as below: 

securityContext: 

  seccompProfile: 

    type: RuntimeDefault

Default Value: By default, seccomp profile is set to unconfined which means 
that no seccomp profiles are enabled.

References:

   1. <https://kubernetes.io/docs/tutorials/clusters/seccomp/>
   2. <https://docs.docker.com/engine/security/seccomp/>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1054 - Software Configuration,Application Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-43,Ensure that the --service-account-key-file argument is set as appropriate,"CIS Benchmark Recommendation id: 1.2.22

Profile Applicability: Level 1 - Master Node

Description: Explicitly set a service account public key file for service 
accounts on the apiserver.

Rationale: By default, if no --service-account-key-file is specified to the 
apiserver, it uses the private key from the TLS serving certificate to 
verify service account tokens. To ensure that the keys for service account 
tokens could be rotated as needed, a separate public/private key pair 
should be used for signing service account tokens. Hence, the public key 
should be specified to the apiserver with --service-account-key-file.

Impact: The corresponding private key must be provided to the controller 
manager. You would need to securely maintain the key file and rotate the 
keys based on your organization's key rotation policy.

Audit: Run the following command on the Control Plane node: 
ps -ef | grep kube-apiserver
Verify that the --service-account-key-file argument exists and is set as 
appropriate.

Remediation: Edit the API server pod specification file 
/etc/kubernetes/manifests/kubeapiserver.yaml on the Control Plane node and 
set the --service-account-key-file parameter to the public key file for 
service accounts: 

--service-account-key-file=<filename>

Default Value: By default, --service-account-key-file argument is not set.

References:

   1. <https://kubernetes.io/docs/admin/kube-apiserver/>
   2. <https://github.com/kubernetes/kubernetes/issues/24167>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1043 - Credential Access Protection,Data Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-42,Ensure that the --service-account-lookup argument is set to true,"CIS Benchmark Recommendation id: 1.2.21

Profile Applicability: Level 1 - Master Node

Description: Validate service account before validating token.

Rationale: If --service-account-lookup is not enabled, the apiserver only 
verifies that the authentication token is valid, and does not validate that 
the service account token mentioned in the request is actually present in 
etcd. This allows using a service account token even after the 
corresponding service account is deleted. This is an example of time of 
check to time of use security issue.

Impact: None

Audit: Run the following command on the Control Plane node: 
ps -ef | grep kube-apiserver

Verify that if the --service-account-lookup argument exists it is set to 
true.

Remediation: Edit the API server pod specification file 
/etc/kubernetes/manifests/kubeapiserver.yaml on the Control Plane node and 
set the below parameter. 

--service-account-lookup=true

Alternatively, you can delete the --service-account-lookup parameter from 
this file so that the default takes effect.

Default Value: By default, --service-account-lookup argument is set to 
true.

References:

   1. <https://kubernetes.io/docs/admin/kube-apiserver/>
   2. <https://github.com/kubernetes/kubernetes/issues/24167>
   3. <https://en.wikipedia.org/wiki/Time_of_check_to_time_of_use>

 ",Created by Rules Engine,Recommended,Not tested,High,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1036 - Account Use Policies,Operational Security,NIST 800-53 v5,AC-12 SESSION TERMINATION
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-54,Ensure that the --service-account-private-key-file argument is set as appropriate,"CIS Benchmark Recommendation id: 1.3.4

Profile Applicability: Level 1 - Master Node

Description: Explicitly set a service account private key file for service 
accounts on the controller manager.

Rationale: To ensure that keys for service account tokens can be rotated as 
needed, a separate public/private key pair should be used for signing 
service account tokens. The private key should be specified to the 
controller manager with --service-account-privatekey-file as appropriate.

Impact: You would need to securely maintain the key file and rotate the 
keys based on your organization's key rotation policy.

Audit: Run the following command on the Control Plane node: 
ps -ef | grep kube-controller-manager

Verify that the --service-account-private-key-file argument is set as 
appropriate.

Remediation: 
Edit the Controller Manager pod specification file 
/etc/kubernetes/manifests/kubecontroller-manager.yaml on the Control Plane 
node and set the --serviceaccount-private-key-file parameter to the private 
key file for service accounts. 

--service-account-private-key-file=<filename>

Default Value: 
By default, --service-account-private-key-file it not set.

References:

   1. <https://kubernetes.io/docs/admin/kube-controller-manager/>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1043 - Credential Access Protection,Data Security,NIST 800-53 v5,SC-12 CRYPTOGRAPHIC KEY ESTABLISHMENT AND MANAGEMENT
Kubernetes worker node (kubernetes-components),C-KUBERNETES-WORKER-NODE-CNT-15,Ensure that the --streaming-connection-idle-timeout argument is not set to 0,"CIS Benchmark Recommendation id: 4.2.5
Profile Applicability: Level 1 - Worker Node 

Description: Do not disable timeouts on streaming connections.

Rationale: Setting idle timeouts ensures that you are protected against 
Denial-of-Service attacks, inactive connections, and running out of 
ephemeral ports. Note: By default, --streaming-connection-idle-timeout is 
set to 4 hours which might be too high for your environment. Setting this 
as appropriate would additionally ensure that such streaming connections 
are timed out after serving legitimate use cases.

Impact: Long-lived connections could be interrupted.

Audit: Run the following command on each node:

ps -ef | grep kubelet

Verify that the --streaming-connection-idle-timeout argument is not set to 
0. If the argument is not present, and there is a Kubelet config file 
specified by --config, check that it does not set 
streamingConnectionIdleTimeout to 0.

Remediation: If using a Kubelet config file, edit the file to set 
streamingConnectionIdleTimeout to a value other than 0. If using command 
line arguments, edit the kubelet service file /etc/kubernetes/kubelet.conf 
on each worker node and set the below parameter in KUBELET_SYSTEM_PODS_ARGS 
variable.

--streaming-connection-idle-timeout=5m

Based on your system, restart the kubelet service. For example:

systemctl daemon-reload
systemctl restart kubelet.service

Default Value: By default, --streaming-connection-idle-timeout is set to 4 
hours.

References:

   1. <https://kubernetes.io/docs/admin/kubelet/>
   2. <https://github.com/kubernetes/kubernetes/pull/18552>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1054 - Software Configuration,Application Security,NIST 800-53 v5,SC-10 NETWORK DISCONNECT
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-51,Ensure that the --terminated-pod-gc-threshold argument is set as appropriate,"CIS Benchmark Recommendation id: 1.3.1

Profile Applicability: Level 1 - Master Node

Description: Activate garbage collector on pod termination, as appropriate.

Rationale: Garbage collection is important to ensure sufficient resource 
availability and avoiding degraded performance and availability. In the 
worst case, the system might crash or just be unusable for a long period of 
time. The current setting for garbage collection is 12,500 terminated pods 
which might be too high for your system to sustain. Based on your system 
resources and tests, choose an appropriate threshold value to activate 
garbage collection.

Impact: None

Audit: Run the following command on the Control Plane node: 
ps -ef | grep kube-controller-manager

Verify that the --terminated-pod-gc-threshold argument is set as 
appropriate.

Remediation: Edit the Controller Manager pod specification file 
/etc/kubernetes/manifests/kubecontroller-manager.yaml on the Control Plane 
node and set the --terminatedpod-gc-threshold to an appropriate threshold, 
for example: 

--terminated-pod-gc-threshold=10

Default Value: By default, --terminated-pod-gc-threshold is set to 12500.

References:

   1. <https://kubernetes.io/docs/admin/kube-controller-manager/>
   2. <https://github.com/kubernetes/kubernetes/issues/28484>",Created by Rules Engine,Recommended,Not tested,High,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1054 - Software Configuration,Operational Security,NIST 800-53 v5,CP-2 Contingency Plan
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-45,Ensure that the --tls-cert-file and --tls-private-key-file arguments are set as appropriate,"CIS Benchmark Recommendation id: 1.2.24

Profile Applicability: Level 1 - Master Node

Description: Setup TLS connection on the API server.

Rationale: API server communication contains sensitive parameters that 
should remain encrypted in transit. Configure the API server to serve only 
HTTPS traffic.

Impact: TLS and client certificate authentication must be configured for 
your Kubernetes cluster deployment.

Audit: Run the following command on the Control Plane node:
ps -ef | grep kube-apiserver

Verify that the --tls-cert-file and --tls-private-key-file arguments exist 
and they are set as appropriate.

Remediation: Follow the Kubernetes documentation and set up the TLS 
connection on the apiserver. Then, edit the API server pod specification 
file /etc/kubernetes/manifests/kubeapiserver.yaml on the master node and 
set the TLS certificate and private key file parameters. 

--tls-cert-file=<path/to/tls-certificate-file> 

--tls-private-key-file=<path/to/tls-key-file>

Default Value: By default, --tls-cert-file and --tls-private-key-file are 
presented and created for use.

References:

   1. <https://kubernetes.io/docs/admin/kube-apiserver/>
   2. <http://rootsquash.com/2016/05/10/securing-the-kubernetes-api/>
   3. <https://github.com/kelseyhightower/docker-kubernetes-tls-guide>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1043 - Credential Access Protection,Network Security,NIST 800-53 v5,SC-16 Transmission of Security and Privacy Attributes
Kubernetes worker node (kubernetes-components),C-KUBERNETES-WORKER-NODE-CNT-19,Ensure that the --tls-cert-file and --tls-private-key-file arguments are set as appropriate,"CIS Benchmark Recommendation id: 4.2.9

Profile Applicability: Level 1 - Worker Node

Description: Setup TLS connection on the Kubelets.

Rationale: The connections from the apiserver to the kubelet are used for 
fetching logs for pods, attaching (through kubectl) to running pods, and 
using the kubelet’s port-forwarding functionality. These connections 
terminate at the kubelet’s HTTPS endpoint. By default, the apiserver does 
not verify the kubelet’s serving certificate, which makes the connection 
subject to man-in-the-middle attacks, and unsafe to run over untrusted 
and/or public networks.

Impact: None

Audit: Run the following command on each node: 
ps -ef | grep kubelet

Verify that the --tls-cert-file and --tls-private-key-file arguments exist 
and they are set as appropriate. If these arguments are not present, check 
that there is a Kubelet config specified by -config and that it contains 
appropriate settings for tlsCertFile and tlsPrivateKeyFile.

Remediation: If using a Kubelet config file, edit the file to set 
tlsCertFile to the location of the certificate file to use to identify this 
Kubelet, and tlsPrivateKeyFile to the location of the corresponding private 
key file. If using command line arguments, edit the kubelet service file 
/etc/kubernetes/kubelet.conf on each worker node and set the below 
parameters in KUBELET_CERTIFICATE_ARGS variable. 
--tls-cert-file=path/to/tls-certificate-file 
--tls-private-key-file=path/to/tls-key-file 

Based on your system, restart the kubelet service. For example:

systemctl daemon-reload 
systemctl restart kubelet.service

Default Value: None

References:

N/A",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1041 - Encrypt Sensitive Information,Network Security,NIST 800-53 v5,SC-8 TRANSMISSION CONFIDENTIALITY AND INTEGRITY
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-23,Ensure that the --token-auth-file parameter is not set,"CIS Benchmark Recommendation id: 1.2.2

Profile Applicability: Level 1 - Master Node

Description: Do not use token based authentication.

Rationale: The token-based authentication utilizes static tokens to 
authenticate requests to the apiserver. The tokens are stored in clear-text 
in a file on the apiserver, and cannot be revoked or rotated without 
restarting the apiserver. Hence, do not use static token-based 
authentication.

Impact: You will have to configure and use alternate authentication 
mechanisms such as certificates. Static token-based authentication could 
not be used.

Audit: Run the following command on the Control Plane node: 
ps -ef | grep kube-apiserver

Verify that the --token-auth-file argument does not exist. 

Alternative Audit Method: 

kubectl get pod -n kube-system -l component=kube-apiserver 
-o=jsonpath='{range .items[]}{.spec.containers[].command}{""\n""}{end}' | 
grep '--token-auth-file' | grep -i false
If the exit code is '1', then the control isn't present / failed

Remediation: Follow the documentation and configure alternate mechanisms 
for authentication. Then, edit the API server pod specification file 
/etc/kubernetes/manifests/kubeapiserver.yaml on the master node and remove 
the --token-authfile= parameter.

Default Value: By default, --token-auth-file argument is not set.

References:

   1. <https://kubernetes.io/docs/admin/authentication/#static-token-file>
   2. <https://kubernetes.io/docs/admin/kube-apiserver/>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1035 - Limit Access to Resource Over Network,Operational Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Control Plane,C-KUBERNETES-CONTROL-PLANE-CNT-53,Ensure that the --use-service-account-credentials argument is set to true,"CIS Benchmark Recommendation id: 1.3.3

Profile Applicability: Level 1 - Master Node

Description: Use individual service account credentials for each 
controller.

Rationale: The controller manager creates a service account per controller 
in the kube-system namespace, generates a credential for it, and builds a 
dedicated API client with that service account credential for each 
controller loop to use. Setting the --use-serviceaccount-credentials to 
true runs each control loop within the controller manager using a separate 
service account credential. When used in combination with RBAC, this 
ensures that the control loops run with the minimum permissions required to 
perform their intended tasks.

Impact: Whatever authorizer is configured for the cluster, it must grant 
sufficient permissions to the service accounts to perform their intended 
tasks. When using the RBAC authorizer, those roles are created and bound to 
the appropriate service accounts in the kube-system namespace automatically 
with default roles and role bindings that are auto-reconciled on startup. 
If using other authorization methods (ABAC, Webhook, etc), the cluster 
deployer is responsible for granting appropriate permissions to the service 
accounts (the required permissions can be seen by inspecting the 
controller-roles.yaml and controller-role-bindings.yaml files for the RBAC 
roles.

Audit: Run the following command on the Control Plane node: 
ps -ef | grep kube-controller-manager
Verify that the --use-service-account-credentials argument is set to true.

Remediation: Edit the Controller Manager pod specification file 
/etc/kubernetes/manifests/kubecontroller-manager.yaml on the Control Plane 
node to set the below parameter.

--use-service-account-credentials=true

Default Value: By default, --use-service-account-credentials is set to 
false.

References:

   1. <https://kubernetes.io/docs/admin/kube-controller-manager/>
   2. <https://kubernetes.io/docs/admin/service-accounts-admin/>
   3. 
      <https://github.com/kubernetes/kubernetes/blob/release1.6/plugin/pkg/auth/authorizer/rbac/bootstrappolicy/testdata/controller-roles.yaml>
   4. 
      <https://github.com/kubernetes/kubernetes/blob/release1.6/plugin/pkg/auth/authorizer/rbac/bootstrappolicy/testdata/controller-rolebindings.yaml>
   5. 
      <https://kubernetes.io/docs/admin/authorization/rbac/#controller-roles>",Created by Rules Engine,Recommended,Not tested,High,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1027 - Password Policies,Operational Security,NIST 800-53 v5,IA-5 AUTHENTICATOR MANAGEMENT
AWS S3 (Simple Storage Service),C-AWS-S3-CNT-02,Ensure that your Amazon S3 buckets use the correct policies and are not publicly accessible,"Unless you explicitly require anyone on the internet to be able to read or 
write to your S3 bucket, make sure that your S3 bucket is not public. The 
following are some of the steps that you can take to block public access:

    * Use S3 Block Public Access. With S3 Block Public Access, you can
      easily set up centralized controls to limit public access to your
      Amazon S3 resources. These centralized controls are enforced
      regardless of how the resources are created. For more information,
      see Blocking public access to your Amazon S3 storage
      <https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-control-block-public-access.html> 
      .
    * Identify Amazon S3 bucket policies that allow a wildcard identity
      such as ""Principal"": ""*"" (which effectively means ""anyone""). Also
      look for policies that allow a wildcard action ""*"" (which effectively
      allows the user to perform any action in the Amazon S3 bucket).
    * Similarly, look for Amazon S3 bucket access control lists (ACLs) that
      provide read, write, or full-access to ""Everyone"" or ""Any
      authenticated AWS user.""
    * Use the ListBuckets API operation to scan all of your Amazon S3
      buckets. Then use GetBucketAcl, GetBucketWebsite, and GetBucketPolicy
      to determine whether each bucket has compliant access controls and a
      compliant configuration.
    * Use AWS Trusted Advisor
      <https://docs.aws.amazon.com/awssupport/latest/user/getting-started.html#trusted-advisor> 
      to inspect your Amazon S3 implementation.
    * Consider implementing ongoing detective controls by using the 
      s3-bucket-public-read-prohibited
      <https://docs.aws.amazon.com/config/latest/developerguide/s3-bucket-public-read-prohibited.html> 
      and s3-bucket-public-write-prohibited
      <https://docs.aws.amazon.com/config/latest/developerguide/s3-bucket-public-write-prohibited.html> 
      managed AWS Config Rules.

For more information, see Identity and Access Management for Amazon S3
<https://docs.aws.amazon.com/AmazonS3/latest/userguide/security-iam.html> 
.",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1030 - Network Segmentation,Cloud Security,NIST 800-53 v5,SC-7 Boundary Protection
VPN (Virtual Private Network),C-VPN-VIRTUAL-PRIVATE-NETWORK-CNT-04,Establish and enforce strong password policies to secure VPN access,"Implement strong password policies for all VPN users to prevent the use of 
weak or easily guessable credentials. Strong password practices reduce the 
risk of unauthorized access and mitigate credential-based attacks such as 
brute force and credential stuffing.

Define Strong Password Requirements:

    * Require passwords to be at least 12 characters long, including a mix
      of uppercase and lowercase letters, numbers, and special characters.
    * Prohibit the use of common or easily guessable passwords (e.g.,
      ""password123"" or ""admin"").

Enforce Password Complexity:

    * Configure the VPN authentication system to enforce password
      complexity rules.
    * Use tools or scripts to check password strength during user creation
      or password resets.

Enable Account Lockout Policies:

    * Set limits on failed login attempts to block brute force attacks.
    * Temporarily lock accounts after multiple failed attempts and notify
      administrators of suspicious activity.

Implement Password Expiration:

    * Require users to update their passwords periodically, such as every
      90 days.
    * Notify users before passwords expire to encourage timely updates.

Prohibit Password Reuse:

    * Configure the system to prevent users from reusing recent passwords.
    * Maintain a history of previous passwords to enforce this policy.

Combine with Multifactor Authentication (MFA):

    * Pair strong passwords with MFA to provide an additional layer of
      security.
    * Use MFA to mitigate the impact of compromised passwords.

Educate Users on Password Best Practices:

    * Train users to create and manage strong passwords.
    * Encourage the use of password managers to securely store and generate
      complex passwords.

Monitor and Audit Password Policies:

    * Regularly review password policies and compliance with organizational
      standards.
    * Audit password-related logs to identify and address vulnerabilities
      or suspicious activities.

By establishing and enforcing strong password policies, developers and 
DevOps engineers can reduce the risk of credential compromise and 
strengthen the security of VPN access.

References:

    * CISA Password Recommendations
      <https://www.cisa.gov/secure-our-world/require-strong-passwords>",Created by Rules Engine,Recommended,Not tested,Very high,N/A,Medium,Hugo Ponthieu,,ATT&CK Enterprise - M1056 - Pre-compromise,Network Security,NIST 800-53 v5,IA-5 AUTHENTICATOR MANAGEMENT
PostgreSQL,C-POSTGRESQL-CNT-POSTGRES-04,Harden postgresql configuration and restrict network access,"Implement and regularly update a hardened PostgreSQL configuration and 
restrict network access to protect sensitive data and prevent unauthorized 
access. This control ensures that PostgreSQL is deployed with secure 
settings—disabling unnecessary features and default behaviors—and that 
network access is limited to trusted hosts using firewall rules, security 
groups, or VLAN segmentation. Developers and DevOps engineers should 
integrate these practices into the PostgreSQL deployment and maintenance 
process, ensuring that configurations are reviewed regularly and network 
access policies are enforced via centralized management tools.

Implementation Steps:

Harden PostgreSQL Configuration:
Review and update the PostgreSQL configuration (e.g., postgresql.conf and 
pg_hba.conf) to disable unnecessary services, enforce strong security 
parameters, and enable robust logging and auditing.

Restrict Network Access:
Deploy PostgreSQL in private network segments and use firewall rules or 
cloud security groups to allow access only from authorized IP addresses or 
subnets.

Regularly Audit and Update:
Perform periodic security audits and configuration reviews to ensure that 
both the database settings and network access policies remain aligned with 
evolving security best practices.

References:

    * PostgreSQL Security Documentation
      <https://www.postgresql.org/support/security/>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1035 - Limit Access to Resource Over Network,Application Security,NIST 800-53 v5,SC-7 Boundary Protection
Redis Server,C-REDIS-SERVER-CNT-REDIS-03,Harden Redis configuration and disable dangerous commands,"Implement and regularly update a hardened Redis configuration by disabling 
dangerous commands to reduce the system's attack surface. This control 
ensures that only necessary commands are enabled, limiting the potential 
for misuse by attackers or malicious insiders. Developers and DevOps 
engineers should review the default Redis configuration, disable or 
restrict high-risk commands (such as FLUSHDB, FLUSHALL, CONFIG, and 
others), and enforce these settings via configuration management tools to 
maintain a secure deployment.

Implementation Steps:

Review Default Configuration:
Audit the default Redis configuration to identify and document commands 
that are not required for your use case.

Disable Dangerous Commands:
Update the configuration file to disable commands that could be misused 
(e.g., FLUSHDB, FLUSHALL, CONFIG, DEBUG) by renaming them or setting 
appropriate access controls.

Enforce Secure Configurations:
Use configuration management tools (e.g., Ansible, Puppet, Chef) to ensure 
that hardened settings are consistently applied across all Redis instances.

Regular Audits and Testing:
Periodically audit the Redis configuration and test the system to verify 
that dangerous commands remain disabled and that the system complies with 
security best practices.

References:

    * Redis Security Documentation
      <https://redis.io/docs/latest/operate/oss_and_stack/management/security/>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1054 - Software Configuration,Application Security,NIST 800-53 v5,SI-10 INFORMATION INPUT VALIDATION
AWS S3 (Simple Storage Service),C-AWS-S3-CNT-17,Identify and audit all of your Amazon S3 buckets,"Identification of your IT assets is a crucial aspect of governance and 
security. You need to have visibility of all your Amazon S3 resources to 
assess their security posture and take action on potential areas of 
weakness. To audit your resources, we recommend doing the following:

    * Use Tag Editor to identify and tag security-sensitive or
      audit-sensitive resources, then use those tags when you need to
      search for these resources. For more information, see Searching for
      Resources to Tag
      <https://docs.aws.amazon.com/ARG/latest/userguide/tag-editor.html> 
      in the Tagging AWS Resources User Guide.
    * Use S3 Inventory to audit and report on the replication and
      encryption status of your objects for business, compliance, and
      regulatory needs. For more information, see Amazon S3 Inventory
      <https://docs.aws.amazon.com/AmazonS3/latest/userguide/storage-inventory.html> 
      .
    * Create resource groups for your Amazon S3 resources. For more
      information, see What are resource groups?
      <https://docs.aws.amazon.com/ARG/latest/userguide/welcome.html> in
      the AWS Resource Groups User Guide.",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1047 - Audit,Cloud Security,NIST 800-53 v5,AC-7 UNSUCCESSFUL LOGON ATTEMPTS
AWS S3 (Simple Storage Service),C-AWS-S3-CNT-05,Identify potential threats to your Amazon S3 buckets by using Amazon GuardDuty,"Amazon GuardDuty
<https://docs.aws.amazon.com/guardduty/latest/ug/guardduty_data-sources.html#guardduty_controlplane> 
is a threat detection service that identifies potential threats to your 
accounts, containers, workloads, and the data within your AWS environment. 
By using machine learning (ML) models, and anomaly and threat detection 
capabilities, Amazon GuardDuty continuously monitors different data sources 
to identify and prioritize potential security risks and malicious 
activities in your environment. When you enable GuardDuty, it offers threat 
detection for foundational data sources that includes AWS CloudTrail 
management events
<https://docs.aws.amazon.com/guardduty/latest/ug/guardduty_data-sources.html#guardduty_controlplane> 
, VPC flow logs, and DNS logs. To extend threat detection to data plane 
events in S3 buckets, you can enable the GuardDuty S3 Protection
<https://docs.aws.amazon.com/guardduty/latest/ug/s3-protection.html> 
feature. This feature detects threats such as data exfiltration and 
suspicious access to S3 buckets via Tor nodes. GuardDuty also establishes a 
normal baseline pattern in your environment and when it identifies a 
potentially anomalous behavior, it provides contextual information to help 
you remediate the potentially compromised S3 bucket or AWS credentials. For 
more information, see GuardDuty
<https://docs.aws.amazon.com/guardduty/latest/ug/what-is-guardduty.html> .",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1050 - Exploit Protection,Cloud Security,NIST 800-53 v5,SI-3 Malicious Code Protection
Kubernetes worker node (kubernetes-components),C-KUBERNETES-WORKER-NODE-CNT-04,If proxy kubeconfig file exists ensure ownership is set to root:root,"CIS Benchmark Recommendation id: 4.1.4

Profile Applicability: Level 1 - Worker Node

Description: If kube-proxy is running, ensure that the file ownership of 
its kubeconfig file is set to root:root.

Rationale: The kubeconfig file for kube-proxy controls various parameters 
for the kube-proxy service in the worker node. You should set its file 
ownership to maintain the integrity of the file. The file should be owned 
by root:root.

Impact: None

Audit: Find the kubeconfig file being used by kube-proxy by running the 
following command: 
ps -ef | grep kube-proxy

If kube-proxy is running, get the kubeconfig file location from the 
--kubeconfig parameter. To perform the audit: Run the below command (based 
on the file location on your system) on each worker node. For example, 
stat -c %U:%G /path/filename

Verify that the ownership is set to root:root.

Remediation: Run the below command (based on the file location on your 
system) on each worker node. For example, 
chown root:root /path/proxy_kubeconfig_file

Default Value: By default, proxy file ownership is set to root:root.

References:

   1. <https://kubernetes.io/docs/admin/kube-proxy/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1022 - Restrict File and Directory Permissions,Operational Security,NIST 800-53 v5,"SI-7 Software, Firmware, and Information Integrity"
Kubernetes worker node (kubernetes-components),C-KUBERNETES-WORKER-NODE-CNT-03,If proxy kubeconfig file exists ensure permissions are set to 600 or more restrictive,"CIS Benchmark Recommendation id: 4.1.3

Profile Applicability: Level 1 - Worker Node

Description: If kube-proxy is running, and if it is using a file-based 
kubeconfig file, ensure that the proxy kubeconfig file has permissions of 
600 or more restrictive.

Rationale: The kube-proxy kubeconfig file controls various parameters of 
the kube-proxy service in the worker node. You should restrict its file 
permissions to maintain the integrity of the file. The file should be 
writable by only the administrators on the system. It is possible to run 
kube-proxy with the kubeconfig parameters configured as a Kubernetes 
ConfigMap instead of a file. In this case, there is no proxy kubeconfig 
file.

Impact: None

Audit: Find the kubeconfig file being used by kube-proxy by running the 
following command: 
ps -ef | grep kube-proxy

If kube-proxy is running, get the kubeconfig file location from the 
--kubeconfig parameter. To perform the audit: Run the below command (based 
on the file location on your system) on each worker node. For example, 

stat -c %a path/filename

Verify that a file is specified and it exists with permissions are 600 or 
more restrictive.

Remediation: Run the below command (based on the file location on your 
system) on each worker node. For example, 

chmod 600 proxy-kubeconfig-file

Default Value: By default, proxy file has permissions of 640.

References:

   1. <https://kubernetes.io/docs/admin/kube-proxy/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1022 - Restrict File and Directory Permissions,Operational Security,NIST 800-53 v5,CM-6 Configuration Settings
Kubernetes worker node (kubernetes-components),C-KUBERNETES-WORKER-NODE-CNT-10,If the kubelet config.yaml configuration file is being used validate file ownership is set to root:root,"CIS Benchmark Recommendation id: 4.1.10
Profile Applicability: Level 1 - Worker Node 

Description: Ensure that if the kubelet refers to a configuration file with 
the --config argument, that file is owned by root:root. 

Rationale: The kubelet reads various parameters, including security 
settings, from a config file specified by the --config argument. If this 
file is specified you should restrict its file permissions to maintain the 
integrity of the file. The file should be owned by root:root. 

Impact: None 

Audit: Automated AAC auditing has been modified to allow CIS-CAT to input a 
variable for the <PATH>/<FILENAME> of the kubelet config yaml file. Please 
set $kubelet_config_yaml=<PATH> based on the file location on your system; 
for example: 

export kubelet_config_yaml=/var/lib/kubelet/config.yaml 

To perform the audit manually: Run the below command (based on the file 
location on your system) on each worker node. For example: 

stat -c %aU %G /var/lib/kubelet/config.yaml 

Verify that the ownership is set to root:root. 

Remediation: Run the following command (using the config file location 
identified in the Audit step): 

chown root:root /etc/kubernetes/kubelet.conf 

Default Value: By default, /var/lib/kubelet/config.yaml file as set up by 
kubeadm is owned by root:root. 

References:

   1. 
      <https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1026 - Privileged Account Management,Operational Security,NIST 800-53 v5,"SI-7 Software, Firmware, and Information Integrity"
Kubernetes worker node (kubernetes-components),C-KUBERNETES-WORKER-NODE-CNT-09,If the kubelet config.yaml configuration file is being used validate permissions set to 600 or more restrictive,"CIS Benchmark Recommendation id: 4.1.9

Profile Applicability: Level 1 - Worker Node

Description: Ensure that if the kubelet refers to a configuration file with 
the --config argument, that file has permissions of 600 or more 
restrictive.

Rationale: The kubelet reads various parameters, including security 
settings, from a config file specified by the --config argument. If this 
file is specified, you should restrict its file permissions to maintain the 
integrity of the file. The file should be writable by only the 
administrators on the system.

Impact: None

Audit: Automated AAC auditing has been modified to allow CIS-CAT to input a 
variable for the <PATH>/<FILENAME> of the kubelet config yaml file. Please 
set $kubelet_config_yaml=<PATH> based on the file location on your system. 
For example: 

export kubelet_config_yaml=/var/lib/kubelet/config.yaml.

To perform the audit manually: Run the below command (based on the file 
location on your system) on each worker node. For example, 

stat -c %a /var/lib/kubelet/config.yaml.

Verify that the permissions are 600 or more restrictive.

Remediation: Run the following command (using the config file location 
identified in the Audit step): 

chmod 600 /var/lib/kubelet/config.yaml

Default Value: By default, the /var/lib/kubelet/config.yaml file as set up 
by kubeadm has permissions of 600.

References:

   1. 
      <https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1022 - Restrict File and Directory Permissions,Operational Security,NIST 800-53 v5,CM-6 Configuration Settings
VPN (Virtual Private Network),C-VPN-VIRTUAL-PRIVATE-NETWORK-CNT-10,Implement automated tools to manage and enforce secure VPN configurations consistently,"Use automated tools to manage, deploy, and enforce secure VPN 
configurations across the network. Automation ensures consistency, 
minimizes human error, and enables rapid response to emerging threats or 
policy updates.

Select an Automation Tool:

    * Choose tools that support VPN configuration management, such as
      Terraform, Ansible, or Cisco’s VPN automation features.
    * Ensure the tool integrates with your VPN solution and supports secure
      configuration protocols.

Define Baseline Configurations:

    * Establish a baseline for secure VPN settings, including
      authentication mechanisms, encryption protocols, and logging
      policies.
    * Align baseline configurations with industry standards like NIST or
      CIS Benchmarks.

Automate Deployment and Updates:

    * Use the automation tool to deploy consistent VPN configurations
      across all devices and locations.
    * Schedule automated updates to apply security patches and
      configuration changes promptly.

Integrate Compliance Validation:

    * Implement automated checks to validate configurations against the
      defined security baseline.
    * Generate alerts for any deviations or non-compliant settings
      detected.

Monitor and Manage Configuration Drift:

    * Enable continuous monitoring to detect and correct configuration
      drift, ensuring all VPN endpoints adhere to the approved settings.
    * Automatically revert unauthorized or accidental changes to maintain
      compliance.

Document and Version Control Configurations:

    * Use version control systems (e.g., Git) to track changes to VPN
      configurations and facilitate rollback if issues occur.
    * Maintain detailed documentation for all automation scripts and
      templates.

Test Automation Processes:

    * Conduct testing in a staging environment before deploying changes to
      production.
    * Verify that automated processes achieve the intended security
      outcomes without disrupting VPN operations.

Provide Training and Support:

    * Train administrators and DevOps teams on the use of automation tools
      for VPN management.
    * Ensure a clear understanding of how to troubleshoot and update
      automation scripts as needed.

By implementing automated tools for managing VPN configurations, developers 
and DevOps engineers can ensure consistent enforcement of security 
standards, reduce the risk of misconfigurations, and enhance the overall 
efficiency of VPN management.

References:

    * NIST Guidelines for Secure VPN Deployment
      <https://csrc.nist.gov/publications/detail/sp/800-41/rev-1/final>",Created by Rules Engine,Recommended,Not tested,High,N/A,High,Hugo Ponthieu,,ATT&CK Enterprise - M1054 - Software Configuration,Network Security,NIST 800-53 v5,CM-6 Configuration Settings
"*.beep,ovh",C-IMPLEMENT-COMPREHENSIVE-DNS-LOGGING-AND-MONITORING,Implement Comprehensive DNS Logging and Monitoring,"Comprehensive DNS logging and monitoring are crucial for maintaining the 
security and integrity of DNS operations. These practices help in detecting 
unauthorized changes, potential security threats, and ensuring compliance 
with regulatory standards. Effective logging and monitoring can provide 
early warnings of malicious activities and facilitate rapid response to 
security incidents.

Steps to Implement Comprehensive DNS Logging and Monitoring

Define What to Log:

    * Determine the types of DNS transactions and events that need to be
      logged, such as query requests, responses, errors, and administrative
      changes.
    * Include details such as source IP, destination IP, query type,
      timestamp, and response code in the logs.

Choose Appropriate Logging Tools and Solutions:

    * Evaluate and select DNS logging tools that can handle the volume and
      variety of your DNS traffic. Consider tools that offer real-time
      monitoring and alerting capabilities.
    * Ensure that the chosen tools are compatible with your existing DNS
      infrastructure and security systems.

Configure DNS Servers for Logging:

    * Enable logging on all DNS servers. Configure the servers to record
      detailed information about all transactions and security-relevant
      events.
    * Set up log rotation and archiving policies to manage the size and
      longevity of log files while ensuring that data is retained long
      enough to meet operational and compliance needs.

Set Up a Centralized Logging System:

    * Implement a centralized log management system to consolidate logs
      from all DNS servers for easier analysis and management.
    * Use log management solutions that provide facilities for searching,
      filtering, and correlating log data, which are essential for
      effective analysis and incident response.

Implement Real-Time Monitoring and Alerting:

    * Set up real-time monitoring of DNS logs to detect unusual patterns
      and potential security threats, such as a high volume of failed query
      responses, which might indicate a DDoS attack or configuration
      issues.
    * Configure alerting mechanisms to notify IT staff immediately of
      critical events or indicators of compromise.

Regularly Review and Audit Logs:

    * Schedule regular reviews of DNS logs to identify trends that may
      indicate security issues or operational inefficiencies.
    * Conduct periodic audits of DNS logs and monitoring procedures to
      ensure they comply with organizational policies and regulatory
      requirements.

Enhance Security with Anomaly Detection:

    * Employ advanced analytics and machine learning techniques to identify
      anomalies in DNS traffic that may elude traditional monitoring tools.
    * Continuously update and refine detection algorithms based on new
      threat intelligence and evolving attack techniques.

Train and Educate Staff:

    * Educate DNS administrators and IT security staff on the importance of
      DNS log monitoring and the specific tools and practices employed by
      your organization.
    * Provide training on how to effectively analyze log data and respond
      to alerts.

Maintain and Update Monitoring Tools:

    * Regularly update monitoring and logging tools to leverage the latest
      features and maintain security against evolving threats.
    * Stay informed about advancements in logging and monitoring
      technologies to continuously improve your DNS security posture.

Good Security Practices Reference

    * Implement logging and monitoring in accordance with best practices
      from organizations like the Internet Corporation for Assigned Names
      and Numbers (ICANN) and Internet Engineering Task Force (IETF).
    * Follow security guidelines and recommendations from cybersecurity
      frameworks and institutions such as the National Institute of
      Standards and Technology (NIST) or the Center for Internet Security
      (CIS).

By implementing comprehensive DNS logging and monitoring, organizations can 
achieve greater visibility into their DNS infrastructure, enhance their 
security posture, and ensure quick response to incidents, all while 
maintaining compliance with regulatory requirements.",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Hugo Ponthieu,,ATT&CK Enterprise - M1053 - Data Backup,Operational Security,NIST 800-53 v5,AU-2 Event Logging
Redis Server,C-REDIS-SERVER-CNT-REDIS-06,Implement data integrity verification and access logging,"Implement and regularly update data integrity verification and access 
logging for Redis Server to ensure that all data modifications are 
validated and all access events are recorded for auditing purposes. This 
control helps maintain the accuracy and reliability of data while providing 
detailed logs to facilitate forensic analysis and real-time monitoring. 
Developers and DevOps engineers should integrate integrity checks into 
Redis operations and configure centralized logging systems to capture and 
analyze access events.

Implementation Steps:

Enable Integrity Verification:
Integrate mechanisms such as checksums or hash verifications to 
continuously validate the integrity of data stored in Redis.

Configure Comprehensive Access Logging:
Set up Redis to log all relevant access events, including command usage, 
authentication attempts, and configuration changes. Use centralized logging 
solutions (e.g., ELK stack, Splunk) for real-time analysis and historical 
audits.

Integrate with Monitoring and SIEM Tools:
Feed access logs and integrity check results into security information and 
event management (SIEM) systems to trigger alerts for anomalous activities.

Regular Audits and Reviews:
Periodically review logs and perform data integrity audits to ensure 
compliance with security policies and quickly detect any unauthorized 
changes.

References:

    * OWASP Logging Cheat Sheet
      <https://cheatsheetseries.owasp.org/cheatsheets/Logging_Cheat_Sheet.html>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1022 - Restrict File and Directory Permissions,Application Security,NIST 800-53 v5,AU-12 Audit Record Generation
DNS (Domain Name System),C-DNS-DOMAIN-NAME-SYSTEM-CNT-1,Implement DNSSEC and source port randomization,"Implementing DNS Security Extensions (DNSSEC): Step-by-Step Guidance

   1. Assess Compatibility: Before deploying DNSSEC, ensure that your DNS
      software, such as BIND, Unbound, or Microsoft DNS, supports DNSSEC.
      Verify compatibility and update to the latest version if necessary to
      take advantage of security patches and features.
   2. DNS Server Preparation: Prepare your DNS servers by checking that
      they have the necessary cryptographic libraries and that there is
      sufficient CPU and memory resources, as the cryptographic operations
      required for DNSSEC can be computationally intensive.
   3. Zone Signing: Generate your zone signing key (ZSK) and key signing
      key (KSK). These keys will be used to sign the DNS records. Use a
      strong encryption algorithm such as RSA with a key length of 2048
      bits or higher. Tools like BIND's `dnssec-keygen` can be utilized for
      this purpose.
   4. Sign DNS Records: Use your ZSK to sign the DNS records in your zone
      file. This involves creating RRSIG records, which are signatures of
      your DNS records. Ensure that all resource records in your zone,
      except NSEC/NSEC3 records, are signed.
   5. Publish DNSKEY Records: Include the DNSKEY records corresponding to
      your ZSK and KSK in your zone file. These records allow resolvers to
      verify the authenticity of your signed records.
   6. Create DS Records: The Delegation Signer (DS) records provide a link
      between your DNS zone and its parent zone. Submit your DS records to
      the parent zone, such as your domain registrar, for entry into their
      DNS database.
   7. Configure DNS Resolvers for Port Randomization: To prevent DNS cache
      poisoning attacks, ensure that your DNS resolvers are configured to
      randomize the source port of DNS queries. Most modern DNS software
      supports this feature; for instance, BIND does so by default. Verify
      by checking configuration options or using network analysis tools.
   8. Testing and Validation: Test your DNSSEC deployment thoroughly before
      moving to production. Use tools such as DNSViz or Verisign’s DNSSEC
      debugger to ensure your DNSSEC setup is functioning correctly and no
      misconfigurations exist.
   9. Monitor and Renew Keys: Establish a key rollover process to regularly
      change the cryptographic keys. Use automated tools and scripts to
      facilitate this process, minimizing human error. Monitor your DNS
      server logs for any anomalies or DNSSEC failures.

References

    * DNS Security Best Practices
      <https://blog.safedns.com/dns-security-best-practices-2/>",Created by Rules Engine,Recommended,Not tested,Very high,N/A,High,Hugo Ponthieu,,ATT&CK Enterprise - M1050 - Exploit Protection,Network Security,NIST 800-53 v5,SC-20 Secure Name/address Resolution Service (authoritative Source)
Cloudflare,C-CLOUDFLARE-01,Implement DNSSEC (Domain Name System Security Extensions),"Implementing DNSSEC (Domain Name System Security Extensions) adds 
cryptographic signatures to DNS records, ensuring their authenticity and 
integrity. This helps prevent DNS spoofing attacks.

Steps to Implement DNSSEC:

   1. Enable DNSSEC on your DNS servers to cryptographically sign your DNS
      records.
   2. Ensure your DNS resolver validates DNSSEC signatures.
   3. Regularly monitor and audit your DNS records for any signs of
      tampering.
   4. Update and patch your DNS software to protect against known
      vulnerabilities.
   5. Educate your IT staff about the importance of DNS security and how to
      manage DNSSEC keys properly.
   6. Work with your DNS service provider to ensure they support and
      correctly implement DNSSEC.

Refer to the best practices outlined by organizations like ICANN and the 
Internet Society for maintaining and managing DNSSEC keys securely.",Created by Rules Engine,Recommended,Not tested,Very high,N/A,Medium,Hugo Ponthieu,,ATT&CK Enterprise - M1031 - Network Intrusion Prevention,Application Security||Data Security||Network Security,NIST 800-53 v5,SC-20 Secure Name/address Resolution Service (authoritative Source)
Cloudflare,C-CLOUDFLARE-03,Implement end-to-end encryption,"Implementing end-to-end encryption ensures that data transmitted between 
Cloudflare servers and client systems is protected from interception and 
unauthorized access.

Steps to Implement:

   1. Use SSL/TLS to encrypt data transmitted over the network.
   2. Configure Cloudflare to enforce encrypted connections and reject
      unencrypted traffic.
   3. Regularly update encryption protocols and certificates to comply with
      current security standards.
   4. Monitor network traffic to ensure that all communications are
      encrypted and detect any attempts at interception.
   5. Educate users on the importance of encryption and how to verify
      secure connections.

Encryption significantly reduces the risk of data interception and ensures 
the confidentiality and integrity of transmitted data.",Created by Rules Engine,Recommended,Not tested,High,N/A,High,Hugo Ponthieu,,ATT&CK Enterprise - M1041 - Encrypt Sensitive Information,Data Security||Network Security,NIST 800-53 v5,SC-8 TRANSMISSION CONFIDENTIALITY AND INTEGRITY
"*.beep,ovh",C-IMPLEMENT-INPUT-VALIDATION,Implement Input Validation,"Input validation is a critical security measure that involves verifying the 
correctness, relevance, and security of the data that users or systems 
submit to your applications. Proper input validation can prevent numerous 
types of security vulnerabilities, including SQL injection, cross-site 
scripting (XSS), and command injection, which can compromise your 
application’s integrity and security.

Steps to Implement Input Validation

Identify Input Sources:

    * Determine all the points in your application where user input is
      accepted. This includes forms, URL parameters, headers, cookies, and
      any external systems that interact with your application.
    * Understand the context in which each input is used within your
      application, such as database queries, command line scripts, or
      output generation.

Define Valid Input Criteria:

    * Specify the valid format, type, and range for each input field based
      on its expected use. For example, an email address should match a
      standard email format, and numeric fields should not accept
      alphabetic characters.
    * Establish maximum and minimum length requirements to prevent overly
      long input that could be used in buffer overflow attacks.

Implement Validation Logic:

    * Use built-in validation frameworks provided by your development
      platform, such as input sanitizers and validators in web development
      frameworks like Django, Flask, ASP.NET, or Spring.
    * Write custom validation functions if necessary, especially for
      complex inputs that require specific business logic validation.
    * Apply whitelist validation (allowlisting), where only explicitly
      permitted values are accepted.

Validate Input at the Right Location:

    * Perform validation as close as possible to the point of entry before
      the input is processed or consumed by your application.
    * Revalidate or sanitize input at every transition point within your
      application, especially when involving different subsystems or
      services.

Provide User Feedback:

    * Clearly inform users of input errors and provide constructive
      feedback on how to correct them. Ensure that error messages do not
      disclose sensitive information about the application’s internal
      workings.
    * Use generic error messages for sensitive operations to avoid giving
      clues that could help an attacker (e.g., use ""Invalid login details""
      instead of specifying whether the username or password was
      incorrect).

Securely Handle Invalid Input:

    * Decide on a safe response to invalid input, such as rejecting the
      request, substituting default values, or logging the event for
      further investigation.
    * Ensure that responses to invalid input do not enable additional
      vulnerabilities, such as reflected XSS or error-based SQL injection.

Regularly Review and Update Validation Rules:

    * Periodically review your input validation rules and update them in
      response to new security threats or changes in application
      functionality.
    * Incorporate feedback from security testing, user input, and error
      logs to refine and enhance your validation strategies.

Educate and Train Developers:

    * Provide training for developers on best practices for secure coding
      and input validation.
    * Encourage regular participation in security workshops and updates on
      the latest security vulnerabilities and prevention techniques.

Good Security Practices Reference

    * Adhere to best practices from reputable sources such as OWASP (Open
      Web Application Security Project), which provides guidelines and
      techniques for effective input validation.
    * Consult security standards relevant to your industry or technology
      stack, such as those from NIST (National Institute of Standards and
      Technology), to ensure compliance with security regulations and
      recommendations.

By implementing robust input validation, you protect your application from 
a wide array of attacks that exploit invalid or malicious input, thereby 
enhancing the security and stability of your systems.",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Hugo Ponthieu,,ATT&CK ICS - M0818 - Validate Program Inputs,Application Security||Data Security,NIST 800-53 v5,SI-10 INFORMATION INPUT VALIDATION
Kubernetes Namespace,C-KUBERNETES-NAMESPACE-05,Implement Lateral Movement Detection and Prevention Mechanisms,"Deploy detection and prevention mechanisms to monitor and block lateral 
movement attempts between namespaces.

1. Use network segmentation and micro-segmentation to limit communications 
between namespaces.

2. Implement intrusion detection systems (IDS) and intrusion prevention 
systems (IPS) to monitor for lateral movement attempts.

3. Regularly review and enforce network policies to restrict unnecessary 
inter-namespace communication.

4. Train incident response teams on detecting and responding to lateral 
movement within Kubernetes clusters.",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1031 - Network Intrusion Prevention,Network Security,NIST 800-53 v5,SC-7 Boundary Protection
AWS S3 (Simple Storage Service),C-AWS-S3-CNT-03,Implement least privilege access,"When granting permissions, you decide who is getting what permissions to 
which Amazon S3 resources. You enable specific actions that you want to 
allow on those resources. Therefore, we recommend that you grant only the 
permissions that are required to perform a task. Implementing least 
privilege access is fundamental in reducing security risk and the impact 
that could result from errors or malicious intent.

The following tools are available to implement least privilege access:

    * Policy actions for Amazon S3
      <https://docs.aws.amazon.com/AmazonS3/latest/userguide/security_iam_service-with-iam.html#security_iam_service-with-iam-id-based-policies-actions> 
      and Permissions Boundaries for IAM Entities
      <https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_boundaries.html>
    * How Amazon S3 works with IAM
      <https://docs.aws.amazon.com/AmazonS3/latest/userguide/security_iam_service-with-iam.html>
    * Access control list (ACL) overview
      <https://docs.aws.amazon.com/AmazonS3/latest/userguide/acl-overview.html>
    * Service Control Policies
      <https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scp.html>

For guidance on what to consider when choosing one or more of the preceding 
mechanisms, see Identity and Access Management for Amazon S3
<https://docs.aws.amazon.com/AmazonS3/latest/userguide/security-iam.html> 
.",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1026 - Privileged Account Management,Application Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
AWS S3 (Simple Storage Service),C-AWS-S3-CNT-10,Implement monitoring by using AWS monitoring tools,"Monitoring is an important part of maintaining the reliability, security, 
availability, and performance of Amazon S3 and your AWS solutions. AWS 
provides several tools and services to help you monitor Amazon S3 and your 
other AWS services. For example, you can monitor Amazon CloudWatch metrics 
for Amazon S3, particularly the PutRequests, GetRequests, 4xxErrors, and 
DeleteRequests metrics. For more information, see Monitoring metrics with 
Amazon CloudWatch
<https://docs.aws.amazon.com/AmazonS3/latest/userguide/cloudwatch-monitoring.html> 
and Monitoring Amazon S3
<https://docs.aws.amazon.com/AmazonS3/latest/userguide/monitoring-overview.html> 
.

For a second example, see Example: Amazon S3 Bucket Activity
<http://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudwatch-alarms-for-cloudtrail.html#cloudwatch-alarms-for-cloudtrail-s3-bucket-activity> 
. This example describes how to create a CloudWatch alarm that is triggered 
when an Amazon S3 API call is made to PUT or DELETE a bucket policy, a 
bucket lifecycle, or a bucket replication configuration, or to PUT a bucket 
ACL.",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1047 - Audit,Cloud Security,NIST 800-53 v5,"AU-6 Audit Record Review, Analysis, and Reporting"
Bare Metal Server,C-BARE-METAL-SERVER-CNT-01,Implement multi-factor authentication for administrative interfaces,"Implementing multi-factor authentication (MFA) for accessing server 
management interfaces is a crucial step in enhancing the security of bare 
metal servers. Below is a detailed guide on implementing this 
countermeasure:

   1. Assess Current Access Management Interfaces:
          o Identify all server management interfaces and tools in use,
            such as IPMI, iLO, or DRAC.
          o Determine which interfaces currently support MFA natively and
            which will require additional configuration or third-party
            solutions.
   2. Select an Appropriate MFA Solution:
          o Consider compatibility, ease of integration, and user
            experience when selecting an MFA solution.
          o Popular MFA providers include Google Authenticator, Microsoft
            Authenticator, Duo, and YubiKey.
   3. Configure MFA for Compatible Interfaces:
          o For management interfaces supporting MFA, access the
            configuration settings. This often involves navigating to a
            security or authentication settings menu.
          o Enable MFA and follow the solution's specific setup procedure,
            which usually includes linking a second factor method like an
            app-based authenticator or hardware token.
   4. Integrate MFA with External Solutions for Non-Compatible Interfaces:
          o If a management interface does not natively support MFA,
            consider using an external solution such as a VPN with MFA
            support or a secure gateway that requires MFA before granting
            access.
   5. Test Configuration:
          o Conduct thorough testing to ensure that MFA is correctly
            implemented, and verify that only authorized users can access
            the server management interfaces using their credentials and
            the second factor.
   6. Train Users:
          o Provide clear instructions and training to users on how to
            authenticate using the MFA solution chosen.
          o Ensure users know how to proceed if they encounter issues with
            their second factor during authentication.
   7. Monitor and Maintain:
          o Regularly review access logs to identify unauthorized access
            attempts.
          o Update the MFA system and maintain backup codes for emergency
            access.

References

    * Duo Security Documentation <https://duo.com/docs>
    * Microsoft Azure - How it works: Azure Multi-Factor Authentication
      <https://docs.microsoft.com/en-us/azure/active-directory/authentication/concept-mfa-howitworks>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Hugo Ponthieu,,EMB3D - MID-045 - Multi-factor Authentication,Operational Security,NIST 800-53 v5,IA-2 Identification and Authentication (organizational Users)
Bare Metal Server,C-BARE-METAL-SERVER-CNT-01,Implement multi-factor authentication for administrative interfaces,"Implementing multi-factor authentication (MFA) for accessing server 
management interfaces is a crucial step in enhancing the security of bare 
metal servers. Below is a detailed guide on implementing this 
countermeasure:

   1. Assess Current Access Management Interfaces:
          o Identify all server management interfaces and tools in use,
            such as IPMI, iLO, or DRAC.
          o Determine which interfaces currently support MFA natively and
            which will require additional configuration or third-party
            solutions.
   2. Select an Appropriate MFA Solution:
          o Consider compatibility, ease of integration, and user
            experience when selecting an MFA solution.
          o Popular MFA providers include Google Authenticator, Microsoft
            Authenticator, Duo, and YubiKey.
   3. Configure MFA for Compatible Interfaces:
          o For management interfaces supporting MFA, access the
            configuration settings. This often involves navigating to a
            security or authentication settings menu.
          o Enable MFA and follow the solution's specific setup procedure,
            which usually includes linking a second factor method like an
            app-based authenticator or hardware token.
   4. Integrate MFA with External Solutions for Non-Compatible Interfaces:
          o If a management interface does not natively support MFA,
            consider using an external solution such as a VPN with MFA
            support or a secure gateway that requires MFA before granting
            access.
   5. Test Configuration:
          o Conduct thorough testing to ensure that MFA is correctly
            implemented, and verify that only authorized users can access
            the server management interfaces using their credentials and
            the second factor.
   6. Train Users:
          o Provide clear instructions and training to users on how to
            authenticate using the MFA solution chosen.
          o Ensure users know how to proceed if they encounter issues with
            their second factor during authentication.
   7. Monitor and Maintain:
          o Regularly review access logs to identify unauthorized access
            attempts.
          o Update the MFA system and maintain backup codes for emergency
            access.

References

    * Duo Security Documentation <https://duo.com/docs>
    * Microsoft Azure - How it works: Azure Multi-Factor Authentication
      <https://docs.microsoft.com/en-us/azure/active-directory/authentication/concept-mfa-howitworks>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Hugo Ponthieu,,EMB3D - MID-045 - Multi-factor Authentication,Operational Security,NIST 800-53 v5,IA-2 Identification and Authentication (organizational Users)
Kubernetes Namespace,C-KUBERNETES-NAMESPACE-03,Implement Network Policies and Namespace Segmentation,"Enforce strict network policies and ensure proper segmentation between 
namespaces to prevent unauthorized access.

1. Define and implement network policies that limit communication between 
namespaces based on application requirements.

2. Utilize Kubernetes security contexts to enforce isolation between 
namespaces.

3. Regularly audit and test namespace isolation to ensure it meets security 
standards.

4. Train development teams on best practices for namespace isolation and 
network policies.",Created by Rules Engine,Recommended,Not tested,High,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1030 - Network Segmentation,Network Security,NIST 800-53 v5,AC-4 Information Flow Enforcement
Backend,C-WEB-APPLICATION-SERVER-SIDE-CNT-01,Implement prepared statements and validate user inputs,"To prevent injection attacks (e.g., SQL injection, command injection), 
implement prepared statements for all database queries and validate all 
user inputs on the server side. This ensures that user input is treated as 
data, not executable code, and prevents attackers from injecting malicious 
commands that could compromise your application or database.

Implementation Steps:

   1. Use Prepared Statements: Always use prepared statements with
      parameterized queries for interacting with the database, ensuring
      that user inputs are never directly included in SQL queries.
   2. Sanitize and Validate Inputs: Validate all incoming data on the
      server side (e.g., using whitelist validation or data type checking)
      to ensure it conforms to expected formats and ranges.
   3. Escape Output: Properly escape or encode output to prevent cross-site
      scripting (XSS) and other injection attacks when displaying
      user-provided data.
   4. Use ORM or Query Builders: If possible, use Object-Relational Mapping
      (ORM) frameworks or query builders that automatically handle safe
      query construction.
   5. Implement Content Security Policies: Use security controls like
      Content Security Policies (CSP) and Input Validation to further
      mitigate injection risks.

References:

    * OWASP SQL Injection Prevention Cheat Sheet
      <https://cheatsheetseries.owasp.org/cheatsheets/SQL_Injection_Prevention_Cheat_Sheet.html>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1057 - Data Loss Prevention,Application Security,NIST 800-53 v5,SI-10 INFORMATION INPUT VALIDATION
Fronend,C-WEB-APPLICATION-SERVER-SIDE-CNT-01,Implement prepared statements and validate user inputs,"To prevent injection attacks (e.g., SQL injection, command injection), 
implement prepared statements for all database queries and validate all 
user inputs on the server side. This ensures that user input is treated as 
data, not executable code, and prevents attackers from injecting malicious 
commands that could compromise your application or database.

Implementation Steps:

   1. Use Prepared Statements: Always use prepared statements with
      parameterized queries for interacting with the database, ensuring
      that user inputs are never directly included in SQL queries.
   2. Sanitize and Validate Inputs: Validate all incoming data on the
      server side (e.g., using whitelist validation or data type checking)
      to ensure it conforms to expected formats and ranges.
   3. Escape Output: Properly escape or encode output to prevent cross-site
      scripting (XSS) and other injection attacks when displaying
      user-provided data.
   4. Use ORM or Query Builders: If possible, use Object-Relational Mapping
      (ORM) frameworks or query builders that automatically handle safe
      query construction.
   5. Implement Content Security Policies: Use security controls like
      Content Security Policies (CSP) and Input Validation to further
      mitigate injection risks.

References:

    * OWASP SQL Injection Prevention Cheat Sheet
      <https://cheatsheetseries.owasp.org/cheatsheets/SQL_Injection_Prevention_Cheat_Sheet.html>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1057 - Data Loss Prevention,Application Security,NIST 800-53 v5,SI-10 INFORMATION INPUT VALIDATION
Web Framework,C-ACCESS-CONTROLS,Implement proper access controls and authorization checks,"To establish and enforce robust access controls and authorization checks, 
follow these steps:

    * Verify user identities thoroughly before granting access to
      resources. Implement credential-based authentication systems, and,
      where feasible, enhance security with multi-factor authentication
      (MFA) mechanisms.
    * Adopt the principle of least privilege across your application.
      Ensure that users or systems have only the minimum level of access or
      permissions they need to fulfill their functions. Regularly review
      and adjust permissions to reflect changes in user roles or system
      configurations.
    * Utilize Access Control Lists (ACLs) to define specific permissions on
      resources. Clearly specify which users or system processes can access
      certain resources and the actions they are permitted to perform.
      Apply ACLs within the file system and within the application itself
      to control access more granically.
    * Incorporate authorization checks into your application code. Before
      executing critical operations or accessing sensitive data, verify
      that the requesting user has the necessary permissions. Implement
      these checks consistently throughout the application, particularly at
      entry points for sensitive operations.
    * Implement role-based access control (RBAC) or attribute-based access
      control (ABAC) to manage permissions systematically. Define roles or
      attributes that reflect the various levels of access required by
      different users or systems, and assign permissions accordingly. This
      structured approach helps in maintaining clarity and consistency in
      access control policies.

References to good security practices include the OWASP (Open Web 
Application Security Project) guidelines on access control and the use of 
established security frameworks and libraries that support secure 
authentication and authorization mechanisms. Regularly update and patch 
these libraries to address known vulnerabilities.",Created by Rules Engine,Recommended,Not tested,High,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1032 - Multi-factor Authentication||ATT&CK Enterprise - M1018 - User Account Management||ATT&CK Enterprise - M1027 - Password Policies,Data Security||Operational Security,NIST 800-53 v5,AC-1 POLICY AND PROCEDURES||AC-3 ACCESS ENFORCEMENT||AC-6 LEAST PRIVILEGE
Web Framework,C-PROTECT-INTERNAL-REFS,Implement proper object references and binding,"Securing object references within your application is essential to 
mitigating risks related to unauthorized access, information leakage, or 
data manipulation. To properly manage object references and ensure secure 
access, follow these guidelines:

    * Utilize indirect references to manage access to sensitive objects and
      resources. Avoid using direct references such as database keys or
      file paths in user-facing components. Instead, employ indirect
      references or tokens that are mapped server-side to the actual
      resources. This approach limits exposure and reduces the risk of
      direct object reference attacks.
    * Implement binding verification mechanisms to confirm that the user or
      entity attempting to access an object is authorized to do so. This
      involves checking permissions against the user's session or
      authentication context before granting access to an object or
      executing a sensitive operation.
    * Incorporate secure session management techniques to tie object
      references to authenticated and authorized sessions. Ensure that each
      session has a defined scope of access, and validate session tokens
      against user actions to prevent unauthorized access attempts.
    * Encapsulate your objects, exposing only the necessary interfaces to
      the outside world while hiding the internal workings and sensitive
      data. This encapsulation ensures that users can only interact with
      objects through carefully controlled pathways, significantly reducing
      the risk of unintended access or manipulation.

By adopting these practices, developers can strengthen the security of 
their applications against a variety of threats stemming from improper 
object handling and access control. Always prioritize the principle of 
least privilege and ensure that access controls are rigorously applied and 
maintained across the application's components.",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1038 - Execution Prevention,Application Security||Data Security,NIST 800-53 v5,SC-8 TRANSMISSION CONFIDENTIALITY AND INTEGRITY
RESTful Web Service,C-RESTFUL-WEB-SERVICE-CNT-09,Implement proper session expiration and use secure session tokens,"To enhance the security of your RESTful Web Service, implement proper 
session expiration and use secure session tokens. Session expiration 
ensures that sessions are automatically terminated after a predefined 
period of inactivity, reducing the risk of session hijacking. Secure 
session tokens should be used to authenticate users and ensure that session 
identifiers are stored securely, transmitted over encrypted channels, and 
protected from unauthorized access or theft.

Implementation Steps:

   1. Set Session Expiry: Configure session expiration times based on user
      activity or inactivity. Ensure sessions automatically expire after a
      certain period or when the user logs out.
   2. Use Secure Tokens: Implement strong session tokens (e.g., JWT or
      OAuth tokens) that are cryptographically signed and include secure,
      random identifiers to prevent guessable session tokens.
   3. Secure Token Storage: Store session tokens in secure, HttpOnly
      cookies or in secure storage mechanisms to prevent cross-site
      scripting (XSS) or session hijacking.
   4. Use HTTPS: Ensure that all session tokens are transmitted over HTTPS
      to protect them from being intercepted during transmission.
   5. Revoke Tokens Upon Logout: Implement session token revocation
      mechanisms, ensuring tokens are invalidated when the user logs out or
      the session expires.

References:

    * JWT.io Introduction <https://jwt.io/introduction>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1032 - Multi-factor Authentication,Application Security,NIST 800-53 v5,SC-23 SESSION AUTHENTICITY
RESTful Web Service,C-RESTFUL-WEB-SERVICE-CNT-09,Implement proper session expiration and use secure session tokens,"To enhance the security of your RESTful Web Service, implement proper 
session expiration and use secure session tokens. Session expiration 
ensures that sessions are automatically terminated after a predefined 
period of inactivity, reducing the risk of session hijacking. Secure 
session tokens should be used to authenticate users and ensure that session 
identifiers are stored securely, transmitted over encrypted channels, and 
protected from unauthorized access or theft.

Implementation Steps:

   1. Set Session Expiry: Configure session expiration times based on user
      activity or inactivity. Ensure sessions automatically expire after a
      certain period or when the user logs out.
   2. Use Secure Tokens: Implement strong session tokens (e.g., JWT or
      OAuth tokens) that are cryptographically signed and include secure,
      random identifiers to prevent guessable session tokens.
   3. Secure Token Storage: Store session tokens in secure, HttpOnly
      cookies or in secure storage mechanisms to prevent cross-site
      scripting (XSS) or session hijacking.
   4. Use HTTPS: Ensure that all session tokens are transmitted over HTTPS
      to protect them from being intercepted during transmission.
   5. Revoke Tokens Upon Logout: Implement session token revocation
      mechanisms, ensuring tokens are invalidated when the user logs out or
      the session expires.

References:

    * JWT.io Introduction <https://jwt.io/introduction>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Hugo Ponthieu,,ATT&CK Enterprise - M1032 - Multi-factor Authentication,Application Security,NIST 800-53 v5,SC-23 SESSION AUTHENTICITY
RESTful Web Service,C-RESTFUL-WEB-SERVICE-CNT-04,Implement rate limiting and IP blocking,"To protect your RESTful Web Service from abuse, implement rate limiting and 
IP blocking mechanisms. Rate limiting controls the number of requests that 
a client can make in a specified time period, reducing the risk of 
denial-of-service (DoS) attacks and excessive resource consumption. IP 
blocking helps mitigate attacks from specific IP addresses by blocking 
malicious or abusive IPs after detecting suspicious behavior, such as 
multiple failed login attempts or high-frequency requests.

Implementation Steps:

   1. Define Rate Limits: Set appropriate rate limits for your API
      endpoints based on expected usage and resource constraints, ensuring
      a balance between usability and security.
   2. Dynamic Rate Limiting: Adjust rate limits based on traffic patterns
      or user behavior, allowing higher limits for trusted clients and
      lower limits for suspicious activity.
   3. Monitor IP Behavior: Track the frequency of requests from each IP
      address, and identify patterns indicative of abuse, such as repeated
      failed login attempts or excessive requests in a short time.
   4. Block Malicious IPs: Implement logic to automatically block or
      challenge requests from IP addresses that exhibit suspicious or
      abusive behavior, either temporarily or permanently.
   5. Provide Feedback: Ensure that clients receive appropriate feedback,
      such as HTTP 429 Too Many Requests status codes when rate limits are
      exceeded and HTTP 403 Forbidden status codes when IPs are blocked.

References:

    * OWASP Rate Limiting Cheat Sheet
      <https://cheatsheetseries.owasp.org/cheatsheets/Denial_of_Service_Cheat_Sheet.html>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1034 - Limit Hardware Installation,Network Security,NIST 800-53 v5,SC-50 Software-enforced Separation and Policy Enforcement
RESTful Web Service,C-RESTFUL-WEB-SERVICE-CNT-04,Implement rate limiting and IP blocking,"To protect your RESTful Web Service from abuse, implement rate limiting and 
IP blocking mechanisms. Rate limiting controls the number of requests that 
a client can make in a specified time period, reducing the risk of 
denial-of-service (DoS) attacks and excessive resource consumption. IP 
blocking helps mitigate attacks from specific IP addresses by blocking 
malicious or abusive IPs after detecting suspicious behavior, such as 
multiple failed login attempts or high-frequency requests.

Implementation Steps:

   1. Define Rate Limits: Set appropriate rate limits for your API
      endpoints based on expected usage and resource constraints, ensuring
      a balance between usability and security.
   2. Dynamic Rate Limiting: Adjust rate limits based on traffic patterns
      or user behavior, allowing higher limits for trusted clients and
      lower limits for suspicious activity.
   3. Monitor IP Behavior: Track the frequency of requests from each IP
      address, and identify patterns indicative of abuse, such as repeated
      failed login attempts or excessive requests in a short time.
   4. Block Malicious IPs: Implement logic to automatically block or
      challenge requests from IP addresses that exhibit suspicious or
      abusive behavior, either temporarily or permanently.
   5. Provide Feedback: Ensure that clients receive appropriate feedback,
      such as HTTP 429 Too Many Requests status codes when rate limits are
      exceeded and HTTP 403 Forbidden status codes when IPs are blocked.

References:

    * OWASP Rate Limiting Cheat Sheet
      <https://cheatsheetseries.owasp.org/cheatsheets/Denial_of_Service_Cheat_Sheet.html>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Hugo Ponthieu,,ATT&CK Enterprise - M1034 - Limit Hardware Installation,Network Security,NIST 800-53 v5,SC-50 Software-enforced Separation and Policy Enforcement
PostgreSQL,C-POSTGRESQL-CNT-POSTGRES-07,Implement rate limiting and resource throttling,"Implement and regularly update rate limiting and resource throttling for 
PostgreSQL to protect against denial-of-service (DoS) attacks and resource 
exhaustion. This control ensures that query rates and system resource usage 
(CPU, memory, disk I/O) are constrained within defined limits, preserving 
database availability and performance even under heavy load or attack 
conditions. Developers and DevOps engineers should integrate rate limiting 
into the query processing and utilize OS-level or middleware resource 
controls, continuously monitoring system performance to adjust thresholds 
as needed.

Implementation Steps:

Define Acceptable Thresholds:
Establish baseline limits for the number of queries, connections, and 
resource usage (CPU, memory, I/O) that the system can handle under normal 
operation.

Implement Query Rate Limiting:
Use PostgreSQL settings or middleware solutions to limit the rate at which 
queries are accepted from clients, preventing overload during traffic 
spikes.

Configure Resource Throttling:
Apply OS-level resource controls (e.g., cgroups on Linux) or similar 
mechanisms to restrict the CPU and memory usage of PostgreSQL processes, 
ensuring that no single query or connection can monopolize system 
resources.

Monitor and Audit:
Continuously track performance metrics and log query activities. Regularly 
audit resource consumption and adjust thresholds to maintain optimal 
performance and security.

References:

    * PostgreSQL Performance Tips
      <https://www.postgresql.org/docs/current/performance-tips.html>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1021 - Restrict Web-Based Content,Application Security,NIST 800-53 v5,SC-5 DENIAL-OF-SERVICE PROTECTION
Redis Server,C-REDIS-SERVER-CNT-REDIS-04,Implement rate limiting and resource throttling,"Implement and regularly update rate limiting and resource throttling for 
Redis Server to protect against denial-of-service attacks and resource 
exhaustion. This control ensures that incoming requests are controlled and 
that system resource usage (e.g., CPU, memory, I/O) is constrained, 
preventing overload caused by excessive or malicious traffic. Developers 
and DevOps engineers should integrate rate limiting policies and resource 
throttling mechanisms into their Redis deployment using built-in 
configurations or external middleware, and continuously monitor system 
performance to adjust thresholds as needed.

Implementation Steps:

Define Rate Limiting Policies:
Establish acceptable thresholds for incoming requests based on system 
capacity and expected workloads.

Implement Rate Limiting Mechanisms:
Utilize built-in Redis configurations or deploy external proxies/load 
balancers that enforce rate limiting on API calls and client connections.

Apply Resource Throttling Controls:
Configure settings to limit resource consumption (e.g., CPU, memory, and 
I/O usage) per client or connection to prevent a single source from 
overloading the system.

Monitor and Audit:
Continuously monitor performance metrics and log access patterns. Regularly 
review and adjust rate limiting and throttling settings to ensure they 
remain effective against emerging traffic patterns or attack vectors.

References:

    * OWASP API Security Project
      <https://owasp.org/www-project-api-security/>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1056 - Pre-compromise,Application Security,NIST 800-53 v5,SC-5 DENIAL-OF-SERVICE PROTECTION
Virtual Machine,C-VIRTUAL-MACHINE-CNT-07,Implement rate limiting and resource throttling to prevent DoS attacks on VMs,"To mitigate the risk of Denial of Service (DoS) attacks on virtual 
machines, implement rate limiting and resource throttling mechanisms. 
Attackers can overload VM resources by consuming excessive CPU, memory, 
disk I/O, or network bandwidth, leading to degraded performance or service 
outages. By enforcing limits on resource usage, critical workloads remain 
operational even under attack conditions.

Steps to Implement:

   1. Configure VM resource quotas for CPU, memory, disk I/O, and network
      bandwidth to prevent resource exhaustion.
   2. Enable rate limiting on network traffic to control excessive inbound
      or outbound requests.
   3. Implement automated scaling policies to adjust resources dynamically
      based on demand.
   4. Monitor VM performance and set up alerts for unusual spikes in
      resource consumption.
   5. Use firewall rules and intrusion detection systems to block malicious
      traffic patterns.

References:

    * VMware vSphere Resource Management
      <https://docs.vmware.com/en/VMware-vSphere/7.0/com.vmware.vsphere.resmgmt.doc/GUID-98BD5A8A-260A-494F-BAAE-74781F5C4B87.html>",Created by Rules Engine,Recommended,Not tested,High,N/A,High,Hugo Ponthieu,,ATT&CK Enterprise - M1052 - User Account Control,Cloud Security,NIST 800-53 v5,SC-5 DENIAL-OF-SERVICE PROTECTION
Cloudflare,C-CLOUDFLARE-04,Implement regular security configuration audits,"Conducting regular security configuration audits ensures that the system's 
security settings are correctly configured and adhere to best practices.

Steps to Implement:

   1. Develop a checklist of security configurations based on industry best
      practices and compliance requirements.
   2. Use automated tools to scan for misconfigurations in your system.
      Tools like CIS-CAT, Nessus, or OpenSCAP can help identify issues.
   3. Regularly review firewall rules, access controls, and encryption
      settings to ensure they meet security standards.
   4. Implement a process for correcting any misconfigurations identified
      during the audits.
   5. Document and track changes to the system configuration to maintain an
      audit trail.
   6. Conduct periodic training for administrators on secure configuration
      practices.

By following these steps, you can significantly reduce the risk of security 
breaches due to misconfigured settings.",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Hugo Ponthieu,,ATT&CK Enterprise - M1047 - Audit,Application Security||Data Security,NIST 800-53 v5,CM-6 Configuration Settings
PostgreSQL,C-POSTGRESQL-CNT-POSTGRES-01,Implement robust authentication and role-based access control,"Implement and regularly update robust authentication and role-based access 
control for PostgreSQL to ensure that only verified users with appropriate 
privileges can access and manage the database. This control mandates the 
use of strong authentication mechanisms (such as multi-factor 
authentication and complex passwords) and granular role-based access 
control (RBAC) to restrict permissions according to the principle of least 
privilege. Developers and DevOps engineers should integrate these practices 
into the PostgreSQL deployment using centralized identity management 
systems and enforce policies via configuration management tools.

Implementation Steps:

Enforce Strong Authentication:
Configure PostgreSQL to require strong passwords and, where applicable, 
integrate with external identity providers (e.g., LDAP, Active Directory) 
that support multi-factor authentication.

Implement Role-Based Access Control (RBAC):
Define roles with specific permissions and assign users only the privileges 
necessary for their responsibilities. Regularly review and adjust roles to 
ensure they align with current security policies.

Centralize Authentication Management:
Leverage centralized identity management systems to streamline user 
provisioning, password policies, and access audits across all PostgreSQL 
instances.

Monitor and Audit:
Enable detailed logging of authentication attempts and role changes. 
Periodically audit access logs and RBAC configurations to ensure compliance 
and detect potential anomalies.

References:

    * OWASP Authentication Cheat Sheet
      <https://cheatsheetseries.owasp.org/cheatsheets/Authentication_Cheat_Sheet.html>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1043 - Credential Access Protection,Application Security,NIST 800-53 v5,SC-23 SESSION AUTHENTICITY
RESTful Web Service,C-RESTFUL-WEB-SERVICE-CNT-06,Implement role-based access control (RBAC),"To enforce the principle of least privilege and ensure users can only 
access resources appropriate to their role, implement Role-Based Access 
Control (RBAC) in your RESTful Web Service. RBAC assigns permissions to 
roles rather than individual users, making it easier to manage user access 
at scale. Each user is assigned one or more roles, and those roles 
determine what actions the user is allowed to perform within the service.

Implementation Steps:

   1. Define Roles: Identify and define roles within your system (e.g.,
      Admin, User, Moderator) based on your service’s requirements and user
      needs.
   2. Assign Permissions to Roles: Map specific actions or resources (e.g.,
      read, write, delete) to each role to control what users can access
      and modify.
   3. Assign Roles to Users: Assign users to roles based on their job
      responsibilities and the level of access they require.
   4. Enforce RBAC at the API Level: Ensure that each API endpoint checks
      the user’s roles and verifies whether they have the necessary
      permissions to perform the requested action.
   5. Monitor and Review Role Assignments: Regularly review and update user
      roles and permissions to ensure that they align with organizational
      changes and security best practices.

References:

    * OWASP RBAC Cheat Sheet
      <https://cheatsheetseries.owasp.org/cheatsheets/Authorization_Cheat_Sheet.html>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1026 - Privileged Account Management,Application Security,NIST 800-53 v5,PS-6 Access Agreements
RESTful Web Service,C-RESTFUL-WEB-SERVICE-CNT-06,Implement role-based access control (RBAC),"To enforce the principle of least privilege and ensure users can only 
access resources appropriate to their role, implement Role-Based Access 
Control (RBAC) in your RESTful Web Service. RBAC assigns permissions to 
roles rather than individual users, making it easier to manage user access 
at scale. Each user is assigned one or more roles, and those roles 
determine what actions the user is allowed to perform within the service.

Implementation Steps:

   1. Define Roles: Identify and define roles within your system (e.g.,
      Admin, User, Moderator) based on your service’s requirements and user
      needs.
   2. Assign Permissions to Roles: Map specific actions or resources (e.g.,
      read, write, delete) to each role to control what users can access
      and modify.
   3. Assign Roles to Users: Assign users to roles based on their job
      responsibilities and the level of access they require.
   4. Enforce RBAC at the API Level: Ensure that each API endpoint checks
      the user’s roles and verifies whether they have the necessary
      permissions to perform the requested action.
   5. Monitor and Review Role Assignments: Regularly review and update user
      roles and permissions to ensure that they align with organizational
      changes and security best practices.

References:

    * OWASP RBAC Cheat Sheet
      <https://cheatsheetseries.owasp.org/cheatsheets/Authorization_Cheat_Sheet.html>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Hugo Ponthieu,,ATT&CK Enterprise - M1026 - Privileged Account Management,Application Security,NIST 800-53 v5,PS-6 Access Agreements
Virtual Machine,C-VIRTUAL-MACHINE-CNT-01,Implement Role-Based Access Control (RBAC) and enforce strong authentication mechanisms,"To protect virtual machines from unauthorized access, enforce Role-Based 
Access Control (RBAC) and strong authentication mechanisms. RBAC ensures 
that users have only the necessary permissions based on their roles, 
minimizing the risk of privilege misuse. Strong authentication, such as 
multi-factor authentication (MFA), adds an extra layer of security against 
credential-based attacks.

Steps to Implement:

   1. Define user roles and assign the minimum necessary permissions
      following the principle of least privilege.
   2. Use built-in RBAC features in cloud platforms (e.g., Azure RBAC, AWS
      IAM, vSphere Roles) to manage access control.
   3. Enable multi-factor authentication (MFA) for all administrative and
      privileged accounts.
   4. Regularly review access logs and audit permissions to remove
      unnecessary privileges.
   5. Implement Just-in-Time (JIT) access to limit the duration of
      administrative sessions.

References:

    * VMware vSphere Permissions and Roles
      <https://docs.vmware.com/en/VMware-vSphere/6.7/com.vmware.vsphere.security.doc/GUID-FAA074CC-E8C9-4F13-ABCF-6CF7F15F04EE.html>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Hugo Ponthieu,,ATT&CK Enterprise - M1022 - Restrict File and Directory Permissions,Application Security,NIST 800-53 v5,PS-6 Access Agreements
Kubernetes Namespace,C-KUBERNETES-NAMESPACE-01,Implement Role-Based Access Control (RBAC) Auditing and Least Privilege,"Regularly audit Role-Based Access Control (RBAC) configurations to ensure 
that roles and role bindings are set according to the principle of least 
privilege.

1. Review all roles and role bindings to ensure they adhere to the least 
privilege principle.

2. Implement automated tools to monitor and alert on any deviations from 
RBAC best practices.

3. Regularly update and enforce RBAC policies as per security guidelines.

4. Conduct periodic reviews and audits of the RBAC configurations.",Created by Rules Engine,Recommended,Not tested,High,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1026 - Privileged Account Management,Application Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
PostgreSQL,C-POSTGRESQL-CNT-POSTGRES-08,Implement secure backup procedures with encryption and access controls,"Implement and regularly update secure backup procedures with encryption and 
access controls for PostgreSQL to protect backup data against unauthorized 
access and tampering. This control ensures that all backup files are 
encrypted using strong cryptographic standards (e.g., AES-256) and that 
access to these backups is restricted to authorized personnel only. 
Developers and DevOps engineers should integrate secure backup mechanisms 
into their PostgreSQL deployment process using automated backup tools and 
centralized management systems to enforce encryption and access policies 
consistently.

Implementation Steps:

Encrypt Backup Files:
Configure backup tools to encrypt PostgreSQL backup files using robust 
encryption algorithms before storage or transmission.

Enforce Access Controls:
Use OS-level permissions, cloud storage access policies, or centralized 
management tools to restrict backup file access to authorized users only.

Automate Backup Processes:
Integrate automated backup solutions that enforce encryption and access 
controls, ensuring consistent and secure backup routines across all 
PostgreSQL instances.

Monitor and Audit Backup Procedures:
Regularly review backup logs and conduct audits to verify that encryption 
and access controls are maintained and that backup data remains secure.

References:

    * PostgreSQL Backup and Restore Documentation
      <https://www.postgresql.org/docs/current/backup.html>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1056 - Pre-compromise,Data Security,NIST 800-53 v5,CP-9 System Backup
"*.beep,ovh",C-IMPLEMENT-SECURE-PROTOCOLS-AND-ACCESS-CONTROLS,Implement Secure Protocols and Access Controls,"Implementing secure protocols and robust access controls is essential for 
protecting sensitive data and system resources from unauthorized access and 
breaches. Secure protocols ensure data integrity and confidentiality during 
transmission, while access controls limit user privileges and activities 
based on predefined policies.

Steps to Implement Secure Protocols and Access Controls

Assess Current Security Posture:

    * Conduct an audit of existing network and application protocols,
      authentication methods, and access controls.
    * Identify potential vulnerabilities or outdated practices that could
      compromise security.

Implement Secure Communication Protocols:

    * Upgrade all network communications to use secure protocols such as
      HTTPS for web traffic, TLS for email, and SSH instead of Telnet for
      remote administration.
    * Configure SSL/TLS settings to use strong ciphers and the latest
      protocol versions.

Define Access Control Policies:

    * Establish comprehensive access control policies that define who can
      access what resources and under what conditions.
    * Consider both physical and logical access controls, incorporating
      factors like job roles, data sensitivity, and environmental context.

Apply the Principle of Least Privilege:

    * Ensure that all user accounts, especially those with administrative
      access, only have the minimum necessary permissions to perform their
      tasks.
    * Regularly review and adjust permissions to ensure they are aligned
      with current job requirements and organizational policies.

Use Multi-Factor Authentication (MFA):

    * Implement MFA for accessing critical systems, particularly for remote
      access and administrative interfaces.
    * Choose authentication factors that include something you know
      (password), something you have (security token), and something you
      are (biometrics).

Secure Authentication Mechanisms:

    * Store user credentials securely using salted hashing techniques.
    * Avoid using default credentials and enforce strong password policies
      that require a mix of letters, numbers, and special characters.

Implement Role-Based Access Control (RBAC):

    * Define roles based on the access needs of different user groups
      within your organization.
    * Assign permissions to roles rather than individuals to simplify
      management and ensure consistent application of security policies.

Monitor and Log Access Events:

    * Set up comprehensive logging for access events to track who accessed
      what resources and when.
    * Use automated monitoring tools to detect and alert on unusual access
      patterns or unauthorized access attempts.

Regularly Review and Update Security Configurations:

    * Schedule regular reviews and updates of security protocols, access
      controls, and policies to adapt to new threats or changes in the
      organization.
    * Include security considerations in your change management processes
      to ensure ongoing compliance with best practices.

Educate and Train Employees:

    * Provide regular training on security awareness and protocols to all
      employees.
    * Specifically train IT staff and system administrators on the latest
      security practices and tools.

Good Security Practices Reference

    * Follow guidelines from organizations like the National Institute of
      Standards and Technology (NIST) for recommendations on secure
      protocols and access controls.
    * Refer to the ISO/IEC 27001 standard for information security
      management best practices that include secure communications and
      access management.

By carefully implementing secure protocols and robust access controls, 
organizations can significantly enhance their defense against unauthorized 
access and data breaches, ensuring the security and integrity of their 
information systems.",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Hugo Ponthieu,,ATT&CK Enterprise - M1041 - Encrypt Sensitive Information,Data Security||Network Security,NIST 800-53 v5,AC-3 ACCESS ENFORCEMENT||SC-13 Cryptographic Protection
Web Framework,C-SESSION-MANAGEMENT,Implement secure session management including using built-in mechanisms,"To safeguard your application against unauthorized access and session-based 
attacks, it's critical to implement robust session management practices. 
Follow these guidelines to ensure secure session management:

    * Transmit session IDs exclusively over HTTPS to prevent interception.
      Ensure your entire site is accessible only through HTTPS to avoid
      exposing sensitive information.
    * Adopt server-side session management. Store session identifiers
      securely on the server and avoid exposing them in URLs or on the
      client side.
    * Implement session expiration policies. Set sessions to expire after a
      predetermined period of inactivity and enforce absolute timeout
      limits to further reduce the risk of unauthorized session use.
    * When managing sessions with cookies, apply the HttpOnly and Secure
      flags to prevent access to the session cookie via client-side scripts
      and ensure cookies are sent only over secure connections,
      respectively. Use the SameSite cookie attribute to mitigate CSRF
      attacks.
    * Regularly check session integrity and user authenticity through
      session metadata. This could include validation checks against user
      agent strings, IP addresses, or other session tokens that ensure the
      session has not been hijacked.
    * Ensure sessions are securely terminated by deleting session data on
      the server and clearing session cookies on the client when the user
      logs out or the session expires. This helps prevent session hijacking
      and reuse.
    * To combat session fixation, generate a new session ID with a new
      cookie after user login to replace the old session ID that could have
      been compromised.
    * Maintain logs of session-related events and actively monitor for
      signs of attack, such as repeated failed login attempts or suspicious
      session activity, to quickly identify and respond to security
      threats.

By adhering to these steps, developers can create a more secure environment 
for users, protecting them from session hijacking, session fixation, and 
CSRF attacks among other session-related vulnerabilities.",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1018 - User Account Management||ATT&CK Enterprise - M1039 - Environment Variable Permissions,Application Security,NIST 800-53 v5,AC-12 SESSION TERMINATION||AU-14 Session Audit||SC-10 NETWORK DISCONNECT||SC-23 SESSION AUTHENTICITY
"*.beep,ovh",C-IMPLEMENT-SECURE-ZONE-TRANSFER-PROTOCOLS-AND-DNSSEC,Implement Secure Zone Transfer Protocols and DNSSEC,"Secure zone transfer protocols and DNS Security Extensions (DNSSEC) are 
critical in protecting DNS data integrity and preventing DNS-based attacks 
like cache poisoning and spoofing. Implementing these security measures 
ensures that the DNS information is accurate and transmitted securely 
between authorized servers only.

Steps to Implement Secure Zone Transfer Protocols and DNSSEC

Assess Existing DNS Configuration:

    * Audit your current DNS infrastructure to identify how zone transfers
      are currently managed and identify any existing vulnerabilities.
    * Document all authoritative DNS servers and their relationships
      (primary, secondary).

Implement Secure Zone Transfer Protocols:

    * Configure DNS servers to use secure protocols like TSIG (Transaction
      Signature) or SIG(0) for authenticating DNS zone transfers between
      servers. These methods use cryptographic signatures to validate the
      authenticity of the DNS data being exchanged.
    * Restrict zone transfers to only allow requests from specific IP
      addresses of known secondary servers.

Deploy DNSSEC:

    * Enable DNSSEC on all authoritative DNS servers to add digital
      signatures to DNS data, ensuring its integrity and authenticity.
    * Generate and securely store cryptographic keys used in the DNSSEC
      signing process. Consider using a hardware security module (HSM) for
      key management.
    * Configure DNS zones to sign zone data automatically upon changes to
      ensure all records are validated.

Update Resolver Configuration:

    * Ensure that DNS resolvers are configured to validate DNSSEC
      signatures on DNS responses. This helps prevent clients from
      accepting forged DNS data.
    * Test DNSSEC validation to ensure it works correctly without
      disrupting DNS resolution services.

Secure and Monitor Key Management:

    * Implement policies for key creation, storage, rotation, and
      destruction. Regularly rotate DNSSEC keys according to best practices
      to minimize the risk of key compromise.
    * Monitor the use of DNSSEC keys and audit key management activities to
      detect and respond to any unauthorized access or anomalies.

Educate Network Administrators:

    * Train DNS administrators on the importance of secure DNS
      configurations, focusing on secure zone transfers and DNSSEC.
    * Provide ongoing training to keep up with advancements in DNS security
      technologies and threats.

Regularly Audit DNS Security:

    * Conduct regular security audits to ensure that zone transfer settings
      and DNSSEC configurations adhere to security policies.
    * Review and update these configurations as needed to adapt to new
      security challenges or changes in the network infrastructure.

Plan for Emergency Response:

    * Develop an incident response plan specifically for DNS security
      breaches, including procedures for addressing compromised DNS keys or
      unauthorized zone transfers.
    * Practice DNS-specific drills to ensure that your team can respond
      quickly and effectively to DNS-related security incidents.

Good Security Practices Reference

    * Follow guidelines from the Internet Engineering Task Force (IETF) and
      the Internet Corporation for Assigned Names and Numbers (ICANN) for
      implementing secure DNS practices.
    * Adhere to best practices recommended by cybersecurity organizations
      such as the National Institute of Standards and Technology (NIST) for
      DNS security.

By implementing secure zone transfer protocols and DNSSEC, organizations 
can significantly enhance the security of their DNS infrastructure. This 
not only protects against common DNS threats but also helps maintain the 
reliability and integrity of internet operations within the organization.",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Hugo Ponthieu,,ATT&CK Enterprise - M1041 - Encrypt Sensitive Information,Network Security,NIST 800-53 v5,SC-20 Secure Name/address Resolution Service (authoritative Source)||SC-21 Secure Name/address Resolution Service (recursive or Caching Resolver)
Backend,C-WEB-APPLICATION-SERVER-SIDE-CNT-12,Implement server-side checks and multi-step validation for important transactions,"To prevent workflow abuses, especially for critical or sensitive 
transactions, implement server-side checks and multi-step validation. This 
ensures that transactions are properly validated at multiple points in the 
process, reducing the risk of unauthorized actions, fraud, or exploitation 
of business workflows.

Implementation Steps:

   1. Define Critical Transactions: Identify which transactions are
      critical (e.g., financial transactions, user permissions changes) and
      require extra validation to ensure security.
   2. Server-Side Validation: Ensure that all business rules, permissions,
      and workflows are validated on the server side, rather than relying
      solely on client-side validation.
   3. Multi-Step Validation Process: Implement a multi-step validation
      process for important transactions, requiring approval or
      confirmation at multiple stages (e.g., email confirmation, admin
      approval, CAPTCHA verification).
   4. Audit Trail: Maintain a detailed audit trail for critical
      transactions, logging every step and any changes made, so that any
      suspicious activity can be detected and reviewed.
   5. Review and Update Validation Rules Regularly: Periodically review and
      update the validation rules to adapt to new business requirements and
      emerging threats.

References:

    * PCI DSS Quick Reference Guide
      <https://listings.pcisecuritystandards.org/documents/PCI_DSS-QRG-v3_2_1.pdf>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1057 - Data Loss Prevention,Application Security,NIST 800-53 v5,"AU-6 Audit Record Review, Analysis, and Reporting"
Fronend,C-WEB-APPLICATION-SERVER-SIDE-CNT-12,Implement server-side checks and multi-step validation for important transactions,"To prevent workflow abuses, especially for critical or sensitive 
transactions, implement server-side checks and multi-step validation. This 
ensures that transactions are properly validated at multiple points in the 
process, reducing the risk of unauthorized actions, fraud, or exploitation 
of business workflows.

Implementation Steps:

   1. Define Critical Transactions: Identify which transactions are
      critical (e.g., financial transactions, user permissions changes) and
      require extra validation to ensure security.
   2. Server-Side Validation: Ensure that all business rules, permissions,
      and workflows are validated on the server side, rather than relying
      solely on client-side validation.
   3. Multi-Step Validation Process: Implement a multi-step validation
      process for important transactions, requiring approval or
      confirmation at multiple stages (e.g., email confirmation, admin
      approval, CAPTCHA verification).
   4. Audit Trail: Maintain a detailed audit trail for critical
      transactions, logging every step and any changes made, so that any
      suspicious activity can be detected and reviewed.
   5. Review and Update Validation Rules Regularly: Periodically review and
      update the validation rules to adapt to new business requirements and
      emerging threats.

References:

    * PCI DSS Quick Reference Guide
      <https://listings.pcisecuritystandards.org/documents/PCI_DSS-QRG-v3_2_1.pdf>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1057 - Data Loss Prevention,Application Security,NIST 800-53 v5,"AU-6 Audit Record Review, Analysis, and Reporting"
Bare Metal Server,C-BARE-METAL-SERVER-CNT-05,Implement side-channel resistance techniques,"Implementing effective countermeasures to obscure data leakage and mitigate 
side-channel attacks on Bare Metal Servers involves both hardware and 
software strategies. Follow the guide below to ensure the security of your 
components.

Step-by-Step Guidance:

1. Implement Hardware-Level Noise Creation

Introduce controlled noise in the server's emitted signals to confuse any 
eavesdropping entities attempting to gather data through side-channel 
analysis.

    * Equip your server's motherboard with noise-generating devices that
      emit random signals alongside genuine ones.
    * Adjust the noise level dynamically to prevent attackers from
      filtering out the noise using predictable patterns.
    * Ensure proper calibration to maintain the server's performance while
      effectively obscuring data emissions.

2. Design Software Execution Paths for Constant Time

Alter software execution paths to prevent attackers from inferring data by 
measuring execution times.

    * Use cryptographic libraries designed with constant-time algorithms to
      prevent timing attacks. For example, instead of using standard
      comparison functions, employ specialized constant-time comparison
      methods for sensitive data.
    * Rewrite critical sections of code to ensure all conditional branches
      execute within the same time frame, eliminating variances based on
      input data.
    * Incorporate testing protocols that analyze execution time to identify
      and address potential anomalies.

3. Regular Audits and Updates

Consistently evaluate and update both hardware and software components to 
defend against evolving attack methods.

    * Schedule regular security audits that specifically target potential
      side-channel vulnerabilities.
    * Keep abreast of the latest research and developments in side-channel
      attack methodologies and defenses.
    * Update hardware and software components as new vulnerabilities are
      discovered and patched.

Additional Tips:

    * Utilize noise analysis tools during prototyping to measure the
      effectiveness of added noise on data signals.
    * Document all changes and implementations for internal audits and
      future reference.

References

    * Side Channel Attacks
      <https://semiengineering.com/knowledge_centers/semiconductor-security/side-channel-attacks/>
    * Side Channels: Attacks, Defences, and Evaluation Schemes
      <https://csrc.nist.gov/csrc/media/Presentations/2021/crypto-club-2021-side-channels-1/images-media/crclub-2021-side-channels-1.pdf>",Created by Rules Engine,Recommended,Not tested,High,N/A,High,Hugo Ponthieu,,EMB3D - MID-059 - Software Patterns for Side Channel Resistance,Hardware Security,NIST 800-53 v5,SI-6 Security and Privacy Function Verification
Bare Metal Server,C-BARE-METAL-SERVER-CNT-05,Implement side-channel resistance techniques,"Implementing effective countermeasures to obscure data leakage and mitigate 
side-channel attacks on Bare Metal Servers involves both hardware and 
software strategies. Follow the guide below to ensure the security of your 
components.

Step-by-Step Guidance:

1. Implement Hardware-Level Noise Creation

Introduce controlled noise in the server's emitted signals to confuse any 
eavesdropping entities attempting to gather data through side-channel 
analysis.

    * Equip your server's motherboard with noise-generating devices that
      emit random signals alongside genuine ones.
    * Adjust the noise level dynamically to prevent attackers from
      filtering out the noise using predictable patterns.
    * Ensure proper calibration to maintain the server's performance while
      effectively obscuring data emissions.

2. Design Software Execution Paths for Constant Time

Alter software execution paths to prevent attackers from inferring data by 
measuring execution times.

    * Use cryptographic libraries designed with constant-time algorithms to
      prevent timing attacks. For example, instead of using standard
      comparison functions, employ specialized constant-time comparison
      methods for sensitive data.
    * Rewrite critical sections of code to ensure all conditional branches
      execute within the same time frame, eliminating variances based on
      input data.
    * Incorporate testing protocols that analyze execution time to identify
      and address potential anomalies.

3. Regular Audits and Updates

Consistently evaluate and update both hardware and software components to 
defend against evolving attack methods.

    * Schedule regular security audits that specifically target potential
      side-channel vulnerabilities.
    * Keep abreast of the latest research and developments in side-channel
      attack methodologies and defenses.
    * Update hardware and software components as new vulnerabilities are
      discovered and patched.

Additional Tips:

    * Utilize noise analysis tools during prototyping to measure the
      effectiveness of added noise on data signals.
    * Document all changes and implementations for internal audits and
      future reference.

References

    * Side Channel Attacks
      <https://semiengineering.com/knowledge_centers/semiconductor-security/side-channel-attacks/>
    * Side Channels: Attacks, Defences, and Evaluation Schemes
      <https://csrc.nist.gov/csrc/media/Presentations/2021/crypto-club-2021-side-channels-1/images-media/crclub-2021-side-channels-1.pdf>",Created by Rules Engine,Recommended,Not tested,High,N/A,High,Hugo Ponthieu,,EMB3D - MID-059 - Software Patterns for Side Channel Resistance,Hardware Security,NIST 800-53 v5,SI-6 Security and Privacy Function Verification
Web Framework,C-SQLI,"Implement SQLi protections, e.g., parameterized queries","Protecting your application from SQL Injection (SQLi) attacks is crucial 
for maintaining data integrity and security. SQLi attacks exploit 
vulnerabilities in data input handling, allowing attackers to execute 
unauthorized SQL statements. Follow these steps to implement effective SQLi 
protections:

    * Always use parameterized queries when interacting with the database.
      Parameterized queries ensure that user input is treated as data, not
      as executable code. This prevents attackers from injecting malicious
      SQL code into your database queries.
    * Utilize Object-Relational Mapping (ORM) libraries provided by your
      framework. ORMs like Django's ORM for Python or Sequelize for Node.js
      with Express.js automatically apply parameterized queries and data
      escaping, reducing the risk of SQLi attacks.
    * Never construct SQL queries by concatenating strings and user inputs.
      If parameterized queries are not an option, ensure that user inputs
      are rigorously validated and sanitized before inclusion in SQL
      statements.
    * Implement regular expression checks or use built-in validation
      mechanisms to validate user inputs against expected patterns,
      minimizing the chance of malicious input passing through.
    * Limit database permissions for the application's database user. Apply
      the principle of least privilege by granting only the permissions
      necessary for the application to operate. This minimizes potential
      damage in case of a successful SQL injection attack.
    * Conduct regular code reviews and security testing, including static
      analysis and penetration testing, to identify and mitigate SQL
      injection vulnerabilities.
    * Educate developers about the risks of SQL injection and the
      importance of using parameterized queries and other preventive
      measures as part of secure coding practices.

Adopting these practices will significantly reduce your application's 
vulnerability to SQL injection attacks, ensuring the security of your data 
and the integrity of your application.",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1030 - Network Segmentation||ATT&CK Enterprise - M1050 - Exploit Protection||ATT&CK Enterprise - M1048 - Application Isolation and Sandboxing,Application Security,NIST 800-53 v5,SI-10 INFORMATION INPUT VALIDATION
Bare Metal Server,C-BARE-METAL-SERVER-CNT-06,Implement strict access controls and activity monitoring,"Implementing robust security measures on a bare metal server is crucial for 
protecting sensitive data and maintaining system integrity. One effective 
security strategy involves the use of role-based access controls (RBAC) 
combined with comprehensive monitoring solutions. Below are the steps to 
effectively implement this countermeasure:

   1. Define Roles and Permissions: Start by identifying various roles
      within your organization and map them to necessary job functions.
      Create a detailed list of permissions needed for each role. Ensure
      that these roles align with the principle of least privilege,
      granting only the necessary permissions needed to perform specific
      tasks.
   2. Implement RBAC on the Server: Use the server’s operating system
      capabilities to create user accounts and assign them to defined
      roles. For Linux-based servers, this can involve configuring user and
      group permissions through local security policies or using tools like
      sudoers for managing administrative access.
   3. Deploy Monitoring Solutions: Choose a monitoring solution that is
      compatible with your server’s operating environment. Install and
      configure the monitoring software to track activities such as login
      attempts, file access, and any changes made to system configurations.
   4. Set Up Alerts for Unusual Activity: Within the monitoring solution,
      configure alerts to be triggered by specific criteria that indicate
      unusual activities. This can include repeated failed login attempts,
      access attempts outside normal working hours, or modifications to
      critical files.
   5. Regularly Review and Update Access Controls: Periodically review role
      permissions and update them to reflect changes in job functions or
      personnel. Ensure that accounts of former employees are timely
      deactivated or removed.
   6. Conduct Training and Awareness Programs: Organize training sessions
      for employees to educate them on the importance of RBAC and how to
      recognize potential security threats. Ensure that IT staff are
      well-versed in monitoring tools and response protocols.

By carefully implementing these steps, organizations can significantly 
enhance the security posture of their bare metal servers. Continuous 
monitoring and regular updates to access controls are key to adapting to 
emerging threats and reducing the risk of unauthorized access.

References

    * Navigating the Landscape of IT Hardware Security
      <https://www.clyk.tech/blog/trends-and-insights-in-it-hardware-security>",Created by Rules Engine,Recommended,Not tested,Very high,N/A,High,Hugo Ponthieu,,EMB3D - MID-012 - OS-based Access Control Mechanisms,Operational Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Bare Metal Server,C-BARE-METAL-SERVER-CNT-06,Implement strict access controls and activity monitoring,"Implementing robust security measures on a bare metal server is crucial for 
protecting sensitive data and maintaining system integrity. One effective 
security strategy involves the use of role-based access controls (RBAC) 
combined with comprehensive monitoring solutions. Below are the steps to 
effectively implement this countermeasure:

   1. Define Roles and Permissions: Start by identifying various roles
      within your organization and map them to necessary job functions.
      Create a detailed list of permissions needed for each role. Ensure
      that these roles align with the principle of least privilege,
      granting only the necessary permissions needed to perform specific
      tasks.
   2. Implement RBAC on the Server: Use the server’s operating system
      capabilities to create user accounts and assign them to defined
      roles. For Linux-based servers, this can involve configuring user and
      group permissions through local security policies or using tools like
      sudoers for managing administrative access.
   3. Deploy Monitoring Solutions: Choose a monitoring solution that is
      compatible with your server’s operating environment. Install and
      configure the monitoring software to track activities such as login
      attempts, file access, and any changes made to system configurations.
   4. Set Up Alerts for Unusual Activity: Within the monitoring solution,
      configure alerts to be triggered by specific criteria that indicate
      unusual activities. This can include repeated failed login attempts,
      access attempts outside normal working hours, or modifications to
      critical files.
   5. Regularly Review and Update Access Controls: Periodically review role
      permissions and update them to reflect changes in job functions or
      personnel. Ensure that accounts of former employees are timely
      deactivated or removed.
   6. Conduct Training and Awareness Programs: Organize training sessions
      for employees to educate them on the importance of RBAC and how to
      recognize potential security threats. Ensure that IT staff are
      well-versed in monitoring tools and response protocols.

By carefully implementing these steps, organizations can significantly 
enhance the security posture of their bare metal servers. Continuous 
monitoring and regular updates to access controls are key to adapting to 
emerging threats and reducing the risk of unauthorized access.

References

    * Navigating the Landscape of IT Hardware Security
      <https://www.clyk.tech/blog/trends-and-insights-in-it-hardware-security>",Created by Rules Engine,Recommended,Not tested,Very high,N/A,High,Hugo Ponthieu,,EMB3D - MID-012 - OS-based Access Control Mechanisms,Operational Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Cloudflare,C-CLOUDFLARE-06,Implement strong API security measures,"Implementing strong API security measures is essential to prevent 
unauthorized access to your APIs. These measures help ensure that only 
authorized users and applications can access the APIs.

Steps to Implement:

   1. Use strong authentication mechanisms for API access, such as OAuth
      2.0 or API keys with granular permissions.
   2. Implement rate limiting and throttling to prevent abuse of the APIs.
   3. Ensure that all API endpoints use HTTPS to encrypt data in transit.
   4. Regularly review and update API access controls to ensure they adhere
      to the principle of least privilege.
   5. Monitor API usage and set up alerts for any suspicious or abnormal
      activities.
   6. Conduct regular security testing of the APIs to identify and
      remediate vulnerabilities.

By following these steps, you can significantly reduce the risk of 
unauthorized API access and ensure the security of your system.",Created by Rules Engine,Recommended,Not tested,High,N/A,High,Hugo Ponthieu,,ATT&CK Enterprise - M1031 - Network Intrusion Prevention,Application Security,NIST 800-53 v5,SC-17 Public Key Infrastructure Certificates
Redis Server,C-REDIS-SERVER-CNT-REDIS-01,Implement strong authentication and ACLs,"Implement and regularly update strong authentication and ACLs for Redis 
Server to ensure that only verified users can access the system and that 
their actions are tightly controlled. This control mandates the use of 
robust authentication mechanisms (e.g., strong passwords, multi-factor 
authentication) and the configuration of granular Access Control Lists 
(ACLs) to restrict command execution and data access based on the principle 
of least privilege. Developers and DevOps engineers should integrate these 
controls into Redis configurations using centralized management tools and 
continuously monitor access logs to verify compliance and detect any 
unauthorized activities.

Implementation Steps:

Enforce Strong Authentication:
Configure Redis to require strong passwords and, where applicable, 
integrate with centralized authentication services to enforce multi-factor 
authentication.

Configure Granular ACLs:
Define and apply ACLs to specify allowed commands and restrict access to 
sensitive data, ensuring that each user or application has only the 
permissions necessary for their function.

Integrate with Centralized Identity Management:
Utilize identity providers or centralized management systems to manage user 
credentials and enforce consistent authentication policies across your 
infrastructure.

Monitor and Audit:
Enable logging for authentication attempts and access events, and perform 
regular audits of ACL configurations to ensure that access controls remain 
effective and up-to-date.

References:

    * Redis ACL Documentation
      <https://redis.io/docs/latest/operate/rc/security/access-control/data-access-control/configure-acls/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1021 - Restrict Web-Based Content,Application Security,NIST 800-53 v5,AC-2 ACCOUNT MANAGEMENT
RESTful Web Service,C-RESTFUL-WEB-SERVICE-CNT-01,Implement strong authentication mechanisms,"To ensure the integrity and security of user identities, implement strong 
authentication mechanisms for your RESTful Web Service. Strong 
authentication reduces the risk of unauthorized access by requiring users 
to provide multiple forms of verification, such as passwords, biometrics, 
or tokens. This typically includes multi-factor authentication (MFA) to 
ensure that even if one factor is compromised, the user account remains 
secure.

Implementation Steps:

   1. Enforce Multi-Factor Authentication (MFA): Require users to
      authenticate using at least two factors, such as something they know
      (password), something they have (security token, mobile device), or
      something they are (biometric data).
   2. Use Strong Password Policies: Implement strong password policies,
      including minimum length, complexity, and expiration periods, to
      reduce the risk of weak passwords being exploited.
   3. Implement Secure Token-Based Authentication: Use secure token-based
      authentication methods (e.g., JWT, OAuth) for API access to ensure
      that tokens are securely issued, validated, and managed.
   4. Leverage OAuth or OpenID Connect: For third-party authentication,
      implement OAuth 2.0 or OpenID Connect to allow users to securely
      authenticate with trusted identity providers.
   5. Monitor and Revoke Sessions: Regularly monitor active sessions for
      any suspicious activity and implement mechanisms to revoke or expire
      sessions after logout, inactivity, or suspicious login attempts.

References:

    * OWASP Authentication Cheat Sheet
      <https://cheatsheetseries.owasp.org/cheatsheets/Authentication_Cheat_Sheet.html>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1032 - Multi-factor Authentication,Application Security,NIST 800-53 v5,IA-5 AUTHENTICATOR MANAGEMENT
RESTful Web Service,C-RESTFUL-WEB-SERVICE-CNT-01,Implement strong authentication mechanisms,"To ensure the integrity and security of user identities, implement strong 
authentication mechanisms for your RESTful Web Service. Strong 
authentication reduces the risk of unauthorized access by requiring users 
to provide multiple forms of verification, such as passwords, biometrics, 
or tokens. This typically includes multi-factor authentication (MFA) to 
ensure that even if one factor is compromised, the user account remains 
secure.

Implementation Steps:

   1. Enforce Multi-Factor Authentication (MFA): Require users to
      authenticate using at least two factors, such as something they know
      (password), something they have (security token, mobile device), or
      something they are (biometric data).
   2. Use Strong Password Policies: Implement strong password policies,
      including minimum length, complexity, and expiration periods, to
      reduce the risk of weak passwords being exploited.
   3. Implement Secure Token-Based Authentication: Use secure token-based
      authentication methods (e.g., JWT, OAuth) for API access to ensure
      that tokens are securely issued, validated, and managed.
   4. Leverage OAuth or OpenID Connect: For third-party authentication,
      implement OAuth 2.0 or OpenID Connect to allow users to securely
      authenticate with trusted identity providers.
   5. Monitor and Revoke Sessions: Regularly monitor active sessions for
      any suspicious activity and implement mechanisms to revoke or expire
      sessions after logout, inactivity, or suspicious login attempts.

References:

    * OWASP Authentication Cheat Sheet
      <https://cheatsheetseries.owasp.org/cheatsheets/Authentication_Cheat_Sheet.html>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Hugo Ponthieu,,ATT&CK Enterprise - M1032 - Multi-factor Authentication,Application Security,NIST 800-53 v5,IA-5 AUTHENTICATOR MANAGEMENT
VPN (Virtual Private Network),C-VPN-VIRTUAL-PRIVATE-NETWORK-CNT-02,"Implement strong, recommended cipher suites to enhance VPN encryption strength and integrity","Configure the VPN to use only strong, recommended cipher suites to ensure 
robust encryption, protect data integrity, and defend against cryptographic 
attacks. This practice mitigates vulnerabilities associated with weak or 
deprecated encryption algorithms and protocols.

Select Strong Cipher Suites:

    * Use modern encryption algorithms such as AES-256 for symmetric
      encryption and SHA-256 or stronger for hashing.
    * Include key exchange mechanisms like Elliptic Curve Diffie-Hellman
      (ECDH) to enhance security.

Disable Weak Cipher Suites:

    * Remove deprecated algorithms such as RC4, MD5, 3DES, or SHA-1.
    * Avoid protocols known to have vulnerabilities, such as SSL, TLS 1.0,
      and TLS 1.1.

Align with Industry Standards:

    * Follow guidelines like NIST SP 800-52, CIS Benchmarks, or
      recommendations from the VPN vendor for approved cipher suites.
    * Regularly review and update configurations to align with evolving
      cryptographic standards.

Configure the VPN Server:

    * Specify allowed cipher suites in the VPN server settings.
    * Test the configurations to ensure that only the selected cipher
      suites are enabled.

Test and Validate Encryption:

    * Use tools like SSL Labs, OpenSSL, or vendor-specific diagnostics to
      verify that the VPN is using the intended cipher suites.
    * Simulate scenarios to confirm compatibility with client devices and
      applications.

Monitor for Compliance:

    * Continuously monitor the VPN for any deviations in cipher suite
      configurations.
    * Enable logging to detect unauthorized changes or usage of weak
      encryption.

Educate Administrators:

    * Train administrators on the importance of strong encryption and best
      practices for maintaining secure configurations.
    * Provide guidelines on troubleshooting issues related to encryption
      settings.

By implementing only strong, recommended cipher suites, developers and 
DevOps engineers can ensure the VPN provides robust encryption and 
maintains the integrity of data transmitted over the network.

References:

    * NIST SP 800-52: Guidelines for TLS Configurations
      <https://csrc.nist.gov/publications/detail/sp/800-52/rev-2/final>",Created by Rules Engine,Recommended,Not tested,Very high,N/A,High,Hugo Ponthieu,,ATT&CK Enterprise - M1041 - Encrypt Sensitive Information,Network Security,NIST 800-53 v5,SC-8 TRANSMISSION CONFIDENTIALITY AND INTEGRITY
Cloudflare,C-CLOUDFLARE-05,Implement User Behavior Analytics (UBA),"Implementing User Behavior Analytics (UBA) helps detect and mitigate 
insider threats by monitoring and analyzing user activities for unusual or 
malicious behavior.

Steps to Implement:

   1. Select a UBA tool that integrates well with your existing security
      infrastructure.
   2. Configure the UBA tool to monitor user activities, including logins,
      file access, and network usage.
   3. Define and customize baseline behaviors for normal user activities.
   4. Set up alerts and automated responses for detected anomalies that
      deviate from baseline behaviors.
   5. Regularly review UBA reports and investigate flagged incidents.
   6. Conduct periodic audits and update baselines as user roles and
      behaviors evolve.

By following these steps, you can effectively detect and respond to insider 
threats, ensuring the security of your system.",Created by Rules Engine,Recommended,Not tested,Very high,N/A,High,Hugo Ponthieu,,ATT&CK Enterprise - M1040 - Behavior Prevention on Endpoint,Operational Security,NIST 800-53 v5,SI-4 System Monitoring
API Gateway,C-API-GATEWAY-CNT-01,Integrate the API gateway with an identity management application,"To effectively provision credentials before activating the API and prevent 
unauthorized access, follow these detailed steps:

   1. Identify Credential Requirements:
          o Determine the type of authentication your API will support
            (e.g., OAuth 2.0, API Key, JWT).
          o Define user roles and permissions associated with different
            levels of access to the API.
   2. Generate Secure Credentials:
          o Use a reliable and secure method to generate API keys or
            tokens. Consider using libraries like JWT <https://jwt.io/> 
            for JSON Web Tokens.
          o Apply strong cryptographic practices like using a secure random
            function for generating secrets.
   3. Establish Credential Distribution Mechanism:
          o Set up an access control mechanism that ensures only authorized
            individuals or systems can request and receive credentials.
          o Utilize secure channels such as TLS/SSL to transmit credentials
            during distribution.
   4. Configure API Gateway:
          o Segregate the API activation stage to ensure credentials are
            mandatory before any API consumption.
          o Implement infrastructure configuration that enforces credential
            verification for each API request.
          o Consider using API management platforms like AWS API Gateway
            <https://aws.amazon.com/api-gateway/> or Google Cloud API
            Gateway <https://cloud.google.com/api-gateway> to streamline
            this process.
   5. Test Credential Mechanisms:
          o Conduct thorough testing on how credentials interact with your
            API, ensuring that unauthorized access is denied.
          o Regularly perform security audits to check for vulnerabilities
            in the credential provisioning and verification process.
   6. Monitor Credential Usage:
          o Implement logging mechanisms to track the usage of credentials
            and analyze access patterns.
          o Set up alerts for suspicious behavior or potential credential
            compromises, using tools like Datadog
            <https://www.datadoghq.com/> or Elastic Security
            <https://www.elastic.co/security> .

Following these steps will help ensure a robust credential provisioning 
strategy, enhancing the security of your API gateway and protecting against 
unauthorized access.

References

    * OAuth 2.0 Getting Started <https://oauth.net/getting-started/>
    * JWT Introduction <https://jwt.io/introduction/>
    * AWS API Gateway <https://aws.amazon.com/api-gateway/>
    * Google Cloud API Gateway <https://cloud.google.com/api-gateway>
    * Datadog <https://www.datadoghq.com/>
    * Elastic Security <https://www.elastic.co/security>",Created by Rules Engine,Recommended,Not tested,High,N/A,High,Hugo Ponthieu,,ATT&CK Enterprise - M1036 - Account Use Policies,Application Security,NIST 800-53 v5,AC-2 ACCOUNT MANAGEMENT
VPN (Virtual Private Network),C-VPN-VIRTUAL-PRIVATE-NETWORK-CNT-06,Integrate VPN logs with a SIEM system for real-time analysis and alerts,"Integrate VPN logs into a Security Information and Event Management (SIEM) 
system to enable centralized log management, real-time analysis, and 
automated alerts. This integration enhances the ability to detect, 
investigate, and respond to suspicious activity or security incidents in 
the VPN environment.

Select a SIEM Solution:

    * Choose a SIEM platform such as Splunk, ELK Stack (Elasticsearch,
      Logstash, Kibana), or IBM QRadar that supports integration with your
      VPN solution.
    * Ensure the SIEM has capabilities for correlation, alerting, and
      visualization of VPN-specific events.

Configure Log Forwarding:

    * Enable log generation on the VPN server for all critical activities,
      such as login attempts, session creation, data transfer, and
      configuration changes.
    * Forward logs securely to the SIEM system using encrypted transport
      protocols like Syslog over TLS.

Define Use Cases and Alerts:

    * Create correlation rules to identify suspicious behaviors, such as
      failed login attempts, connections from untrusted locations, or
      unusual data transfer volumes.
    * Configure automated alerts to notify security teams of high-priority
      events in real-time.

Enable Dashboards and Reporting:

    * Build custom dashboards to visualize VPN usage patterns, security
      incidents, and system health metrics.
    * Generate periodic reports to track compliance and monitor the
      effectiveness of security controls.

Perform Regular Log Reviews:

    * Set up processes to review logs and alerts regularly, ensuring no
      critical incidents are overlooked.
    * Use the SIEM’s analytics capabilities to identify trends and areas
      for improvement.

Integrate with Incident Response:

    * Define workflows for investigating and responding to alerts generated
      by the SIEM system.
    * Use automated playbooks to accelerate containment and remediation of
      identified threats.

Ensure Compliance:

    * Retain logs for an appropriate period to meet regulatory or
      organizational compliance requirements.
    * Protect stored logs with encryption and access controls to prevent
      unauthorized access.

By integrating VPN logs with a SIEM system, developers and DevOps engineers 
can achieve enhanced visibility into VPN activity, detect potential threats 
in real-time, and respond effectively to incidents, ensuring the security 
of the VPN and connected networks.

References:

    * NIST Guide to Security Log Management
      <https://csrc.nist.gov/publications/detail/sp/800-92/final>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Hugo Ponthieu,,ATT&CK Enterprise - M1057 - Data Loss Prevention,Network Security,NIST 800-53 v5,SI-4 System Monitoring
Kubernetes Namespace,C-KUBERNETES-NAMESPACE-04,Limit Service Account Privileges and Perform Regular Audits,"Ensure service accounts within namespaces are granted only the privileges 
necessary to perform their functions.

1. Define roles for service accounts with the minimum necessary privileges.

2. Implement tools to monitor and alert on changes in service account 
permissions.

3. Perform regular audits to review service account privileges and adjust 
as necessary.

4. Enforce the use of short-lived tokens and rotate credentials regularly.",Created by Rules Engine,Recommended,Not tested,High,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1026 - Privileged Account Management,Application Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Cluster,C-KUBERNETES-CLUSTER-CNT-06,"Limit use of the Bind, Impersonate and Escalate permissions in the Kubernetes cluster","CIS Benchmark Recommendation id: 5.1.8

Profile Applicability: Level 1 - Master Node

Description: Cluster roles and roles with the impersonate, bind, or 
escalate permissions should not be granted unless strictly required. Each 
of these permissions allow a particular subject to escalate their 
privileges beyond those explicitly granted by cluster administrators.

Rationale: The impersonate privilege allows a subject to impersonate other 
users gaining their rights to the cluster. The bind privilege allows the 
subject to add a binding to a cluster role or role which escalates their 
effective permissions in the cluster. The escalate privilege allows a 
subject to modify cluster roles to which they are bound, increasing their 
rights to that level. Each of these permissions has the potential to allow 
for privilege escalation to clusteradmin level.

Impact: There are some cases where these permissions are required for 
cluster service operation, and care should be taken before removing these 
permissions from system service accounts.

Audit: Review the users who have access to cluster roles or roles which 
provide the impersonate, bind, or escalate privileges.

Remediation: Where possible, remove the impersonate, bind, and escalate 
rights from subjects.

Default Value: In a default kubeadm cluster, the system:masters group and 
clusterrole-aggregationcontroller service account have access to the 
escalate privilege. The system:masters group also has access to bind and 
impersonate.

References:

   1. <https://www.impidio.com/blog/kubernetes-rbac-security-pitfalls>
   2. <https://raesene.github.io/blog/2020/12/12/Escalating_Away/>
   3. 
      <https://raesene.github.io/blog/2021/01/16/Getting-Into-A-Bind-with-Kubernetes/>

 ",Created by Rules Engine,Recommended,Not tested,High,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1038 - Execution Prevention,Cloud Security,NIST 800-53 v5,AC-5 SEPARATION OF DUTIES
Kubernetes Cluster,C-KUBERNETES-CLUSTER-CNT-05,Minimize access to create persistent volumes,"CIS Benchmark Recommendation id: 5.1.9

Profile Applicability: • Level 1 - Master Node

Description: The ability to create persistent volumes in a cluster can 
provide an opportunity for privilege escalation, via the creation of 
hostPath volumes. As persistent volumes are not covered by Pod Security 
Admission, a user with access to create persistent volumes may be able to 
get access to sensitive files from the underlying host even where 
restrictive Pod Security Admission policies are in place.

Rationale: The ability to create persistent volumes in a cluster opens up 
possibilities for privilege escalation and should be restricted, where 
possible.

Impact: None

Audit: Review the users who have create access to PersistentVolume objects 
in the Kubernetes API.

Remediation: Where possible, remove create access to PersistentVolume 
objects in the cluster.

Default Value: None

References:

   1. 
      <https://kubernetes.io/docs/concepts/security/rbac-good-practices/#persistentvolume-creation>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1029 - Remote Data Storage,Cloud Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Cluster,C-KUBERNETES-CLUSTER-CNT-12,Minimize access to create pods,"CIS Benchmark Recommendation id: 5.1.4

Profile Applicability: Level 1 - Master Node

Description: The ability to create pods in a namespace can provide a number 
of opportunities for privilege escalation, such as assigning privileged 
service accounts to these pods or mounting hostPaths with access to 
sensitive data (unless Pod Security Policies are implemented to restrict 
this access). As such, access to create new pods should be restricted to 
the smallest possible group of users.

Rationale: The ability to create pods in a cluster opens up possibilities 
for privilege escalation and should be restricted, where possible.

Impact: Care should be taken not to remove access to pods to system 
components which require this for their operation

Audit: Review the users who have create access to pod objects in the 
Kubernetes API.

Remediation: Where possible, remove create access to pod objects in the 
cluster.

Default Value: By default in a kubeadm cluster the following list of 
principals have create privileges on pod objects

CLUSTERROLEBINDING                                    SUBJECT               
              TYPE            SA-NAMESPACE

cluster-admin                                         system:masters        
              Group           

system:controller:clusterrole-aggregation-controller  
clusterrole-aggregation-controller  ServiceAccount  kube-system

system:controller:daemon-set-controller               daemon-set-controller 
              ServiceAccount  kube-system

system:controller:job-controller                      job-controller        
              ServiceAccount  kube-system

system:controller:persistent-volume-binder            
persistent-volume-binder            ServiceAccount  kube-system

system:controller:replicaset-controller               replicaset-controller 
              ServiceAccount  kube-system

system:controller:replication-controller              
replication-controller              ServiceAccount  kube-system

system:controller:statefulset-controller              
statefulset-controller              ServiceAccount  kube-system

References:
N/A",Created by Rules Engine,Recommended,Not tested,High,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1035 - Limit Access to Resource Over Network,Cloud Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Cluster,C-KUBERNETES-CLUSTER-CNT-04,Minimize access to secrets,"CIS Benchmark Recommendation id: 5.1.2

Profile Applicability: Level 1 - Master Node

Description: The Kubernetes API stores secrets, which may be service 
account tokens for the Kubernetes API or credentials used by workloads in 
the cluster. Access to these secrets should be restricted to the smallest 
possible group of users to reduce the risk of privilege escalation.

Rationale: Inappropriate access to secrets stored within the Kubernetes 
cluster can allow for an attacker to gain additional access to the 
Kubernetes cluster or external resources whose credentials are stored as 
secrets.

Impact: Care should be taken not to remove access to secrets to system 
components which require this for their operation.

Audit: Review the users who have get, list or watch access to secrets 
objects in the Kubernetes API.

Remediation: Where possible, remove get, list and watch access to secret 
objects in the cluster.

Default Value: By default in a kubeadm cluster the following list of 
principals have get privileges on secret objects

CLUSTERROLEBINDING                                    SUBJECT               
              TYPE            SA-NAMESPACE

cluster-admin                                         system:masters        
              Group

system:controller:clusterrole-aggregation-controller  
clusterrole-aggregation-controller  ServiceAccount  kube-system

system:controller:expand-controller                   expand-controller     
              ServiceAccount  kube-system

system:controller:generic-garbage-collector           
generic-garbage-collector           ServiceAccount  kube-system

system:controller:namespace-controller                namespace-controller  
              ServiceAccount  kube-system

system:controller:persistent-volume-binder            
persistent-volume-binder            ServiceAccount  kube-system

system:kube-controller-manager                        
system:kube-controller-manager      User

References: N/A",Created by Rules Engine,Recommended,Not tested,High,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1026 - Privileged Account Management,Cloud Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Cluster,C-KUBERNETES-CLUSTER-CNT-16,Minimize access to the approval sub-resource of certificatesigningrequests objects,"CIS Benchmark Recommendation id: 5.1.11

Profile Applicability: Level 1 - Master Node

Description: Users with access to update the approval sub-resource of 
certificatesigningrequests objects can approve new client certificates for 
the Kubernetes API effectively allowing them to create new high-privileged 
user accounts. This can allow for privilege escalation to full cluster 
administrator, depending on users configured in the cluster.

Rationale: The ability to update certificate signing requests should be 
limited.

Impact: None

Audit: Review the users who have access to update the approval sub-resource 
of certificatesigningrequests objects in the Kubernetes API.

Remediation: Where possible, remove access to the approval sub-resource of 
certificatesigningrequests objects.

Default Value: None

References:

   1. 
      <https://kubernetes.io/docs/concepts/security/rbac-good-practices/#csrs-andcertificate-issuing>",Created by Rules Engine,Recommended,Not tested,High,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1026 - Privileged Account Management,Application Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Cluster,C-KUBERNETES-CLUSTER-CNT-09,Minimize access to the proxy sub-resource of nodes,"CIS Benchmark Recommendation id: 5.1.10

Profile Applicability: • Level 1 - Master Node

Description: Users with access to the Proxy sub-resource of Node objects 
automatically have permissions to use the Kubelet API, which may allow for 
privilege escalation or bypass cluster security controls such as audit 
logs. The Kubelet provides an API which includes rights to execute commands 
in any container running on the node. Access to this API is covered by 
permissions to the main Kubernetes API via the node object. The proxy 
sub-resource specifically allows wide ranging access to the Kubelet API. 
Direct access to the Kubelet API bypasses controls like audit logging 
(there is no audit log of Kubelet API access) and admission control.

Rationale: The ability to use the proxy sub-resource of node objects opens 
up possibilities for privilege escalation and should be restricted, where 
possible.

Impact: None

Audit: Review the users who have access to the proxy sub-resource of node 
objects in the Kubernetes API.

Remediation: Where possible, remove access to the proxy sub-resource of 
node objects.

Default Value: None

References:

   1. 
      <https://kubernetes.io/docs/concepts/security/rbac-good-practices/#access-toproxy-subresource-of-nodes>
   2. 
      <https://kubernetes.io/docs/reference/access-authn-authz/kubelet-authnauthz/#kubelet-authorization>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1036 - Account Use Policies,Application Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Cluster,C-KUBERNETES-CLUSTER-CNT-14,Minimize access to the service account token creation,"CIS Benchmark Recommendation id: 5.1.13

Profile Applicability: Level 1 - Master Node

Description: Users with rights to create new service account tokens at a 
cluster level can create long-lived privileged credentials in the cluster. 
This could allow for privilege escalation and persistent access to the 
cluster, even if the user's account has been revoked.

Rationale: The ability to create service account tokens should be limited.

Impact: None

Audit: Review the users who have access to create the token sub-resource of 
service account objects in the Kubernetes API.

Remediation: Where possible, remove access to the token sub-resource of 
service account objects.

Default Value: None

References:

   1. 
      <https://kubernetes.io/docs/concepts/security/rbac-good-practices/#token-request>",Created by Rules Engine,Recommended,Not tested,High,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1047 - Audit,Cloud Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Cluster,C-KUBERNETES-CLUSTER-CNT-10,Minimize access to webhook configuration objects,"CIS Benchmark Recommendation id: 5.1.12

Profile Applicability: Level 1 - Master Node

Description: Users with rights to create/modify/delete 
validatingwebhookconfigurations or mutatingwebhookconfigurations can 
control webhooks that can read any object admitted to the cluster, and in 
the case of mutating webhooks, also mutate admitted objects. This could 
allow for privilege escalation or disruption of the operation of the 
cluster.

Rationale: The ability to manage webhook configuration should be limited

Impact: None

Audit: Review the users who have access to validatingwebhookconfigurations 
or mutatingwebhookconfigurations objects in the Kubernetes API.

Remediation: Where possible, remove access to the 
validatingwebhookconfigurations or mutatingwebhookconfigurations objects

Default Value: None

References:

   1. 
      <https://kubernetes.io/docs/concepts/security/rbac-good-practices/#controladmission-webhooks>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1054 - Software Configuration,Application Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Pod,C-KUBERNETES-POD-CNT-14,Minimize the admission of containers which use HostPorts,"CIS Benchmark Recommendation id: 5.2.13

Profile Applicability: Level 1 - Master Node

Description: Do not generally permit containers which require the use of 
HostPorts.

Rationale: Host ports connect containers directly to the host's network. 
This can bypass controls such as network policy. There should be at least 
one admission control policy defined which does not permit containers which 
require the use of HostPorts. If you need to run containers which require 
HostPorts, this should be defined in a separate policy and you should 
carefully check to ensure that only limited service accounts and users are 
given permission to use that policy.

Impact: Pods defined with hostPort settings in either the container, 
initContainer or ephemeralContainer sections will not be permitted unless 
they are run under a specific policy.

Audit: List the policies in use for each namespace in the cluster, ensure 
that each policy disallows the admission of containers which have hostPort 
sections.

Remediation: Add policies to each namespace in the cluster which has user 
workloads to restrict the admission of containers which use hostPort 
sections.

Default Value: By default, there are no restrictions on the use of 
HostPorts.

References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1037 - Filter Network Traffic,Network Security,NIST 800-53 v5,AC-24 Access Control Decisions
Kubernetes Pod,C-KUBERNETES-POD-CNT-14,Minimize the admission of containers which use HostPorts,"CIS Benchmark Recommendation id: 5.2.13

Profile Applicability: Level 1 - Master Node

Description: Do not generally permit containers which require the use of 
HostPorts.

Rationale: Host ports connect containers directly to the host's network. 
This can bypass controls such as network policy. There should be at least 
one admission control policy defined which does not permit containers which 
require the use of HostPorts. If you need to run containers which require 
HostPorts, this should be defined in a separate policy and you should 
carefully check to ensure that only limited service accounts and users are 
given permission to use that policy.

Impact: Pods defined with hostPort settings in either the container, 
initContainer or ephemeralContainer sections will not be permitted unless 
they are run under a specific policy.

Audit: List the policies in use for each namespace in the cluster, ensure 
that each policy disallows the admission of containers which have hostPort 
sections.

Remediation: Add policies to each namespace in the cluster which has user 
workloads to restrict the admission of containers which use hostPort 
sections.

Default Value: By default, there are no restrictions on the use of 
HostPorts.

References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1037 - Filter Network Traffic,Network Security,NIST 800-53 v5,AC-24 Access Control Decisions
Kubernetes Pod,C-KUBERNETES-POD-CNT-14,Minimize the admission of containers which use HostPorts,"CIS Benchmark Recommendation id: 5.2.13

Profile Applicability: Level 1 - Master Node

Description: Do not generally permit containers which require the use of 
HostPorts.

Rationale: Host ports connect containers directly to the host's network. 
This can bypass controls such as network policy. There should be at least 
one admission control policy defined which does not permit containers which 
require the use of HostPorts. If you need to run containers which require 
HostPorts, this should be defined in a separate policy and you should 
carefully check to ensure that only limited service accounts and users are 
given permission to use that policy.

Impact: Pods defined with hostPort settings in either the container, 
initContainer or ephemeralContainer sections will not be permitted unless 
they are run under a specific policy.

Audit: List the policies in use for each namespace in the cluster, ensure 
that each policy disallows the admission of containers which have hostPort 
sections.

Remediation: Add policies to each namespace in the cluster which has user 
workloads to restrict the admission of containers which use hostPort 
sections.

Default Value: By default, there are no restrictions on the use of 
HostPorts.

References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1037 - Filter Network Traffic,Network Security,NIST 800-53 v5,AC-24 Access Control Decisions
Kubernetes Pod,C-KUBERNETES-POD-CNT-14,Minimize the admission of containers which use HostPorts,"CIS Benchmark Recommendation id: 5.2.13

Profile Applicability: Level 1 - Master Node

Description: Do not generally permit containers which require the use of 
HostPorts.

Rationale: Host ports connect containers directly to the host's network. 
This can bypass controls such as network policy. There should be at least 
one admission control policy defined which does not permit containers which 
require the use of HostPorts. If you need to run containers which require 
HostPorts, this should be defined in a separate policy and you should 
carefully check to ensure that only limited service accounts and users are 
given permission to use that policy.

Impact: Pods defined with hostPort settings in either the container, 
initContainer or ephemeralContainer sections will not be permitted unless 
they are run under a specific policy.

Audit: List the policies in use for each namespace in the cluster, ensure 
that each policy disallows the admission of containers which have hostPort 
sections.

Remediation: Add policies to each namespace in the cluster which has user 
workloads to restrict the admission of containers which use hostPort 
sections.

Default Value: By default, there are no restrictions on the use of 
HostPorts.

References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1037 - Filter Network Traffic,Network Security,NIST 800-53 v5,AC-24 Access Control Decisions
Kubernetes Pod,C-KUBERNETES-POD-CNT-14,Minimize the admission of containers which use HostPorts,"CIS Benchmark Recommendation id: 5.2.13

Profile Applicability: Level 1 - Master Node

Description: Do not generally permit containers which require the use of 
HostPorts.

Rationale: Host ports connect containers directly to the host's network. 
This can bypass controls such as network policy. There should be at least 
one admission control policy defined which does not permit containers which 
require the use of HostPorts. If you need to run containers which require 
HostPorts, this should be defined in a separate policy and you should 
carefully check to ensure that only limited service accounts and users are 
given permission to use that policy.

Impact: Pods defined with hostPort settings in either the container, 
initContainer or ephemeralContainer sections will not be permitted unless 
they are run under a specific policy.

Audit: List the policies in use for each namespace in the cluster, ensure 
that each policy disallows the admission of containers which have hostPort 
sections.

Remediation: Add policies to each namespace in the cluster which has user 
workloads to restrict the admission of containers which use hostPort 
sections.

Default Value: By default, there are no restrictions on the use of 
HostPorts.

References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1037 - Filter Network Traffic,Network Security,NIST 800-53 v5,AC-24 Access Control Decisions
Kubernetes Pod,C-KUBERNETES-POD-CNT-04,Minimize the admission of containers wishing to share the host IPC namespace,"CIS Benchmark Recommendation id: 5.2.4
Profile Applicability: Level 1 - Master Node
Description: Do not generally permit containers to be run with the hostIPC 
flag set to true.
Rationale: A container running in the host's IPC namespace can use IPC to 
interact with processes outside the container. There should be at least one 
admission control policy defined which does not permit containers to share 
the host IPC namespace. If you need to run containers which require 
hostIPC, this should be defined in a separate policy and you should 
carefully check to ensure that only limited service accounts and users are 
given permission to use that policy.
Impact: Pods defined with spec.hostIPC: true will not be permitted unless 
they are run under a specific policy.
Audit: To fetch hostIPC from each pod:
get pods -A -o=jsonpath=$'{range .items[*]}{@.metadata.name}: 
{@.spec.hostIPC}\n{end}'
Remediation: Add policies to each namespace in the cluster which has user 
workloads to restrict the admission of hostIPC containers.
Default Value: By default, there are no restrictions on the creation of 
hostIPC containers.
References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1025 - Privileged Process Integrity,Network Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Pod,C-KUBERNETES-POD-CNT-04,Minimize the admission of containers wishing to share the host IPC namespace,"CIS Benchmark Recommendation id: 5.2.4
Profile Applicability: Level 1 - Master Node
Description: Do not generally permit containers to be run with the hostIPC 
flag set to true.
Rationale: A container running in the host's IPC namespace can use IPC to 
interact with processes outside the container. There should be at least one 
admission control policy defined which does not permit containers to share 
the host IPC namespace. If you need to run containers which require 
hostIPC, this should be defined in a separate policy and you should 
carefully check to ensure that only limited service accounts and users are 
given permission to use that policy.
Impact: Pods defined with spec.hostIPC: true will not be permitted unless 
they are run under a specific policy.
Audit: To fetch hostIPC from each pod:
get pods -A -o=jsonpath=$'{range .items[*]}{@.metadata.name}: 
{@.spec.hostIPC}\n{end}'
Remediation: Add policies to each namespace in the cluster which has user 
workloads to restrict the admission of hostIPC containers.
Default Value: By default, there are no restrictions on the creation of 
hostIPC containers.
References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1025 - Privileged Process Integrity,Network Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Pod,C-KUBERNETES-POD-CNT-04,Minimize the admission of containers wishing to share the host IPC namespace,"CIS Benchmark Recommendation id: 5.2.4
Profile Applicability: Level 1 - Master Node
Description: Do not generally permit containers to be run with the hostIPC 
flag set to true.
Rationale: A container running in the host's IPC namespace can use IPC to 
interact with processes outside the container. There should be at least one 
admission control policy defined which does not permit containers to share 
the host IPC namespace. If you need to run containers which require 
hostIPC, this should be defined in a separate policy and you should 
carefully check to ensure that only limited service accounts and users are 
given permission to use that policy.
Impact: Pods defined with spec.hostIPC: true will not be permitted unless 
they are run under a specific policy.
Audit: To fetch hostIPC from each pod:
get pods -A -o=jsonpath=$'{range .items[*]}{@.metadata.name}: 
{@.spec.hostIPC}\n{end}'
Remediation: Add policies to each namespace in the cluster which has user 
workloads to restrict the admission of hostIPC containers.
Default Value: By default, there are no restrictions on the creation of 
hostIPC containers.
References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1025 - Privileged Process Integrity,Network Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Pod,C-KUBERNETES-POD-CNT-04,Minimize the admission of containers wishing to share the host IPC namespace,"CIS Benchmark Recommendation id: 5.2.4
Profile Applicability: Level 1 - Master Node
Description: Do not generally permit containers to be run with the hostIPC 
flag set to true.
Rationale: A container running in the host's IPC namespace can use IPC to 
interact with processes outside the container. There should be at least one 
admission control policy defined which does not permit containers to share 
the host IPC namespace. If you need to run containers which require 
hostIPC, this should be defined in a separate policy and you should 
carefully check to ensure that only limited service accounts and users are 
given permission to use that policy.
Impact: Pods defined with spec.hostIPC: true will not be permitted unless 
they are run under a specific policy.
Audit: To fetch hostIPC from each pod:
get pods -A -o=jsonpath=$'{range .items[*]}{@.metadata.name}: 
{@.spec.hostIPC}\n{end}'
Remediation: Add policies to each namespace in the cluster which has user 
workloads to restrict the admission of hostIPC containers.
Default Value: By default, there are no restrictions on the creation of 
hostIPC containers.
References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1025 - Privileged Process Integrity,Network Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Pod,C-KUBERNETES-POD-CNT-04,Minimize the admission of containers wishing to share the host IPC namespace,"CIS Benchmark Recommendation id: 5.2.4
Profile Applicability: Level 1 - Master Node
Description: Do not generally permit containers to be run with the hostIPC 
flag set to true.
Rationale: A container running in the host's IPC namespace can use IPC to 
interact with processes outside the container. There should be at least one 
admission control policy defined which does not permit containers to share 
the host IPC namespace. If you need to run containers which require 
hostIPC, this should be defined in a separate policy and you should 
carefully check to ensure that only limited service accounts and users are 
given permission to use that policy.
Impact: Pods defined with spec.hostIPC: true will not be permitted unless 
they are run under a specific policy.
Audit: To fetch hostIPC from each pod:
get pods -A -o=jsonpath=$'{range .items[*]}{@.metadata.name}: 
{@.spec.hostIPC}\n{end}'
Remediation: Add policies to each namespace in the cluster which has user 
workloads to restrict the admission of hostIPC containers.
Default Value: By default, there are no restrictions on the creation of 
hostIPC containers.
References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1025 - Privileged Process Integrity,Network Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Pod,C-KUBERNETES-POD-CNT-06,Minimize the admission of containers wishing to share the host network namespace,"CIS Benchmark Recommendation id: 5.2.5 
Profile Applicability: Level 1 - Master Node 

Description: Do not generally permit containers to be run with the 
hostNetwork flag set to true.

Rationale: A container running in the host's network namespace could access 
the local loopback device, and could access network traffic to and from 
other pods. There should be at least one admission control policy defined 
which does not permit containers to share the host network namespace. If 
you need to run containers which require access to the host's network 
namespaces, this should be defined in a separate policy and you should 
carefully check to ensure that only limited service accounts and users are 
given permission to use that policy.

Impact: Pods defined with spec.hostNetwork: true will not be permitted 
unless they are run under a specific policy.

Audit: To fetch hostNetwork from each pod. 

get pods -A -o=jsonpath=$'{range .items[*]}{@.metadata.name}: 
{@.spec.hostNetwork}\n{end}' 

Remediation: Add policies to each namespace in the cluster which has user 
workloads to restrict the admission of hostNetwork containers.

Default Value: By default, there are no restrictions on the creation of 
hostNetwork containers.

References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1054 - Software Configuration,Network Security,NIST 800-53 v5,SC-7 Boundary Protection
Kubernetes Pod,C-KUBERNETES-POD-CNT-06,Minimize the admission of containers wishing to share the host network namespace,"CIS Benchmark Recommendation id: 5.2.5 
Profile Applicability: Level 1 - Master Node 

Description: Do not generally permit containers to be run with the 
hostNetwork flag set to true.

Rationale: A container running in the host's network namespace could access 
the local loopback device, and could access network traffic to and from 
other pods. There should be at least one admission control policy defined 
which does not permit containers to share the host network namespace. If 
you need to run containers which require access to the host's network 
namespaces, this should be defined in a separate policy and you should 
carefully check to ensure that only limited service accounts and users are 
given permission to use that policy.

Impact: Pods defined with spec.hostNetwork: true will not be permitted 
unless they are run under a specific policy.

Audit: To fetch hostNetwork from each pod. 

get pods -A -o=jsonpath=$'{range .items[*]}{@.metadata.name}: 
{@.spec.hostNetwork}\n{end}' 

Remediation: Add policies to each namespace in the cluster which has user 
workloads to restrict the admission of hostNetwork containers.

Default Value: By default, there are no restrictions on the creation of 
hostNetwork containers.

References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1054 - Software Configuration,Network Security,NIST 800-53 v5,SC-7 Boundary Protection
Kubernetes Pod,C-KUBERNETES-POD-CNT-06,Minimize the admission of containers wishing to share the host network namespace,"CIS Benchmark Recommendation id: 5.2.5 
Profile Applicability: Level 1 - Master Node 

Description: Do not generally permit containers to be run with the 
hostNetwork flag set to true.

Rationale: A container running in the host's network namespace could access 
the local loopback device, and could access network traffic to and from 
other pods. There should be at least one admission control policy defined 
which does not permit containers to share the host network namespace. If 
you need to run containers which require access to the host's network 
namespaces, this should be defined in a separate policy and you should 
carefully check to ensure that only limited service accounts and users are 
given permission to use that policy.

Impact: Pods defined with spec.hostNetwork: true will not be permitted 
unless they are run under a specific policy.

Audit: To fetch hostNetwork from each pod. 

get pods -A -o=jsonpath=$'{range .items[*]}{@.metadata.name}: 
{@.spec.hostNetwork}\n{end}' 

Remediation: Add policies to each namespace in the cluster which has user 
workloads to restrict the admission of hostNetwork containers.

Default Value: By default, there are no restrictions on the creation of 
hostNetwork containers.

References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1054 - Software Configuration,Network Security,NIST 800-53 v5,SC-7 Boundary Protection
Kubernetes Pod,C-KUBERNETES-POD-CNT-06,Minimize the admission of containers wishing to share the host network namespace,"CIS Benchmark Recommendation id: 5.2.5 
Profile Applicability: Level 1 - Master Node 

Description: Do not generally permit containers to be run with the 
hostNetwork flag set to true.

Rationale: A container running in the host's network namespace could access 
the local loopback device, and could access network traffic to and from 
other pods. There should be at least one admission control policy defined 
which does not permit containers to share the host network namespace. If 
you need to run containers which require access to the host's network 
namespaces, this should be defined in a separate policy and you should 
carefully check to ensure that only limited service accounts and users are 
given permission to use that policy.

Impact: Pods defined with spec.hostNetwork: true will not be permitted 
unless they are run under a specific policy.

Audit: To fetch hostNetwork from each pod. 

get pods -A -o=jsonpath=$'{range .items[*]}{@.metadata.name}: 
{@.spec.hostNetwork}\n{end}' 

Remediation: Add policies to each namespace in the cluster which has user 
workloads to restrict the admission of hostNetwork containers.

Default Value: By default, there are no restrictions on the creation of 
hostNetwork containers.

References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1054 - Software Configuration,Network Security,NIST 800-53 v5,SC-7 Boundary Protection
Kubernetes Pod,C-KUBERNETES-POD-CNT-06,Minimize the admission of containers wishing to share the host network namespace,"CIS Benchmark Recommendation id: 5.2.5 
Profile Applicability: Level 1 - Master Node 

Description: Do not generally permit containers to be run with the 
hostNetwork flag set to true.

Rationale: A container running in the host's network namespace could access 
the local loopback device, and could access network traffic to and from 
other pods. There should be at least one admission control policy defined 
which does not permit containers to share the host network namespace. If 
you need to run containers which require access to the host's network 
namespaces, this should be defined in a separate policy and you should 
carefully check to ensure that only limited service accounts and users are 
given permission to use that policy.

Impact: Pods defined with spec.hostNetwork: true will not be permitted 
unless they are run under a specific policy.

Audit: To fetch hostNetwork from each pod. 

get pods -A -o=jsonpath=$'{range .items[*]}{@.metadata.name}: 
{@.spec.hostNetwork}\n{end}' 

Remediation: Add policies to each namespace in the cluster which has user 
workloads to restrict the admission of hostNetwork containers.

Default Value: By default, there are no restrictions on the creation of 
hostNetwork containers.

References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1054 - Software Configuration,Network Security,NIST 800-53 v5,SC-7 Boundary Protection
Kubernetes Pod,C-KUBERNETES-POD-CNT-16,Minimize the admission of containers wishing to share the host process ID namespace,"CIS Benchmark Recommendation id: 5.2.3
Profile Applicability: Level 1 - Master Node 

Description: Do not generally permit containers to be run with the hostPID 
flag set to true. 

Rationale: A container running in the host's PID namespace can inspect 
processes running outside the container. If the container also has access 
to ptrace capabilities this can be used to escalate privileges outside of 
the container. There should be at least one admission control policy 
defined which does not permit containers to share the host PID namespace. 
If you need to run containers which require hostPID, this should be defined 
in a separate policy and you should carefully check to ensure that only 
limited service accounts and users are given permission to use that policy. 


Impact: Pods defined with spec.hostPID: true will not be permitted unless 
they are run under a specific policy. 

Audit: Fetch hostPID from each pod with:
get pods -A -o=jsonpath=$'{range .items[*]}{@.metadata.name}: 
{@.spec.hostPID}\n{end}' 

Remediation: Configure the Admission Controller to restrict the admission 
of hostPID containers. 

Default Value: By default, there are no restrictions on the creation of 
hostPID containers. 

References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1056 - Pre-compromise,Application Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Pod,C-KUBERNETES-POD-CNT-16,Minimize the admission of containers wishing to share the host process ID namespace,"CIS Benchmark Recommendation id: 5.2.3
Profile Applicability: Level 1 - Master Node 

Description: Do not generally permit containers to be run with the hostPID 
flag set to true. 

Rationale: A container running in the host's PID namespace can inspect 
processes running outside the container. If the container also has access 
to ptrace capabilities this can be used to escalate privileges outside of 
the container. There should be at least one admission control policy 
defined which does not permit containers to share the host PID namespace. 
If you need to run containers which require hostPID, this should be defined 
in a separate policy and you should carefully check to ensure that only 
limited service accounts and users are given permission to use that policy. 


Impact: Pods defined with spec.hostPID: true will not be permitted unless 
they are run under a specific policy. 

Audit: Fetch hostPID from each pod with:
get pods -A -o=jsonpath=$'{range .items[*]}{@.metadata.name}: 
{@.spec.hostPID}\n{end}' 

Remediation: Configure the Admission Controller to restrict the admission 
of hostPID containers. 

Default Value: By default, there are no restrictions on the creation of 
hostPID containers. 

References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1056 - Pre-compromise,Application Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Pod,C-KUBERNETES-POD-CNT-16,Minimize the admission of containers wishing to share the host process ID namespace,"CIS Benchmark Recommendation id: 5.2.3
Profile Applicability: Level 1 - Master Node 

Description: Do not generally permit containers to be run with the hostPID 
flag set to true. 

Rationale: A container running in the host's PID namespace can inspect 
processes running outside the container. If the container also has access 
to ptrace capabilities this can be used to escalate privileges outside of 
the container. There should be at least one admission control policy 
defined which does not permit containers to share the host PID namespace. 
If you need to run containers which require hostPID, this should be defined 
in a separate policy and you should carefully check to ensure that only 
limited service accounts and users are given permission to use that policy. 


Impact: Pods defined with spec.hostPID: true will not be permitted unless 
they are run under a specific policy. 

Audit: Fetch hostPID from each pod with:
get pods -A -o=jsonpath=$'{range .items[*]}{@.metadata.name}: 
{@.spec.hostPID}\n{end}' 

Remediation: Configure the Admission Controller to restrict the admission 
of hostPID containers. 

Default Value: By default, there are no restrictions on the creation of 
hostPID containers. 

References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1056 - Pre-compromise,Application Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Pod,C-KUBERNETES-POD-CNT-16,Minimize the admission of containers wishing to share the host process ID namespace,"CIS Benchmark Recommendation id: 5.2.3
Profile Applicability: Level 1 - Master Node 

Description: Do not generally permit containers to be run with the hostPID 
flag set to true. 

Rationale: A container running in the host's PID namespace can inspect 
processes running outside the container. If the container also has access 
to ptrace capabilities this can be used to escalate privileges outside of 
the container. There should be at least one admission control policy 
defined which does not permit containers to share the host PID namespace. 
If you need to run containers which require hostPID, this should be defined 
in a separate policy and you should carefully check to ensure that only 
limited service accounts and users are given permission to use that policy. 


Impact: Pods defined with spec.hostPID: true will not be permitted unless 
they are run under a specific policy. 

Audit: Fetch hostPID from each pod with:
get pods -A -o=jsonpath=$'{range .items[*]}{@.metadata.name}: 
{@.spec.hostPID}\n{end}' 

Remediation: Configure the Admission Controller to restrict the admission 
of hostPID containers. 

Default Value: By default, there are no restrictions on the creation of 
hostPID containers. 

References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1056 - Pre-compromise,Application Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Pod,C-KUBERNETES-POD-CNT-16,Minimize the admission of containers wishing to share the host process ID namespace,"CIS Benchmark Recommendation id: 5.2.3
Profile Applicability: Level 1 - Master Node 

Description: Do not generally permit containers to be run with the hostPID 
flag set to true. 

Rationale: A container running in the host's PID namespace can inspect 
processes running outside the container. If the container also has access 
to ptrace capabilities this can be used to escalate privileges outside of 
the container. There should be at least one admission control policy 
defined which does not permit containers to share the host PID namespace. 
If you need to run containers which require hostPID, this should be defined 
in a separate policy and you should carefully check to ensure that only 
limited service accounts and users are given permission to use that policy. 


Impact: Pods defined with spec.hostPID: true will not be permitted unless 
they are run under a specific policy. 

Audit: Fetch hostPID from each pod with:
get pods -A -o=jsonpath=$'{range .items[*]}{@.metadata.name}: 
{@.spec.hostPID}\n{end}' 

Remediation: Configure the Admission Controller to restrict the admission 
of hostPID containers. 

Default Value: By default, there are no restrictions on the creation of 
hostPID containers. 

References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1056 - Pre-compromise,Application Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Pod,C-KUBERNETES-POD-CNT-11,Minimize the admission of containers with added capabilities,"CIS Benchmark Recommendation id: 5.2.9

Profile Applicability: Level 1 - Master Node

Description: Do not generally permit containers with capabilities assigned 
beyond the default set.

Rationale: Containers run with a default set of capabilities as assigned by 
the Container Runtime. Capabilities outside this set can be added to 
containers which could expose them to risks of container breakout attacks. 
There should be at least one policy defined which prevents containers with 
capabilities beyond the default set from launching. If you need to run 
containers with additional capabilities, this should be defined in a 
separate policy and you should carefully check to ensure that only limited 
service accounts and users are given permission to use that policy.

Impact: Pods with containers which require capabilities outwith the default 
set will not be permitted.

Audit: Ensure that allowedCapabilities is not present in policies for the 
cluster unless it is set to an empty array. 
get pods -A -o=jsonpath=${'{range .items[*]}@.metadata.name}: 
@{..securityContext}\n{end}'

Remediation: Ensure that allowedCapabilities is not present in policies for 
the cluster unless it is set to an empty array.

Default Value: By default, there are no restrictions on adding capabilities 
to containers.

References: 

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>
   2. 
      <https://www.nccgroup.trust/uk/our-research/abusing-privileged-and-unprivilegedlinux-containers/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1044 - Restrict Library Loading,Cloud Security,NIST 800-53 v5,CA-9 Internal System Connections
Kubernetes Pod,C-KUBERNETES-POD-CNT-11,Minimize the admission of containers with added capabilities,"CIS Benchmark Recommendation id: 5.2.9

Profile Applicability: Level 1 - Master Node

Description: Do not generally permit containers with capabilities assigned 
beyond the default set.

Rationale: Containers run with a default set of capabilities as assigned by 
the Container Runtime. Capabilities outside this set can be added to 
containers which could expose them to risks of container breakout attacks. 
There should be at least one policy defined which prevents containers with 
capabilities beyond the default set from launching. If you need to run 
containers with additional capabilities, this should be defined in a 
separate policy and you should carefully check to ensure that only limited 
service accounts and users are given permission to use that policy.

Impact: Pods with containers which require capabilities outwith the default 
set will not be permitted.

Audit: Ensure that allowedCapabilities is not present in policies for the 
cluster unless it is set to an empty array. 
get pods -A -o=jsonpath=${'{range .items[*]}@.metadata.name}: 
@{..securityContext}\n{end}'

Remediation: Ensure that allowedCapabilities is not present in policies for 
the cluster unless it is set to an empty array.

Default Value: By default, there are no restrictions on adding capabilities 
to containers.

References: 

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>
   2. 
      <https://www.nccgroup.trust/uk/our-research/abusing-privileged-and-unprivilegedlinux-containers/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1044 - Restrict Library Loading,Cloud Security,NIST 800-53 v5,CA-9 Internal System Connections
Kubernetes Pod,C-KUBERNETES-POD-CNT-11,Minimize the admission of containers with added capabilities,"CIS Benchmark Recommendation id: 5.2.9

Profile Applicability: Level 1 - Master Node

Description: Do not generally permit containers with capabilities assigned 
beyond the default set.

Rationale: Containers run with a default set of capabilities as assigned by 
the Container Runtime. Capabilities outside this set can be added to 
containers which could expose them to risks of container breakout attacks. 
There should be at least one policy defined which prevents containers with 
capabilities beyond the default set from launching. If you need to run 
containers with additional capabilities, this should be defined in a 
separate policy and you should carefully check to ensure that only limited 
service accounts and users are given permission to use that policy.

Impact: Pods with containers which require capabilities outwith the default 
set will not be permitted.

Audit: Ensure that allowedCapabilities is not present in policies for the 
cluster unless it is set to an empty array. 
get pods -A -o=jsonpath=${'{range .items[*]}@.metadata.name}: 
@{..securityContext}\n{end}'

Remediation: Ensure that allowedCapabilities is not present in policies for 
the cluster unless it is set to an empty array.

Default Value: By default, there are no restrictions on adding capabilities 
to containers.

References: 

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>
   2. 
      <https://www.nccgroup.trust/uk/our-research/abusing-privileged-and-unprivilegedlinux-containers/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1044 - Restrict Library Loading,Cloud Security,NIST 800-53 v5,CA-9 Internal System Connections
Kubernetes Pod,C-KUBERNETES-POD-CNT-11,Minimize the admission of containers with added capabilities,"CIS Benchmark Recommendation id: 5.2.9

Profile Applicability: Level 1 - Master Node

Description: Do not generally permit containers with capabilities assigned 
beyond the default set.

Rationale: Containers run with a default set of capabilities as assigned by 
the Container Runtime. Capabilities outside this set can be added to 
containers which could expose them to risks of container breakout attacks. 
There should be at least one policy defined which prevents containers with 
capabilities beyond the default set from launching. If you need to run 
containers with additional capabilities, this should be defined in a 
separate policy and you should carefully check to ensure that only limited 
service accounts and users are given permission to use that policy.

Impact: Pods with containers which require capabilities outwith the default 
set will not be permitted.

Audit: Ensure that allowedCapabilities is not present in policies for the 
cluster unless it is set to an empty array. 
get pods -A -o=jsonpath=${'{range .items[*]}@.metadata.name}: 
@{..securityContext}\n{end}'

Remediation: Ensure that allowedCapabilities is not present in policies for 
the cluster unless it is set to an empty array.

Default Value: By default, there are no restrictions on adding capabilities 
to containers.

References: 

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>
   2. 
      <https://www.nccgroup.trust/uk/our-research/abusing-privileged-and-unprivilegedlinux-containers/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1044 - Restrict Library Loading,Cloud Security,NIST 800-53 v5,CA-9 Internal System Connections
Kubernetes Pod,C-KUBERNETES-POD-CNT-11,Minimize the admission of containers with added capabilities,"CIS Benchmark Recommendation id: 5.2.9

Profile Applicability: Level 1 - Master Node

Description: Do not generally permit containers with capabilities assigned 
beyond the default set.

Rationale: Containers run with a default set of capabilities as assigned by 
the Container Runtime. Capabilities outside this set can be added to 
containers which could expose them to risks of container breakout attacks. 
There should be at least one policy defined which prevents containers with 
capabilities beyond the default set from launching. If you need to run 
containers with additional capabilities, this should be defined in a 
separate policy and you should carefully check to ensure that only limited 
service accounts and users are given permission to use that policy.

Impact: Pods with containers which require capabilities outwith the default 
set will not be permitted.

Audit: Ensure that allowedCapabilities is not present in policies for the 
cluster unless it is set to an empty array. 
get pods -A -o=jsonpath=${'{range .items[*]}@.metadata.name}: 
@{..securityContext}\n{end}'

Remediation: Ensure that allowedCapabilities is not present in policies for 
the cluster unless it is set to an empty array.

Default Value: By default, there are no restrictions on adding capabilities 
to containers.

References: 

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>
   2. 
      <https://www.nccgroup.trust/uk/our-research/abusing-privileged-and-unprivilegedlinux-containers/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1044 - Restrict Library Loading,Cloud Security,NIST 800-53 v5,CA-9 Internal System Connections
Kubernetes Pod,C-KUBERNETES-POD-CNT-07,Minimize the admission of containers with allowPrivilegeEscalation,"CIS Benchmark Recommendation id: 5.2.6
Profile Applicability: Level 1 - Master Node
Description: Do not generally permit containers to be run with the 
allowPrivilegeEscalation flag set to true. Allowing this right can lead to 
a process running a container getting more rights than it started with. 
It's important to note that these rights are still constrained by the 
overall container sandbox, and this setting does not relate to the use of 
privileged containers.
Rationale: A container running with the allowPrivilegeEscalation flag set 
to true may have processes that can gain more privileges than their parent. 
There should be at least one admission control policy defined which does 
not permit containers to allow privilege escalation. The option exists (and 
is defaulted to true) to permit setuid binaries to run. If you have the 
need to run containers which use setuid binaries or require privilege 
escalation, this should be defined in a separate policy and you should 
carefully check to ensure that only limited service accounts and users are 
given permission to use that policy.
Impact: Pods defined with securityContext: allowPrivilegeEscalation: true 
will not be permitted unless they are run under a specific policy.
Audit: List the policies in use for each namespace in the cluster, ensure 
that each policy disallows the admission of containers which allow 
privilege escalation. 
fetch hostNetwork from each pod. 
get pods -A -o=jsonpath=$'{range .items[*]}{@.metadata.name}: 
{@..securityContext}\n{end}'
Remediation: Add policies to each namespace in the cluster which has user 
workloads to restrict the admission of containers with securityContext: 
allowPrivilegeEscalation: true
Default Value: By default, there are no restrictions on contained process 
ability to escalate privileges, within the context of the container.
References: 

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1025 - Privileged Process Integrity,Cloud Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Pod,C-KUBERNETES-POD-CNT-07,Minimize the admission of containers with allowPrivilegeEscalation,"CIS Benchmark Recommendation id: 5.2.6
Profile Applicability: Level 1 - Master Node
Description: Do not generally permit containers to be run with the 
allowPrivilegeEscalation flag set to true. Allowing this right can lead to 
a process running a container getting more rights than it started with. 
It's important to note that these rights are still constrained by the 
overall container sandbox, and this setting does not relate to the use of 
privileged containers.
Rationale: A container running with the allowPrivilegeEscalation flag set 
to true may have processes that can gain more privileges than their parent. 
There should be at least one admission control policy defined which does 
not permit containers to allow privilege escalation. The option exists (and 
is defaulted to true) to permit setuid binaries to run. If you have the 
need to run containers which use setuid binaries or require privilege 
escalation, this should be defined in a separate policy and you should 
carefully check to ensure that only limited service accounts and users are 
given permission to use that policy.
Impact: Pods defined with securityContext: allowPrivilegeEscalation: true 
will not be permitted unless they are run under a specific policy.
Audit: List the policies in use for each namespace in the cluster, ensure 
that each policy disallows the admission of containers which allow 
privilege escalation. 
fetch hostNetwork from each pod. 
get pods -A -o=jsonpath=$'{range .items[*]}{@.metadata.name}: 
{@..securityContext}\n{end}'
Remediation: Add policies to each namespace in the cluster which has user 
workloads to restrict the admission of containers with securityContext: 
allowPrivilegeEscalation: true
Default Value: By default, there are no restrictions on contained process 
ability to escalate privileges, within the context of the container.
References: 

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1025 - Privileged Process Integrity,Cloud Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Pod,C-KUBERNETES-POD-CNT-07,Minimize the admission of containers with allowPrivilegeEscalation,"CIS Benchmark Recommendation id: 5.2.6
Profile Applicability: Level 1 - Master Node
Description: Do not generally permit containers to be run with the 
allowPrivilegeEscalation flag set to true. Allowing this right can lead to 
a process running a container getting more rights than it started with. 
It's important to note that these rights are still constrained by the 
overall container sandbox, and this setting does not relate to the use of 
privileged containers.
Rationale: A container running with the allowPrivilegeEscalation flag set 
to true may have processes that can gain more privileges than their parent. 
There should be at least one admission control policy defined which does 
not permit containers to allow privilege escalation. The option exists (and 
is defaulted to true) to permit setuid binaries to run. If you have the 
need to run containers which use setuid binaries or require privilege 
escalation, this should be defined in a separate policy and you should 
carefully check to ensure that only limited service accounts and users are 
given permission to use that policy.
Impact: Pods defined with securityContext: allowPrivilegeEscalation: true 
will not be permitted unless they are run under a specific policy.
Audit: List the policies in use for each namespace in the cluster, ensure 
that each policy disallows the admission of containers which allow 
privilege escalation. 
fetch hostNetwork from each pod. 
get pods -A -o=jsonpath=$'{range .items[*]}{@.metadata.name}: 
{@..securityContext}\n{end}'
Remediation: Add policies to each namespace in the cluster which has user 
workloads to restrict the admission of containers with securityContext: 
allowPrivilegeEscalation: true
Default Value: By default, there are no restrictions on contained process 
ability to escalate privileges, within the context of the container.
References: 

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1025 - Privileged Process Integrity,Cloud Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Pod,C-KUBERNETES-POD-CNT-07,Minimize the admission of containers with allowPrivilegeEscalation,"CIS Benchmark Recommendation id: 5.2.6
Profile Applicability: Level 1 - Master Node
Description: Do not generally permit containers to be run with the 
allowPrivilegeEscalation flag set to true. Allowing this right can lead to 
a process running a container getting more rights than it started with. 
It's important to note that these rights are still constrained by the 
overall container sandbox, and this setting does not relate to the use of 
privileged containers.
Rationale: A container running with the allowPrivilegeEscalation flag set 
to true may have processes that can gain more privileges than their parent. 
There should be at least one admission control policy defined which does 
not permit containers to allow privilege escalation. The option exists (and 
is defaulted to true) to permit setuid binaries to run. If you have the 
need to run containers which use setuid binaries or require privilege 
escalation, this should be defined in a separate policy and you should 
carefully check to ensure that only limited service accounts and users are 
given permission to use that policy.
Impact: Pods defined with securityContext: allowPrivilegeEscalation: true 
will not be permitted unless they are run under a specific policy.
Audit: List the policies in use for each namespace in the cluster, ensure 
that each policy disallows the admission of containers which allow 
privilege escalation. 
fetch hostNetwork from each pod. 
get pods -A -o=jsonpath=$'{range .items[*]}{@.metadata.name}: 
{@..securityContext}\n{end}'
Remediation: Add policies to each namespace in the cluster which has user 
workloads to restrict the admission of containers with securityContext: 
allowPrivilegeEscalation: true
Default Value: By default, there are no restrictions on contained process 
ability to escalate privileges, within the context of the container.
References: 

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1025 - Privileged Process Integrity,Cloud Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Pod,C-KUBERNETES-POD-CNT-07,Minimize the admission of containers with allowPrivilegeEscalation,"CIS Benchmark Recommendation id: 5.2.6
Profile Applicability: Level 1 - Master Node
Description: Do not generally permit containers to be run with the 
allowPrivilegeEscalation flag set to true. Allowing this right can lead to 
a process running a container getting more rights than it started with. 
It's important to note that these rights are still constrained by the 
overall container sandbox, and this setting does not relate to the use of 
privileged containers.
Rationale: A container running with the allowPrivilegeEscalation flag set 
to true may have processes that can gain more privileges than their parent. 
There should be at least one admission control policy defined which does 
not permit containers to allow privilege escalation. The option exists (and 
is defaulted to true) to permit setuid binaries to run. If you have the 
need to run containers which use setuid binaries or require privilege 
escalation, this should be defined in a separate policy and you should 
carefully check to ensure that only limited service accounts and users are 
given permission to use that policy.
Impact: Pods defined with securityContext: allowPrivilegeEscalation: true 
will not be permitted unless they are run under a specific policy.
Audit: List the policies in use for each namespace in the cluster, ensure 
that each policy disallows the admission of containers which allow 
privilege escalation. 
fetch hostNetwork from each pod. 
get pods -A -o=jsonpath=$'{range .items[*]}{@.metadata.name}: 
{@..securityContext}\n{end}'
Remediation: Add policies to each namespace in the cluster which has user 
workloads to restrict the admission of containers with securityContext: 
allowPrivilegeEscalation: true
Default Value: By default, there are no restrictions on contained process 
ability to escalate privileges, within the context of the container.
References: 

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1025 - Privileged Process Integrity,Cloud Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Pod,C-KUBERNETES-POD-CNT-12,Minimize the admission of containers with capabilities assigned,"CIS Benchmark Recommendation id: 5.2.10

Profile Applicability: Level 2 - Master Node

Description: Do not generally permit containers with capabilities

Rationale: Containers run with a default set of capabilities as assigned by 
the Container Runtime. Capabilities are parts of the rights generally 
granted on a Linux system to the root user. In many cases applications 
running in containers do not require any capabilities to operate, so from 
the perspective of the principal of least privilege use of capabilities 
should be minimized.

Impact: Pods with containers require capabilities to operate will not be 
permitted.

Audit: List the policies in use for each namespace in the cluster, ensure 
that at least one policy requires that capabilities are dropped by all 
containers.

Remediation: Review the use of capabilities in applications running on your 
cluster. Where a namespace contains applications which do not require any 
Linux capabilities to operate consider adding a policy which forbids the 
admission of containers which do not drop all capabilities.

Default Value: By default, there are no restrictions on the creation of 
containers with additional capabilities

References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>
   2. 
      <https://www.nccgroup.trust/uk/our-research/abusing-privileged-and-unprivilegedlinux-containers/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1033 - Limit Software Installation,Application Security,NIST 800-53 v5,CA-9 Internal System Connections
Kubernetes Pod,C-KUBERNETES-POD-CNT-12,Minimize the admission of containers with capabilities assigned,"CIS Benchmark Recommendation id: 5.2.10

Profile Applicability: Level 2 - Master Node

Description: Do not generally permit containers with capabilities

Rationale: Containers run with a default set of capabilities as assigned by 
the Container Runtime. Capabilities are parts of the rights generally 
granted on a Linux system to the root user. In many cases applications 
running in containers do not require any capabilities to operate, so from 
the perspective of the principal of least privilege use of capabilities 
should be minimized.

Impact: Pods with containers require capabilities to operate will not be 
permitted.

Audit: List the policies in use for each namespace in the cluster, ensure 
that at least one policy requires that capabilities are dropped by all 
containers.

Remediation: Review the use of capabilities in applications running on your 
cluster. Where a namespace contains applications which do not require any 
Linux capabilities to operate consider adding a policy which forbids the 
admission of containers which do not drop all capabilities.

Default Value: By default, there are no restrictions on the creation of 
containers with additional capabilities

References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>
   2. 
      <https://www.nccgroup.trust/uk/our-research/abusing-privileged-and-unprivilegedlinux-containers/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1033 - Limit Software Installation,Application Security,NIST 800-53 v5,CA-9 Internal System Connections
Kubernetes Pod,C-KUBERNETES-POD-CNT-12,Minimize the admission of containers with capabilities assigned,"CIS Benchmark Recommendation id: 5.2.10

Profile Applicability: Level 2 - Master Node

Description: Do not generally permit containers with capabilities

Rationale: Containers run with a default set of capabilities as assigned by 
the Container Runtime. Capabilities are parts of the rights generally 
granted on a Linux system to the root user. In many cases applications 
running in containers do not require any capabilities to operate, so from 
the perspective of the principal of least privilege use of capabilities 
should be minimized.

Impact: Pods with containers require capabilities to operate will not be 
permitted.

Audit: List the policies in use for each namespace in the cluster, ensure 
that at least one policy requires that capabilities are dropped by all 
containers.

Remediation: Review the use of capabilities in applications running on your 
cluster. Where a namespace contains applications which do not require any 
Linux capabilities to operate consider adding a policy which forbids the 
admission of containers which do not drop all capabilities.

Default Value: By default, there are no restrictions on the creation of 
containers with additional capabilities

References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>
   2. 
      <https://www.nccgroup.trust/uk/our-research/abusing-privileged-and-unprivilegedlinux-containers/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1033 - Limit Software Installation,Application Security,NIST 800-53 v5,CA-9 Internal System Connections
Kubernetes Pod,C-KUBERNETES-POD-CNT-12,Minimize the admission of containers with capabilities assigned,"CIS Benchmark Recommendation id: 5.2.10

Profile Applicability: Level 2 - Master Node

Description: Do not generally permit containers with capabilities

Rationale: Containers run with a default set of capabilities as assigned by 
the Container Runtime. Capabilities are parts of the rights generally 
granted on a Linux system to the root user. In many cases applications 
running in containers do not require any capabilities to operate, so from 
the perspective of the principal of least privilege use of capabilities 
should be minimized.

Impact: Pods with containers require capabilities to operate will not be 
permitted.

Audit: List the policies in use for each namespace in the cluster, ensure 
that at least one policy requires that capabilities are dropped by all 
containers.

Remediation: Review the use of capabilities in applications running on your 
cluster. Where a namespace contains applications which do not require any 
Linux capabilities to operate consider adding a policy which forbids the 
admission of containers which do not drop all capabilities.

Default Value: By default, there are no restrictions on the creation of 
containers with additional capabilities

References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>
   2. 
      <https://www.nccgroup.trust/uk/our-research/abusing-privileged-and-unprivilegedlinux-containers/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1033 - Limit Software Installation,Application Security,NIST 800-53 v5,CA-9 Internal System Connections
Kubernetes Pod,C-KUBERNETES-POD-CNT-12,Minimize the admission of containers with capabilities assigned,"CIS Benchmark Recommendation id: 5.2.10

Profile Applicability: Level 2 - Master Node

Description: Do not generally permit containers with capabilities

Rationale: Containers run with a default set of capabilities as assigned by 
the Container Runtime. Capabilities are parts of the rights generally 
granted on a Linux system to the root user. In many cases applications 
running in containers do not require any capabilities to operate, so from 
the perspective of the principal of least privilege use of capabilities 
should be minimized.

Impact: Pods with containers require capabilities to operate will not be 
permitted.

Audit: List the policies in use for each namespace in the cluster, ensure 
that at least one policy requires that capabilities are dropped by all 
containers.

Remediation: Review the use of capabilities in applications running on your 
cluster. Where a namespace contains applications which do not require any 
Linux capabilities to operate consider adding a policy which forbids the 
admission of containers which do not drop all capabilities.

Default Value: By default, there are no restrictions on the creation of 
containers with additional capabilities

References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>
   2. 
      <https://www.nccgroup.trust/uk/our-research/abusing-privileged-and-unprivilegedlinux-containers/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1033 - Limit Software Installation,Application Security,NIST 800-53 v5,CA-9 Internal System Connections
Kubernetes Pod,C-KUBERNETES-POD-CNT-10,Minimize the admission of containers with the NET_RAW capability,"CIS Benchmark Recommendation id: 5.2.8
Profile Applicability: Level 1 - Master Node
Description: Do not generally permit containers with the potentially 
dangerous NET_RAW capability.
Rationale: Containers run with a default set of capabilities as assigned by 
the Container Runtime. By default this can include potentially dangerous 
capabilities. With Docker as the container runtime the NET_RAW capability 
is enabled which may be misused by malicious containers. Ideally, all 
containers should drop this capability. There should be at least one 
admission control policy defined which does not permit containers with the 
NET_RAW capability. If you need to run containers with this capability, 
this should be defined in a separate policy and you should carefully check 
to ensure that only limited service accounts and users are given permission 
to use that policy.
Impact: Pods with containers which run with the NET_RAW capability will not 
be permitted.
Audit: List the policies in use for each namespace in the cluster, ensure 
that at least one policy disallows the admission of containers with the 
NET_RAW capability.
Remediation: Add policies to each namespace in the cluster which has user 
workloads to restrict the admission of containers with the NET_RAW 
capability.
Default Value: By default, there are no restrictions on the creation of 
containers with the NET_RAW capability.
References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>
   2. 
      <https://www.nccgroup.trust/uk/our-research/abusing-privileged-and-unprivilegedlinux-containers/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1025 - Privileged Process Integrity,Cloud Security,NIST 800-53 v5,SC-7 Boundary Protection
Kubernetes Pod,C-KUBERNETES-POD-CNT-10,Minimize the admission of containers with the NET_RAW capability,"CIS Benchmark Recommendation id: 5.2.8
Profile Applicability: Level 1 - Master Node
Description: Do not generally permit containers with the potentially 
dangerous NET_RAW capability.
Rationale: Containers run with a default set of capabilities as assigned by 
the Container Runtime. By default this can include potentially dangerous 
capabilities. With Docker as the container runtime the NET_RAW capability 
is enabled which may be misused by malicious containers. Ideally, all 
containers should drop this capability. There should be at least one 
admission control policy defined which does not permit containers with the 
NET_RAW capability. If you need to run containers with this capability, 
this should be defined in a separate policy and you should carefully check 
to ensure that only limited service accounts and users are given permission 
to use that policy.
Impact: Pods with containers which run with the NET_RAW capability will not 
be permitted.
Audit: List the policies in use for each namespace in the cluster, ensure 
that at least one policy disallows the admission of containers with the 
NET_RAW capability.
Remediation: Add policies to each namespace in the cluster which has user 
workloads to restrict the admission of containers with the NET_RAW 
capability.
Default Value: By default, there are no restrictions on the creation of 
containers with the NET_RAW capability.
References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>
   2. 
      <https://www.nccgroup.trust/uk/our-research/abusing-privileged-and-unprivilegedlinux-containers/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1025 - Privileged Process Integrity,Cloud Security,NIST 800-53 v5,SC-7 Boundary Protection
Kubernetes Pod,C-KUBERNETES-POD-CNT-10,Minimize the admission of containers with the NET_RAW capability,"CIS Benchmark Recommendation id: 5.2.8
Profile Applicability: Level 1 - Master Node
Description: Do not generally permit containers with the potentially 
dangerous NET_RAW capability.
Rationale: Containers run with a default set of capabilities as assigned by 
the Container Runtime. By default this can include potentially dangerous 
capabilities. With Docker as the container runtime the NET_RAW capability 
is enabled which may be misused by malicious containers. Ideally, all 
containers should drop this capability. There should be at least one 
admission control policy defined which does not permit containers with the 
NET_RAW capability. If you need to run containers with this capability, 
this should be defined in a separate policy and you should carefully check 
to ensure that only limited service accounts and users are given permission 
to use that policy.
Impact: Pods with containers which run with the NET_RAW capability will not 
be permitted.
Audit: List the policies in use for each namespace in the cluster, ensure 
that at least one policy disallows the admission of containers with the 
NET_RAW capability.
Remediation: Add policies to each namespace in the cluster which has user 
workloads to restrict the admission of containers with the NET_RAW 
capability.
Default Value: By default, there are no restrictions on the creation of 
containers with the NET_RAW capability.
References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>
   2. 
      <https://www.nccgroup.trust/uk/our-research/abusing-privileged-and-unprivilegedlinux-containers/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1025 - Privileged Process Integrity,Cloud Security,NIST 800-53 v5,SC-7 Boundary Protection
Kubernetes Pod,C-KUBERNETES-POD-CNT-10,Minimize the admission of containers with the NET_RAW capability,"CIS Benchmark Recommendation id: 5.2.8
Profile Applicability: Level 1 - Master Node
Description: Do not generally permit containers with the potentially 
dangerous NET_RAW capability.
Rationale: Containers run with a default set of capabilities as assigned by 
the Container Runtime. By default this can include potentially dangerous 
capabilities. With Docker as the container runtime the NET_RAW capability 
is enabled which may be misused by malicious containers. Ideally, all 
containers should drop this capability. There should be at least one 
admission control policy defined which does not permit containers with the 
NET_RAW capability. If you need to run containers with this capability, 
this should be defined in a separate policy and you should carefully check 
to ensure that only limited service accounts and users are given permission 
to use that policy.
Impact: Pods with containers which run with the NET_RAW capability will not 
be permitted.
Audit: List the policies in use for each namespace in the cluster, ensure 
that at least one policy disallows the admission of containers with the 
NET_RAW capability.
Remediation: Add policies to each namespace in the cluster which has user 
workloads to restrict the admission of containers with the NET_RAW 
capability.
Default Value: By default, there are no restrictions on the creation of 
containers with the NET_RAW capability.
References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>
   2. 
      <https://www.nccgroup.trust/uk/our-research/abusing-privileged-and-unprivilegedlinux-containers/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1025 - Privileged Process Integrity,Cloud Security,NIST 800-53 v5,SC-7 Boundary Protection
Kubernetes Pod,C-KUBERNETES-POD-CNT-10,Minimize the admission of containers with the NET_RAW capability,"CIS Benchmark Recommendation id: 5.2.8
Profile Applicability: Level 1 - Master Node
Description: Do not generally permit containers with the potentially 
dangerous NET_RAW capability.
Rationale: Containers run with a default set of capabilities as assigned by 
the Container Runtime. By default this can include potentially dangerous 
capabilities. With Docker as the container runtime the NET_RAW capability 
is enabled which may be misused by malicious containers. Ideally, all 
containers should drop this capability. There should be at least one 
admission control policy defined which does not permit containers with the 
NET_RAW capability. If you need to run containers with this capability, 
this should be defined in a separate policy and you should carefully check 
to ensure that only limited service accounts and users are given permission 
to use that policy.
Impact: Pods with containers which run with the NET_RAW capability will not 
be permitted.
Audit: List the policies in use for each namespace in the cluster, ensure 
that at least one policy disallows the admission of containers with the 
NET_RAW capability.
Remediation: Add policies to each namespace in the cluster which has user 
workloads to restrict the admission of containers with the NET_RAW 
capability.
Default Value: By default, there are no restrictions on the creation of 
containers with the NET_RAW capability.
References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>
   2. 
      <https://www.nccgroup.trust/uk/our-research/abusing-privileged-and-unprivilegedlinux-containers/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1025 - Privileged Process Integrity,Cloud Security,NIST 800-53 v5,SC-7 Boundary Protection
Kubernetes Pod,C-KUBERNETES-POD-CNT-13,Minimize the admission of HostPath volumes,"CIS Benchmark Recommendation id: 5.2.12
Profile Applicability: Level 1 - Master Node
Description: Do not generally admit containers which make use of hostPath 
volumes.
Rationale: A container which mounts a hostPath volume as part of its 
specification will have access to the filesystem of the underlying cluster 
node. The use of hostPath volumes may allow containers access to privileged 
areas of the node filesystem. There should be at least one admission 
control policy defined which does not permit containers to mount hostPath 
volumes. If you need to run containers which require hostPath volumes, this 
should be defined in a separate policy and you should carefully check to 
ensure that only limited service accounts and users are given permission to 
use that policy.
Impact: Pods defined which make use of hostPath volumes will not be 
permitted unless they are run under a specific policy.
Audit: List the policies in use for each namespace in the cluster, ensure 
that each policy disallows the admission of containers with hostPath 
volumes.
Remediation: Add policies to each namespace in the cluster which has user 
workloads to restrict the admission of containers which use hostPath 
volumes.
Default Value: By default, there are no restrictions on the creation of 
hostPath volumes.
References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1025 - Privileged Process Integrity,Network Security,NIST 800-53 v5,"SI-7 Software, Firmware, and Information Integrity"
Kubernetes Pod,C-KUBERNETES-POD-CNT-13,Minimize the admission of HostPath volumes,"CIS Benchmark Recommendation id: 5.2.12
Profile Applicability: Level 1 - Master Node
Description: Do not generally admit containers which make use of hostPath 
volumes.
Rationale: A container which mounts a hostPath volume as part of its 
specification will have access to the filesystem of the underlying cluster 
node. The use of hostPath volumes may allow containers access to privileged 
areas of the node filesystem. There should be at least one admission 
control policy defined which does not permit containers to mount hostPath 
volumes. If you need to run containers which require hostPath volumes, this 
should be defined in a separate policy and you should carefully check to 
ensure that only limited service accounts and users are given permission to 
use that policy.
Impact: Pods defined which make use of hostPath volumes will not be 
permitted unless they are run under a specific policy.
Audit: List the policies in use for each namespace in the cluster, ensure 
that each policy disallows the admission of containers with hostPath 
volumes.
Remediation: Add policies to each namespace in the cluster which has user 
workloads to restrict the admission of containers which use hostPath 
volumes.
Default Value: By default, there are no restrictions on the creation of 
hostPath volumes.
References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1025 - Privileged Process Integrity,Network Security,NIST 800-53 v5,"SI-7 Software, Firmware, and Information Integrity"
Kubernetes Pod,C-KUBERNETES-POD-CNT-13,Minimize the admission of HostPath volumes,"CIS Benchmark Recommendation id: 5.2.12
Profile Applicability: Level 1 - Master Node
Description: Do not generally admit containers which make use of hostPath 
volumes.
Rationale: A container which mounts a hostPath volume as part of its 
specification will have access to the filesystem of the underlying cluster 
node. The use of hostPath volumes may allow containers access to privileged 
areas of the node filesystem. There should be at least one admission 
control policy defined which does not permit containers to mount hostPath 
volumes. If you need to run containers which require hostPath volumes, this 
should be defined in a separate policy and you should carefully check to 
ensure that only limited service accounts and users are given permission to 
use that policy.
Impact: Pods defined which make use of hostPath volumes will not be 
permitted unless they are run under a specific policy.
Audit: List the policies in use for each namespace in the cluster, ensure 
that each policy disallows the admission of containers with hostPath 
volumes.
Remediation: Add policies to each namespace in the cluster which has user 
workloads to restrict the admission of containers which use hostPath 
volumes.
Default Value: By default, there are no restrictions on the creation of 
hostPath volumes.
References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1025 - Privileged Process Integrity,Network Security,NIST 800-53 v5,"SI-7 Software, Firmware, and Information Integrity"
Kubernetes Pod,C-KUBERNETES-POD-CNT-13,Minimize the admission of HostPath volumes,"CIS Benchmark Recommendation id: 5.2.12
Profile Applicability: Level 1 - Master Node
Description: Do not generally admit containers which make use of hostPath 
volumes.
Rationale: A container which mounts a hostPath volume as part of its 
specification will have access to the filesystem of the underlying cluster 
node. The use of hostPath volumes may allow containers access to privileged 
areas of the node filesystem. There should be at least one admission 
control policy defined which does not permit containers to mount hostPath 
volumes. If you need to run containers which require hostPath volumes, this 
should be defined in a separate policy and you should carefully check to 
ensure that only limited service accounts and users are given permission to 
use that policy.
Impact: Pods defined which make use of hostPath volumes will not be 
permitted unless they are run under a specific policy.
Audit: List the policies in use for each namespace in the cluster, ensure 
that each policy disallows the admission of containers with hostPath 
volumes.
Remediation: Add policies to each namespace in the cluster which has user 
workloads to restrict the admission of containers which use hostPath 
volumes.
Default Value: By default, there are no restrictions on the creation of 
hostPath volumes.
References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1025 - Privileged Process Integrity,Network Security,NIST 800-53 v5,"SI-7 Software, Firmware, and Information Integrity"
Kubernetes Pod,C-KUBERNETES-POD-CNT-13,Minimize the admission of HostPath volumes,"CIS Benchmark Recommendation id: 5.2.12
Profile Applicability: Level 1 - Master Node
Description: Do not generally admit containers which make use of hostPath 
volumes.
Rationale: A container which mounts a hostPath volume as part of its 
specification will have access to the filesystem of the underlying cluster 
node. The use of hostPath volumes may allow containers access to privileged 
areas of the node filesystem. There should be at least one admission 
control policy defined which does not permit containers to mount hostPath 
volumes. If you need to run containers which require hostPath volumes, this 
should be defined in a separate policy and you should carefully check to 
ensure that only limited service accounts and users are given permission to 
use that policy.
Impact: Pods defined which make use of hostPath volumes will not be 
permitted unless they are run under a specific policy.
Audit: List the policies in use for each namespace in the cluster, ensure 
that each policy disallows the admission of containers with hostPath 
volumes.
Remediation: Add policies to each namespace in the cluster which has user 
workloads to restrict the admission of containers which use hostPath 
volumes.
Default Value: By default, there are no restrictions on the creation of 
hostPath volumes.
References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1025 - Privileged Process Integrity,Network Security,NIST 800-53 v5,"SI-7 Software, Firmware, and Information Integrity"
Kubernetes Pod,C-KUBERNETES-POD-CNT-15,Minimize the admission of privileged containers,"CIS Benchmark Recommendation id: 5.2.2

Profile Applicability: Level 1 - Master Node

Description: Do not generally permit containers to be run with the 
securityContext.privileged flag set to true.

Rationale: Privileged containers have access to all Linux Kernel 
capabilities and devices. A container running with full privileges can do 
almost everything that the host can do. This flag exists to allow special 
use-cases, like manipulating the network stack and accessing devices. There 
should be at least one admission control policy defined which does not 
permit privileged containers. If you need to run privileged containers, 
this should be defined in a separate policy and you should carefully check 
to ensure that only limited service accounts and users are given permission 
to use that policy.

Impact: Pods defined with spec.containers[].securityContext.privileged: 
true, spec.initContainers[].securityContext.privileged: true and 
spec.ephemeralContainers[].securityContext.privileged: true will not be 
permitted.

Audit: Run the following command: 
get pods -A -o=jsonpath=$'{range .items[*]}{@.metadata.name}: 
{@..securityContext}\n{end}'

It will produce an inventory of all the privileged use on the cluster, if 
any (please, refer to a sample below). Further grepping can be done to 
automate each specific violation detection.

calico-kube-controllers-57b57c56f-jtmk4: {} << No Elevated Privileges
calico-nodec4xv4: {} {""privileged"":true} {""privileged"":true} 
{""privileged"":true} {""privileged"":true} << Violates 5.2.2
dashboard-metrics-scraper-7bc864c59-2m2xw: 
{""seccompProfile"":{""type"":""RuntimeDefault""}} 
{""allowPrivilegeEscalation"":false,""readOnlyRootFilesystem"":true,""runAsGroup"":2001,""runAsUser"":1001}

Remediation: Add policies to each namespace in the cluster which has user 
workloads to restrict the admission of privileged containers.

Default Value: By default, there are no restrictions on the creation of 
privileged containers.

References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1025 - Privileged Process Integrity,Application Security,NIST 800-53 v5,SC-7 Boundary Protection
Kubernetes Pod,C-KUBERNETES-POD-CNT-15,Minimize the admission of privileged containers,"CIS Benchmark Recommendation id: 5.2.2

Profile Applicability: Level 1 - Master Node

Description: Do not generally permit containers to be run with the 
securityContext.privileged flag set to true.

Rationale: Privileged containers have access to all Linux Kernel 
capabilities and devices. A container running with full privileges can do 
almost everything that the host can do. This flag exists to allow special 
use-cases, like manipulating the network stack and accessing devices. There 
should be at least one admission control policy defined which does not 
permit privileged containers. If you need to run privileged containers, 
this should be defined in a separate policy and you should carefully check 
to ensure that only limited service accounts and users are given permission 
to use that policy.

Impact: Pods defined with spec.containers[].securityContext.privileged: 
true, spec.initContainers[].securityContext.privileged: true and 
spec.ephemeralContainers[].securityContext.privileged: true will not be 
permitted.

Audit: Run the following command: 
get pods -A -o=jsonpath=$'{range .items[*]}{@.metadata.name}: 
{@..securityContext}\n{end}'

It will produce an inventory of all the privileged use on the cluster, if 
any (please, refer to a sample below). Further grepping can be done to 
automate each specific violation detection.

calico-kube-controllers-57b57c56f-jtmk4: {} << No Elevated Privileges
calico-nodec4xv4: {} {""privileged"":true} {""privileged"":true} 
{""privileged"":true} {""privileged"":true} << Violates 5.2.2
dashboard-metrics-scraper-7bc864c59-2m2xw: 
{""seccompProfile"":{""type"":""RuntimeDefault""}} 
{""allowPrivilegeEscalation"":false,""readOnlyRootFilesystem"":true,""runAsGroup"":2001,""runAsUser"":1001}

Remediation: Add policies to each namespace in the cluster which has user 
workloads to restrict the admission of privileged containers.

Default Value: By default, there are no restrictions on the creation of 
privileged containers.

References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1025 - Privileged Process Integrity,Application Security,NIST 800-53 v5,SC-7 Boundary Protection
Kubernetes Pod,C-KUBERNETES-POD-CNT-15,Minimize the admission of privileged containers,"CIS Benchmark Recommendation id: 5.2.2

Profile Applicability: Level 1 - Master Node

Description: Do not generally permit containers to be run with the 
securityContext.privileged flag set to true.

Rationale: Privileged containers have access to all Linux Kernel 
capabilities and devices. A container running with full privileges can do 
almost everything that the host can do. This flag exists to allow special 
use-cases, like manipulating the network stack and accessing devices. There 
should be at least one admission control policy defined which does not 
permit privileged containers. If you need to run privileged containers, 
this should be defined in a separate policy and you should carefully check 
to ensure that only limited service accounts and users are given permission 
to use that policy.

Impact: Pods defined with spec.containers[].securityContext.privileged: 
true, spec.initContainers[].securityContext.privileged: true and 
spec.ephemeralContainers[].securityContext.privileged: true will not be 
permitted.

Audit: Run the following command: 
get pods -A -o=jsonpath=$'{range .items[*]}{@.metadata.name}: 
{@..securityContext}\n{end}'

It will produce an inventory of all the privileged use on the cluster, if 
any (please, refer to a sample below). Further grepping can be done to 
automate each specific violation detection.

calico-kube-controllers-57b57c56f-jtmk4: {} << No Elevated Privileges
calico-nodec4xv4: {} {""privileged"":true} {""privileged"":true} 
{""privileged"":true} {""privileged"":true} << Violates 5.2.2
dashboard-metrics-scraper-7bc864c59-2m2xw: 
{""seccompProfile"":{""type"":""RuntimeDefault""}} 
{""allowPrivilegeEscalation"":false,""readOnlyRootFilesystem"":true,""runAsGroup"":2001,""runAsUser"":1001}

Remediation: Add policies to each namespace in the cluster which has user 
workloads to restrict the admission of privileged containers.

Default Value: By default, there are no restrictions on the creation of 
privileged containers.

References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1025 - Privileged Process Integrity,Application Security,NIST 800-53 v5,SC-7 Boundary Protection
Kubernetes Pod,C-KUBERNETES-POD-CNT-15,Minimize the admission of privileged containers,"CIS Benchmark Recommendation id: 5.2.2

Profile Applicability: Level 1 - Master Node

Description: Do not generally permit containers to be run with the 
securityContext.privileged flag set to true.

Rationale: Privileged containers have access to all Linux Kernel 
capabilities and devices. A container running with full privileges can do 
almost everything that the host can do. This flag exists to allow special 
use-cases, like manipulating the network stack and accessing devices. There 
should be at least one admission control policy defined which does not 
permit privileged containers. If you need to run privileged containers, 
this should be defined in a separate policy and you should carefully check 
to ensure that only limited service accounts and users are given permission 
to use that policy.

Impact: Pods defined with spec.containers[].securityContext.privileged: 
true, spec.initContainers[].securityContext.privileged: true and 
spec.ephemeralContainers[].securityContext.privileged: true will not be 
permitted.

Audit: Run the following command: 
get pods -A -o=jsonpath=$'{range .items[*]}{@.metadata.name}: 
{@..securityContext}\n{end}'

It will produce an inventory of all the privileged use on the cluster, if 
any (please, refer to a sample below). Further grepping can be done to 
automate each specific violation detection.

calico-kube-controllers-57b57c56f-jtmk4: {} << No Elevated Privileges
calico-nodec4xv4: {} {""privileged"":true} {""privileged"":true} 
{""privileged"":true} {""privileged"":true} << Violates 5.2.2
dashboard-metrics-scraper-7bc864c59-2m2xw: 
{""seccompProfile"":{""type"":""RuntimeDefault""}} 
{""allowPrivilegeEscalation"":false,""readOnlyRootFilesystem"":true,""runAsGroup"":2001,""runAsUser"":1001}

Remediation: Add policies to each namespace in the cluster which has user 
workloads to restrict the admission of privileged containers.

Default Value: By default, there are no restrictions on the creation of 
privileged containers.

References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1025 - Privileged Process Integrity,Application Security,NIST 800-53 v5,SC-7 Boundary Protection
Kubernetes Pod,C-KUBERNETES-POD-CNT-15,Minimize the admission of privileged containers,"CIS Benchmark Recommendation id: 5.2.2

Profile Applicability: Level 1 - Master Node

Description: Do not generally permit containers to be run with the 
securityContext.privileged flag set to true.

Rationale: Privileged containers have access to all Linux Kernel 
capabilities and devices. A container running with full privileges can do 
almost everything that the host can do. This flag exists to allow special 
use-cases, like manipulating the network stack and accessing devices. There 
should be at least one admission control policy defined which does not 
permit privileged containers. If you need to run privileged containers, 
this should be defined in a separate policy and you should carefully check 
to ensure that only limited service accounts and users are given permission 
to use that policy.

Impact: Pods defined with spec.containers[].securityContext.privileged: 
true, spec.initContainers[].securityContext.privileged: true and 
spec.ephemeralContainers[].securityContext.privileged: true will not be 
permitted.

Audit: Run the following command: 
get pods -A -o=jsonpath=$'{range .items[*]}{@.metadata.name}: 
{@..securityContext}\n{end}'

It will produce an inventory of all the privileged use on the cluster, if 
any (please, refer to a sample below). Further grepping can be done to 
automate each specific violation detection.

calico-kube-controllers-57b57c56f-jtmk4: {} << No Elevated Privileges
calico-nodec4xv4: {} {""privileged"":true} {""privileged"":true} 
{""privileged"":true} {""privileged"":true} << Violates 5.2.2
dashboard-metrics-scraper-7bc864c59-2m2xw: 
{""seccompProfile"":{""type"":""RuntimeDefault""}} 
{""allowPrivilegeEscalation"":false,""readOnlyRootFilesystem"":true,""runAsGroup"":2001,""runAsUser"":1001}

Remediation: Add policies to each namespace in the cluster which has user 
workloads to restrict the admission of privileged containers.

Default Value: By default, there are no restrictions on the creation of 
privileged containers.

References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1025 - Privileged Process Integrity,Application Security,NIST 800-53 v5,SC-7 Boundary Protection
Kubernetes Pod,C-KUBERNETES-POD-CNT-08,Minimize the admission of root containers,"CIS Benchmark Recommendation id: 5.2.7

Profile Applicability: Level 2 - Master Node

Description: Do not generally permit containers to be run as the root user.

Rationale: Containers may run as any Linux user. Containers which run as 
the root user, whilst constrained by Container Runtime security features 
still have a escalated likelihood of container breakout. Ideally, all 
containers should run as a defined non-UID 0 user. There should be at least 
one admission control policy defined which does not permit root containers. 
If you need to run root containers, this should be defined in a separate 
policy and you should carefully check to ensure that only limited service 
accounts and users are given permission to use that policy.

Impact: Pods with containers which run as the root user will not be 
permitted.

Audit: List the policies in use for each namespace in the cluster, ensure 
that each policy restricts the use of root containers by setting 
MustRunAsNonRoot or MustRunAs with the range of UIDs not including 0.

Remediation: Create a policy for each namespace in the cluster, ensuring 
that either MustRunAsNonRoot or MustRunAs with the range of UIDs not 
including 0, is set.

Default Value: By default, there are no restrictions on the use of root 
containers and if a User is not specified in the image, the container will 
run as root.

References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1026 - Privileged Account Management,Application Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Pod,C-KUBERNETES-POD-CNT-08,Minimize the admission of root containers,"CIS Benchmark Recommendation id: 5.2.7

Profile Applicability: Level 2 - Master Node

Description: Do not generally permit containers to be run as the root user.

Rationale: Containers may run as any Linux user. Containers which run as 
the root user, whilst constrained by Container Runtime security features 
still have a escalated likelihood of container breakout. Ideally, all 
containers should run as a defined non-UID 0 user. There should be at least 
one admission control policy defined which does not permit root containers. 
If you need to run root containers, this should be defined in a separate 
policy and you should carefully check to ensure that only limited service 
accounts and users are given permission to use that policy.

Impact: Pods with containers which run as the root user will not be 
permitted.

Audit: List the policies in use for each namespace in the cluster, ensure 
that each policy restricts the use of root containers by setting 
MustRunAsNonRoot or MustRunAs with the range of UIDs not including 0.

Remediation: Create a policy for each namespace in the cluster, ensuring 
that either MustRunAsNonRoot or MustRunAs with the range of UIDs not 
including 0, is set.

Default Value: By default, there are no restrictions on the use of root 
containers and if a User is not specified in the image, the container will 
run as root.

References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1026 - Privileged Account Management,Application Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Pod,C-KUBERNETES-POD-CNT-08,Minimize the admission of root containers,"CIS Benchmark Recommendation id: 5.2.7

Profile Applicability: Level 2 - Master Node

Description: Do not generally permit containers to be run as the root user.

Rationale: Containers may run as any Linux user. Containers which run as 
the root user, whilst constrained by Container Runtime security features 
still have a escalated likelihood of container breakout. Ideally, all 
containers should run as a defined non-UID 0 user. There should be at least 
one admission control policy defined which does not permit root containers. 
If you need to run root containers, this should be defined in a separate 
policy and you should carefully check to ensure that only limited service 
accounts and users are given permission to use that policy.

Impact: Pods with containers which run as the root user will not be 
permitted.

Audit: List the policies in use for each namespace in the cluster, ensure 
that each policy restricts the use of root containers by setting 
MustRunAsNonRoot or MustRunAs with the range of UIDs not including 0.

Remediation: Create a policy for each namespace in the cluster, ensuring 
that either MustRunAsNonRoot or MustRunAs with the range of UIDs not 
including 0, is set.

Default Value: By default, there are no restrictions on the use of root 
containers and if a User is not specified in the image, the container will 
run as root.

References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1026 - Privileged Account Management,Application Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Pod,C-KUBERNETES-POD-CNT-08,Minimize the admission of root containers,"CIS Benchmark Recommendation id: 5.2.7

Profile Applicability: Level 2 - Master Node

Description: Do not generally permit containers to be run as the root user.

Rationale: Containers may run as any Linux user. Containers which run as 
the root user, whilst constrained by Container Runtime security features 
still have a escalated likelihood of container breakout. Ideally, all 
containers should run as a defined non-UID 0 user. There should be at least 
one admission control policy defined which does not permit root containers. 
If you need to run root containers, this should be defined in a separate 
policy and you should carefully check to ensure that only limited service 
accounts and users are given permission to use that policy.

Impact: Pods with containers which run as the root user will not be 
permitted.

Audit: List the policies in use for each namespace in the cluster, ensure 
that each policy restricts the use of root containers by setting 
MustRunAsNonRoot or MustRunAs with the range of UIDs not including 0.

Remediation: Create a policy for each namespace in the cluster, ensuring 
that either MustRunAsNonRoot or MustRunAs with the range of UIDs not 
including 0, is set.

Default Value: By default, there are no restrictions on the use of root 
containers and if a User is not specified in the image, the container will 
run as root.

References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1026 - Privileged Account Management,Application Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Pod,C-KUBERNETES-POD-CNT-08,Minimize the admission of root containers,"CIS Benchmark Recommendation id: 5.2.7

Profile Applicability: Level 2 - Master Node

Description: Do not generally permit containers to be run as the root user.

Rationale: Containers may run as any Linux user. Containers which run as 
the root user, whilst constrained by Container Runtime security features 
still have a escalated likelihood of container breakout. Ideally, all 
containers should run as a defined non-UID 0 user. There should be at least 
one admission control policy defined which does not permit root containers. 
If you need to run root containers, this should be defined in a separate 
policy and you should carefully check to ensure that only limited service 
accounts and users are given permission to use that policy.

Impact: Pods with containers which run as the root user will not be 
permitted.

Audit: List the policies in use for each namespace in the cluster, ensure 
that each policy restricts the use of root containers by setting 
MustRunAsNonRoot or MustRunAs with the range of UIDs not including 0.

Remediation: Create a policy for each namespace in the cluster, ensuring 
that either MustRunAsNonRoot or MustRunAs with the range of UIDs not 
including 0, is set.

Default Value: By default, there are no restrictions on the use of root 
containers and if a User is not specified in the image, the container will 
run as root.

References:

   1. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1026 - Privileged Account Management,Application Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Pod,C-KUBERNETES-POD-CNT-09,Minimize the admission of Windows HostProcess Containers,"CIS Benchmark Recommendation id: 5.2.11

Profile Applicability: Level 1 - Master Node

Description: Do not generally permit Windows containers to be run with the 
hostProcess flag set to true.

Rationale: A Windows container making use of the hostProcess flag can 
interact with the underlying Windows cluster node. As per the Kubernetes 
documentation, this provides ""privileged access"" to the Windows node. Where 
Windows containers are used inside a Kubernetes cluster, there should be at 
least one admission control policy which does not permit hostProcess 
Windows containers. If you need to run Windows containers which require 
hostProcess, this should be defined in a separate policy and you should 
carefully check to ensure that only limited service accounts and users are 
given permission to use that policy.

Impact: Pods defined with securityContext.windowsOptions.hostProcess: true 
will not be permitted unless they are run under a specific policy.

Audit: List the policies in use for each namespace in the cluster, ensure 
that each policy disallows the admission of hostProcess containers.

Remediation: Add policies to each namespace in the cluster which has user 
workloads to restrict the admission of hostProcess containers.

Default Value: By default, there are no restrictions on the creation of 
hostProcess containers.

References:

   1. 
      <https://kubernetes.io/docs/tasks/configure-pod-container/create-hostprocess-pod/>
   2. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1025 - Privileged Process Integrity,Network Security,NIST 800-53 v5,SC-7 Boundary Protection
Kubernetes Pod,C-KUBERNETES-POD-CNT-09,Minimize the admission of Windows HostProcess Containers,"CIS Benchmark Recommendation id: 5.2.11

Profile Applicability: Level 1 - Master Node

Description: Do not generally permit Windows containers to be run with the 
hostProcess flag set to true.

Rationale: A Windows container making use of the hostProcess flag can 
interact with the underlying Windows cluster node. As per the Kubernetes 
documentation, this provides ""privileged access"" to the Windows node. Where 
Windows containers are used inside a Kubernetes cluster, there should be at 
least one admission control policy which does not permit hostProcess 
Windows containers. If you need to run Windows containers which require 
hostProcess, this should be defined in a separate policy and you should 
carefully check to ensure that only limited service accounts and users are 
given permission to use that policy.

Impact: Pods defined with securityContext.windowsOptions.hostProcess: true 
will not be permitted unless they are run under a specific policy.

Audit: List the policies in use for each namespace in the cluster, ensure 
that each policy disallows the admission of hostProcess containers.

Remediation: Add policies to each namespace in the cluster which has user 
workloads to restrict the admission of hostProcess containers.

Default Value: By default, there are no restrictions on the creation of 
hostProcess containers.

References:

   1. 
      <https://kubernetes.io/docs/tasks/configure-pod-container/create-hostprocess-pod/>
   2. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1025 - Privileged Process Integrity,Network Security,NIST 800-53 v5,SC-7 Boundary Protection
Kubernetes Pod,C-KUBERNETES-POD-CNT-09,Minimize the admission of Windows HostProcess Containers,"CIS Benchmark Recommendation id: 5.2.11

Profile Applicability: Level 1 - Master Node

Description: Do not generally permit Windows containers to be run with the 
hostProcess flag set to true.

Rationale: A Windows container making use of the hostProcess flag can 
interact with the underlying Windows cluster node. As per the Kubernetes 
documentation, this provides ""privileged access"" to the Windows node. Where 
Windows containers are used inside a Kubernetes cluster, there should be at 
least one admission control policy which does not permit hostProcess 
Windows containers. If you need to run Windows containers which require 
hostProcess, this should be defined in a separate policy and you should 
carefully check to ensure that only limited service accounts and users are 
given permission to use that policy.

Impact: Pods defined with securityContext.windowsOptions.hostProcess: true 
will not be permitted unless they are run under a specific policy.

Audit: List the policies in use for each namespace in the cluster, ensure 
that each policy disallows the admission of hostProcess containers.

Remediation: Add policies to each namespace in the cluster which has user 
workloads to restrict the admission of hostProcess containers.

Default Value: By default, there are no restrictions on the creation of 
hostProcess containers.

References:

   1. 
      <https://kubernetes.io/docs/tasks/configure-pod-container/create-hostprocess-pod/>
   2. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1025 - Privileged Process Integrity,Network Security,NIST 800-53 v5,SC-7 Boundary Protection
Kubernetes Pod,C-KUBERNETES-POD-CNT-09,Minimize the admission of Windows HostProcess Containers,"CIS Benchmark Recommendation id: 5.2.11

Profile Applicability: Level 1 - Master Node

Description: Do not generally permit Windows containers to be run with the 
hostProcess flag set to true.

Rationale: A Windows container making use of the hostProcess flag can 
interact with the underlying Windows cluster node. As per the Kubernetes 
documentation, this provides ""privileged access"" to the Windows node. Where 
Windows containers are used inside a Kubernetes cluster, there should be at 
least one admission control policy which does not permit hostProcess 
Windows containers. If you need to run Windows containers which require 
hostProcess, this should be defined in a separate policy and you should 
carefully check to ensure that only limited service accounts and users are 
given permission to use that policy.

Impact: Pods defined with securityContext.windowsOptions.hostProcess: true 
will not be permitted unless they are run under a specific policy.

Audit: List the policies in use for each namespace in the cluster, ensure 
that each policy disallows the admission of hostProcess containers.

Remediation: Add policies to each namespace in the cluster which has user 
workloads to restrict the admission of hostProcess containers.

Default Value: By default, there are no restrictions on the creation of 
hostProcess containers.

References:

   1. 
      <https://kubernetes.io/docs/tasks/configure-pod-container/create-hostprocess-pod/>
   2. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1025 - Privileged Process Integrity,Network Security,NIST 800-53 v5,SC-7 Boundary Protection
Kubernetes Pod,C-KUBERNETES-POD-CNT-09,Minimize the admission of Windows HostProcess Containers,"CIS Benchmark Recommendation id: 5.2.11

Profile Applicability: Level 1 - Master Node

Description: Do not generally permit Windows containers to be run with the 
hostProcess flag set to true.

Rationale: A Windows container making use of the hostProcess flag can 
interact with the underlying Windows cluster node. As per the Kubernetes 
documentation, this provides ""privileged access"" to the Windows node. Where 
Windows containers are used inside a Kubernetes cluster, there should be at 
least one admission control policy which does not permit hostProcess 
Windows containers. If you need to run Windows containers which require 
hostProcess, this should be defined in a separate policy and you should 
carefully check to ensure that only limited service accounts and users are 
given permission to use that policy.

Impact: Pods defined with securityContext.windowsOptions.hostProcess: true 
will not be permitted unless they are run under a specific policy.

Audit: List the policies in use for each namespace in the cluster, ensure 
that each policy disallows the admission of hostProcess containers.

Remediation: Add policies to each namespace in the cluster which has user 
workloads to restrict the admission of hostProcess containers.

Default Value: By default, there are no restrictions on the creation of 
hostProcess containers.

References:

   1. 
      <https://kubernetes.io/docs/tasks/configure-pod-container/create-hostprocess-pod/>
   2. 
      <https://kubernetes.io/docs/concepts/security/pod-security-standards/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1025 - Privileged Process Integrity,Network Security,NIST 800-53 v5,SC-7 Boundary Protection
Kubernetes Cluster,C-KUBERNETES-CLUSTER-CNT-11,Minimize wildcard use in Roles and ClusterRoles,"CIS Benchmark Recommendation id: 5.1.3

Profile Applicability: Level 1 - Worker Node

Description: Kubernetes Roles and ClusterRoles provide access to resources 
based on sets of objects and actions that can be taken on those objects. It 
is possible to set either of these to be the wildcard ""*"" which matches all 
items. Use of wildcards is not optimal from a security perspective as it 
may allow for inadvertent access to be granted when new resources are added 
to the Kubernetes API either as CRDs or in later versions of the product.

Rationale: The principle of least privilege recommends that users are 
provided only the access required for their role and nothing more. The use 
of wildcard rights grants is likely to provide excessive rights to the 
Kubernetes API.

Impact: None

Audit: Retrieve the roles defined across each namespace in the cluster and 
review for wildcards
kubectl get roles --all-namespaces -o yaml

Retrieve the cluster roles defined in the cluster and review for wildcards
kubectl get clusterroles -o yaml

Remediation: Where possible replace any use of wildcards in clusterroles 
and roles with specific objects or actions.

Default Value: None

References:
N/A",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1026 - Privileged Account Management,Cloud Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
DNS (Domain Name System),C-DNS-DOMAIN-NAME-SYSTEM-CNT-3,Monitor DNS queries and deploy DNS firewalls,"To enhance the security of your DNS infrastructure, implementing monitoring 
of DNS query patterns and volumes alongside a DNS firewall is essential. 
This approach aims to detect anomalies promptly and filter out potentially 
harmful traffic. Below is a detailed guide to achieve this:


Step-by-Step Implementation


Step 1: Set Up DNS Monitoring

   1. Select DNS Monitoring Tools: Choose a DNS monitoring tool such as 
      Prometheus <https://prometheus.io> , Datadog
      <https://www.datadoghq.com/> , or Zabbix <https://www.zabbix.com/> 
      to track DNS query patterns.
   2. Install and Configure: Deploy your selected monitoring tool on your
      DNS servers. Ensure it is configured to capture metrics related to
      query volumes, source IP addresses, and response times.
   3. Create Alerts: Define thresholds for unusual DNS activity and
      configure alerts. Set triggers for high volumes of queries from a
      single IP or spikes in particular query types.
   4. Regular Review: Establish a routine to review alerts and log data.
      Analyze patterns to identify anomalies that could indicate spam,
      DDoS, or tunneling attacks.


Step 2: Deploy DNS Firewall

   1. Select a DNS Firewall Solution: Opt for a firewall solution like 
      Cisco Umbrella
      <https://umbrella.cisco.com/products/dns-layer-network-security> , 
      Infoblox DNS Firewall
      <https://www.infoblox.com/products/dns-security> , or AWS Route 53
      <https://aws.amazon.com/route53/> .
   2. Integrate with Existing Infrastructure: Configure your DNS firewall
      to work with your current DNS servers. Set up rules to block known
      malicious domains and filter outbound DNS queries.
   3. Update and Maintain Lists: Regularly update your firewall with threat
      intelligence feeds to ensure it blocks the latest malicious domain
      names and IP addresses.
   4. Test the Configuration: Conduct tests to confirm that the firewall
      correctly enforces policies and does not inadvertently block
      legitimate traffic.


Step 3: Continuous Improvement

   1. Analyze Data: Continuously analyze data collected from your
      monitoring system to refine detection rules and improve threat
      detection accuracy.
   2. Iterative Updates: Adapt and enhance your firewall rules and
      monitoring alerts based on new threats and network changes.
   3. Training and Awareness: Conduct regular training sessions for IT
      staff to ensure they are aware of the latest DNS security trends and
      tools.

By effectively monitoring and controlling DNS traffic, you can 
significantly enhance your network's defense mechanisms against potential 
threats.

References

    * Cloudflare DNS Firewall
      <https://www.cloudflare.com/dns/dns-firewall/>",Created by Rules Engine,Recommended,Not tested,High,N/A,High,Hugo Ponthieu,,ATT&CK Enterprise - M1047 - Audit,Network Security,NIST 800-53 v5,SI-4 System Monitoring
Backend,C-WEB-APPLICATION-SERVER-SIDE-CNT-08,Perform software composition analysis and patch outdated libraries,"To reduce the risk of vulnerabilities from outdated or insecure libraries, 
perform software composition analysis (SCA) to identify all third-party 
libraries and dependencies used in your web application. Regularly scan for 
known vulnerabilities and outdated components, then promptly patch or 
upgrade them to secure versions. This ensures that your application is 
protected from known exploits related to insecure or deprecated libraries.

Implementation Steps:

   1. Perform Software Composition Analysis: Use automated tools to scan
      your codebase and identify all third-party libraries and
      dependencies, including their versions.
   2. Identify Vulnerabilities: Cross-reference your libraries against
      known vulnerability databases (e.g., CVE, NVD) to identify any
      libraries that are outdated or have known security issues.
   3. Patch or Upgrade Libraries: Once outdated or vulnerable libraries are
      identified, promptly upgrade to the latest stable versions or apply
      necessary patches to mitigate any security risks.
   4. Automate Regular Scanning: Set up automated scanning processes to
      regularly check for vulnerabilities in your dependencies, ensuring
      that any new risks are identified and addressed in a timely manner.

References:

    * OWASP Software Composition Analysis
      <https://www.owasp.org/index.php/OWASP_Dependency_Track_Project>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1054 - Software Configuration,Application Security,NIST 800-53 v5,"SI-7 Software, Firmware, and Information Integrity"
Fronend,C-WEB-APPLICATION-SERVER-SIDE-CNT-08,Perform software composition analysis and patch outdated libraries,"To reduce the risk of vulnerabilities from outdated or insecure libraries, 
perform software composition analysis (SCA) to identify all third-party 
libraries and dependencies used in your web application. Regularly scan for 
known vulnerabilities and outdated components, then promptly patch or 
upgrade them to secure versions. This ensures that your application is 
protected from known exploits related to insecure or deprecated libraries.

Implementation Steps:

   1. Perform Software Composition Analysis: Use automated tools to scan
      your codebase and identify all third-party libraries and
      dependencies, including their versions.
   2. Identify Vulnerabilities: Cross-reference your libraries against
      known vulnerability databases (e.g., CVE, NVD) to identify any
      libraries that are outdated or have known security issues.
   3. Patch or Upgrade Libraries: Once outdated or vulnerable libraries are
      identified, promptly upgrade to the latest stable versions or apply
      necessary patches to mitigate any security risks.
   4. Automate Regular Scanning: Set up automated scanning processes to
      regularly check for vulnerabilities in your dependencies, ensuring
      that any new risks are identified and addressed in a timely manner.

References:

    * OWASP Software Composition Analysis
      <https://www.owasp.org/index.php/OWASP_Dependency_Track_Project>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1054 - Software Configuration,Application Security,NIST 800-53 v5,"SI-7 Software, Firmware, and Information Integrity"
Kubernetes Pod,C-KUBERNETES-POD-CNT-02,Prefer using secrets as files over secrets as environment variables,"CIS Benchmark Recommendation id: 5.4.1
Profile Applicability: Level 2 - Master Node
Description: Kubernetes supports mounting secrets as data volumes or as 
environment variables. Minimize the use of environment variable secrets.
Rationale: It is reasonably common for application code to log out its 
environment (particularly in the event of an error). This will include any 
secret values passed in as environment variables, so secrets can easily be 
exposed to any user or entity who has access to the logs.
Impact: Application code which expects to read secrets in the form of 
environment variables would need modification
Audit: Run the following command to find references to objects which use 
environment variables defined from secrets.
kubectl get all -o jsonpath='{range .items[?(@..secretKeyRef)]} {.kind} 
{.metadata.name} {""\n""}{end}' -A
Remediation: If possible, rewrite application code to read secrets from 
mounted secret files, rather than from environment variables.
Default Value: By default, secrets are not defined

Additional Information: Mounting secrets as volumes has the additional 
benefit that secret values can be updated without restarting the pod
References:

   1. 
      <https://kubernetes.io/docs/concepts/configuration/secret/#using-secrets>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1043 - Credential Access Protection,Cloud Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Pod,C-KUBERNETES-POD-CNT-02,Prefer using secrets as files over secrets as environment variables,"CIS Benchmark Recommendation id: 5.4.1
Profile Applicability: Level 2 - Master Node
Description: Kubernetes supports mounting secrets as data volumes or as 
environment variables. Minimize the use of environment variable secrets.
Rationale: It is reasonably common for application code to log out its 
environment (particularly in the event of an error). This will include any 
secret values passed in as environment variables, so secrets can easily be 
exposed to any user or entity who has access to the logs.
Impact: Application code which expects to read secrets in the form of 
environment variables would need modification
Audit: Run the following command to find references to objects which use 
environment variables defined from secrets.
kubectl get all -o jsonpath='{range .items[?(@..secretKeyRef)]} {.kind} 
{.metadata.name} {""\n""}{end}' -A
Remediation: If possible, rewrite application code to read secrets from 
mounted secret files, rather than from environment variables.
Default Value: By default, secrets are not defined

Additional Information: Mounting secrets as volumes has the additional 
benefit that secret values can be updated without restarting the pod
References:

   1. 
      <https://kubernetes.io/docs/concepts/configuration/secret/#using-secrets>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1043 - Credential Access Protection,Cloud Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Pod,C-KUBERNETES-POD-CNT-02,Prefer using secrets as files over secrets as environment variables,"CIS Benchmark Recommendation id: 5.4.1
Profile Applicability: Level 2 - Master Node
Description: Kubernetes supports mounting secrets as data volumes or as 
environment variables. Minimize the use of environment variable secrets.
Rationale: It is reasonably common for application code to log out its 
environment (particularly in the event of an error). This will include any 
secret values passed in as environment variables, so secrets can easily be 
exposed to any user or entity who has access to the logs.
Impact: Application code which expects to read secrets in the form of 
environment variables would need modification
Audit: Run the following command to find references to objects which use 
environment variables defined from secrets.
kubectl get all -o jsonpath='{range .items[?(@..secretKeyRef)]} {.kind} 
{.metadata.name} {""\n""}{end}' -A
Remediation: If possible, rewrite application code to read secrets from 
mounted secret files, rather than from environment variables.
Default Value: By default, secrets are not defined

Additional Information: Mounting secrets as volumes has the additional 
benefit that secret values can be updated without restarting the pod
References:

   1. 
      <https://kubernetes.io/docs/concepts/configuration/secret/#using-secrets>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1043 - Credential Access Protection,Cloud Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Pod,C-KUBERNETES-POD-CNT-02,Prefer using secrets as files over secrets as environment variables,"CIS Benchmark Recommendation id: 5.4.1
Profile Applicability: Level 2 - Master Node
Description: Kubernetes supports mounting secrets as data volumes or as 
environment variables. Minimize the use of environment variable secrets.
Rationale: It is reasonably common for application code to log out its 
environment (particularly in the event of an error). This will include any 
secret values passed in as environment variables, so secrets can easily be 
exposed to any user or entity who has access to the logs.
Impact: Application code which expects to read secrets in the form of 
environment variables would need modification
Audit: Run the following command to find references to objects which use 
environment variables defined from secrets.
kubectl get all -o jsonpath='{range .items[?(@..secretKeyRef)]} {.kind} 
{.metadata.name} {""\n""}{end}' -A
Remediation: If possible, rewrite application code to read secrets from 
mounted secret files, rather than from environment variables.
Default Value: By default, secrets are not defined

Additional Information: Mounting secrets as volumes has the additional 
benefit that secret values can be updated without restarting the pod
References:

   1. 
      <https://kubernetes.io/docs/concepts/configuration/secret/#using-secrets>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1043 - Credential Access Protection,Cloud Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Pod,C-KUBERNETES-POD-CNT-02,Prefer using secrets as files over secrets as environment variables,"CIS Benchmark Recommendation id: 5.4.1
Profile Applicability: Level 2 - Master Node
Description: Kubernetes supports mounting secrets as data volumes or as 
environment variables. Minimize the use of environment variable secrets.
Rationale: It is reasonably common for application code to log out its 
environment (particularly in the event of an error). This will include any 
secret values passed in as environment variables, so secrets can easily be 
exposed to any user or entity who has access to the logs.
Impact: Application code which expects to read secrets in the form of 
environment variables would need modification
Audit: Run the following command to find references to objects which use 
environment variables defined from secrets.
kubectl get all -o jsonpath='{range .items[?(@..secretKeyRef)]} {.kind} 
{.metadata.name} {""\n""}{end}' -A
Remediation: If possible, rewrite application code to read secrets from 
mounted secret files, rather than from environment variables.
Default Value: By default, secrets are not defined

Additional Information: Mounting secrets as volumes has the additional 
benefit that secret values can be updated without restarting the pod
References:

   1. 
      <https://kubernetes.io/docs/concepts/configuration/secret/#using-secrets>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1043 - Credential Access Protection,Cloud Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
React.js,C-REACT-JS-CNT-REACTJS-05,Prevent cross-site request forgery (CSRF) attacks on ReactJS,"Implement measures to prevent Cross-Site Request Forgery (CSRF) attacks in 
your React.js application by using anti-CSRF tokens and secure request 
headers. CSRF attacks involve tricking authenticated users into submitting 
requests without their consent, often leading to unintended actions like 
changing account settings or transferring funds. To prevent this, use tools 
like csrf-token in React.js to generate a unique token for each session. 
Ensure that every state-modifying request (e.g., POST, PUT, DELETE) 
includes a valid CSRF token, which is validated on the server side. 
Additionally, implement SameSite cookie attributes and use secure HTTP 
methods for sensitive requests.

References

    * OWASP CSRF Prevention Cheat Sheet
      <https://cheatsheetseries.owasp.org/cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1056 - Pre-compromise,Application Security,NIST 800-53 v5,SI-10 INFORMATION INPUT VALIDATION
DNS (Domain Name System),C-DNS-DOMAIN-NAME-SYSTEM-CNT-2,Rate limiting and recursion restriction,"Implement Rate Limiting on DNS Servers

    * Edit the DNS server configuration file. The location and file name
      depend on the DNS software in use (e.g., /etc/named.conf for BIND).

Add a rate-limiting directive. For BIND, you can use Response Rate Limiting 
(RRL) by adding the following:

    * rate-limit {    responses-per-second 5;  /* Limits responses to 5 per
      second */    window 5;                /* Time window for rate
      calculations */ };                

This setting restricts the number of times the server will respond to 
repeated queries, mitigating DNS amplification attacks.

Restart the DNS service for changes to take effect. This can be done using 
system commands like:

    * sudo systemctl restart named
    * Test the configuration to ensure it is working without impacting
      legitimate traffic, by monitoring logs and network traffic.

Disable Recursion on Public DNS Servers

    * Open the DNS server configuration file again.

Locate the options block, and add or modify the recursion configuration:

    * options {    recursion no;  /* Disables recursive queries */ };      
               

This setting prevents your DNS server from performing recursive queries on 
behalf of clients, which helps to limit its exposure to certain attack 
vectors like cache poisoning and DNS-based DDoS attacks.

    * Restart the DNS service to apply the changes.
    * Verify the DNS server is not providing recursive query responses by
      using tools like dig:
          o dig @your_dyndns_server_ip example.com +norecurse

The response should not include an answer if the server is properly 
configured not to recurse.

References

    * DNS and BIND, 5th Edition: Disabling Recursion
      <https://docstore.mik.ua/orelly/networking_2ndEd/dns/ch10_04.htm>",Created by Rules Engine,Recommended,Not tested,High,N/A,High,Hugo Ponthieu,,ATT&CK Enterprise - M1031 - Network Intrusion Prevention,Network Security,NIST 800-53 v5,SC-5 DENIAL-OF-SERVICE PROTECTION
"*.beep,ovh",C-REGULAR-AUDITING-AND-UPDATING-OF-THIRD-PARTY-LIBRARIES,Regular Auditing and Updating of Third-Party Libraries,"Regularly auditing and updating third-party libraries are crucial practices 
for maintaining the security and stability of software applications. 
Third-party libraries can introduce vulnerabilities if they are outdated or 
not properly managed, which can be exploited by attackers to compromise an 
application.

Steps to Implement Regular Auditing and Updating of Third-Party Libraries

Inventory All Third-Party Libraries:

    * Compile a complete list of all third-party libraries used in your
      applications, including versions and their dependencies.
    * Utilize tools like package managers (e.g., npm, Maven, NuGet) that
      can automate the inventory process and track library versions.

Establish a Regular Audit Schedule:

    * Define a schedule for regularly auditing third-party libraries.
      Frequency may depend on the criticality of the application and the
      environment in which it operates.
    * Consider automating the auditing process using tools that can scan
      for outdated libraries and known vulnerabilities.

Integrate Security Scanning Tools:

    * Implement automated tools to scan third-party libraries for known
      vulnerabilities. Tools like OWASP Dependency-Check, Snyk, or
      WhiteSource can be integrated into your development and deployment
      pipelines.
    * Set up these tools to run automatically at specified intervals or as
      part of your continuous integration/continuous deployment (CI/CD)
      pipeline.

Develop a Patch Management Policy:

    * Create a policy for how updates and patches to third-party libraries
      are handled, including how quickly patches are applied once a
      vulnerability is identified.
    * Define roles and responsibilities within your team for updating
      libraries and addressing security issues.

Monitor Security Advisories and Vulnerability Databases:

    * Subscribe to security advisories and alerts related to the
      third-party libraries you use. Sources could include vendor security
      mailing lists and databases like the National Vulnerability Database
      (NVD).
    * Stay informed about the latest security trends and threats that might
      affect the libraries you depend on.

Test Updates in a Controlled Environment:

    * Before rolling out updates to production, test them in a development
      or staging environment to ensure they do not break existing
      functionalities.
    * Implement automated tests that can quickly identify problems
      introduced by updated libraries.

Implement Automated Dependency Updates:

    * Use tools that can automatically update third-party libraries to
      their latest secure versions. For example, dependabot in GitHub can
      automatically create pull requests to update dependencies.
    * Ensure that these updates are subject to review and testing before
      being merged into the main codebase.

Educate and Train Development Teams:

    * Provide training for developers on the importance of using secure
      libraries and the risks associated with third-party code.
    * Encourage best practices like using the minimal necessary libraries
      and regularly reviewing the necessity and security of each
      dependency.

Document and Maintain Records:

    * Keep detailed records of all library audits, updates, and security
      measures implemented.
    * Use these records to improve your security posture over time and
      provide documentation for compliance requirements.

Good Security Practices Reference

    * Adhere to best practices from sources such as OWASP (Open Web
      Application Security Project) on secure handling of third-party
      dependencies.
    * Consult industry standards and guidelines, such as those from the
      Software Engineering Institute (SEI) at Carnegie Mellon University,
      for managing software dependencies securely.

By implementing a structured approach to regularly auditing and updating 
third-party libraries, organizations can reduce the risk of introducing 
vulnerabilities through external code, thereby enhancing the overall 
security of their applications.",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Hugo Ponthieu,,ATT&CK Enterprise - M1016 - Vulnerability Scanning||ATT&CK Enterprise - M1051 - Update Software,Application Security,NIST 800-53 v5,SI-2 Flaw Remediation
"*.beep,ovh",C-REGULAR-CONFIGURATION-REVIEWS-UPDATES-AND-SECURE-ERROR-HANDLING,"Regular Configuration Reviews, Updates, and Secure Error Handling","Maintaining security through regular configuration reviews, timely updates, 
and secure error handling is essential to defend against evolving security 
threats. This proactive approach helps ensure that system configurations 
remain robust against vulnerabilities and that errors do not expose 
sensitive information or lead to security breaches.

Steps to Implement Regular Configuration Reviews, Updates, and Secure Error 
Handling

Establish a Configuration Management Policy:

    * Develop and document a comprehensive policy that covers the
      management, review, and updating of system configurations. This
      policy should also address secure error handling practices.
    * Define standards for secure configurations based on industry best
      practices and compliance requirements.

Schedule Regular Configuration Reviews:

    * Set up a routine schedule to review and assess the security of system
      configurations. This might be monthly, quarterly, or in alignment
      with specific compliance or audit requirements.
    * Utilize automated tools where possible to assist in reviewing
      configurations against predefined security baselines or checklists
      (e.g., CIS Benchmarks, NIST guidelines).

Implement Configuration Change Control:

    * Establish a formal change management process for any modifications to
      system configurations. This process should include approval by
      designated personnel, rigorous testing, and documentation of changes.
    * Ensure that all changes are tracked in a change management system for
      accountability and auditing purposes.

Update Systems and Software Regularly:

    * Keep all systems, applications, and infrastructure components updated
      with the latest security patches and updates.
    * Automate the update process where feasible, ensuring that updates are
      applied promptly and consistently across all environments.

Implement Secure Error Handling:

    * Design and implement error-handling procedures that avoid disclosing
      sensitive information in error messages or logs. This includes
      generic error messages for end users and detailed logs for internal
      use that are protected and monitored.
    * Train developers on best practices for secure error handling,
      including how to properly log errors and avoid common security
      mistakes such as verbose error messages that could aid an attacker.

Monitor and Audit Configurations:

    * Use configuration monitoring tools to continuously monitor and detect
      unauthorized changes to configurations. Tools such as Tripwire or
      configuration modules in systems like Puppet, Chef, or Ansible can
      provide real-time alerts and remediation capabilities.
    * Conduct periodic audits to ensure compliance with the configuration
      management policy and to identify areas needing improvement.

Test Configuration Changes:

    * Before deploying any changes to production environments, thoroughly
      test them in a controlled staging environment to ensure they do not
      introduce new vulnerabilities or disrupt existing functionalities.
    * Implement automated testing scripts that can quickly verify the
      security and functionality of updated configurations.

Educate and Train Staff:

    * Provide ongoing training for all IT staff on configuration management
      practices, secure error handling, and the importance of maintaining
      security hygiene.
    * Encourage a culture of security awareness where staff feel
      responsible for the security of system configurations and are
      vigilant in identifying and reporting potential security issues.

Good Security Practices Reference

    * Follow guidelines from organizations like OWASP (Open Web Application
      Security Project) for secure configuration and error handling.
    * Refer to standards from ISO/IEC 27001 for information security
      management, which include requirements for regular reviews of
      security policies and technical compliance.

By adhering to these steps, organizations can ensure that their systems are 
configured securely, vulnerabilities are addressed promptly, and errors are 
handled in a manner that does not compromise security. This proactive 
approach significantly reduces the risk of security breaches and maintains 
the integrity and reliability of IT systems.",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Hugo Ponthieu,,ATT&CK Enterprise - M1022 - Restrict File and Directory Permissions||ATT&CK Enterprise - M1051 - Update Software,Application Security||Data Security,NIST 800-53 v5,CM-2 BASELINE CONFIGURATION||IR-4 Incident Handling||SI-11 Error Handling||SI-2 Flaw Remediation
Bare Metal Server,C-BARE-METAL-SERVER-CNT-03,Regular firmware updates and integrity checks,"Step 1: Assess the Current Firmware Management Practices

   1. Document all the current firmware versions installed on your bare
      metal servers.
   2. Identify the sources from which these firmware updates are received
      to ensure they are trusted.
   3. Evaluate any existing verification methods used to validate the
      authenticity of firmware updates.

Step 2: Establish a Firmware Update Schedule

   1. Research and identify the frequency of updates provided by the
      hardware vendor.
   2. Set up regular intervals (e.g., quarterly or semi-annual) for
      checking and applying updates.
   3. Incorporate emergency update procedures for critical patches or
      vulnerabilities.

Step 3: Verify the Source and Integrity of Firmware

   1. Ensure all updates are sourced directly from the manufacturer's
      official site or approved partners.
   2. Implement strong cryptographic methods like digital signatures to
      verify the integrity of downloaded firmware.
   3. Use checksums or hash-verification tools to double-check the
      integrity of the firmware files before applying updates.

Step 4: Implement Robust Integrity Verification Techniques

   1. Implement systems that automatically perform integrity checks during
      the boot process to alert any unauthorized firmware changes.
   2. Use Trusted Platform Module (TPM) chips or similar technologies to
      enhance firmware security and ensure verified boot.
   3. Deploy firmware protection tools that can alert or automatically
      revert to a known secure state in case of integrity compromise.

Step 5: Test and Monitor Firmware Updates

   1. Design a test environment to apply and verify updates before
      deployment to production servers.
   2. Ensure continuous monitoring for any anomalies or performance issues
      post-update.
   3. Maintain logs and analysis tools to track changes and revert updates
      if necessary.

Step 6: Educate and Train Personnel

   1. Organize regular training sessions to keep IT staff updated on best
      practices in firmware management and security.
   2. Develop clear documentation on the procedures for scheduling,
      applying, and verifying firmware updates.
   3. Allocate responsibilities and ensure that staff are competent in
      executing all aspects of this countermeasure.

References

    * NIST Cybersecurity Framework
      <https://www.nist.gov/cyberframework/framework>
    * Firmware Security: Key Challenges and 11 Critical Best Practices
      <https://sternumiot.com/iot-blog/firmware-security-key-challenges-and-11-critical-best-practices/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Hugo Ponthieu,,EMB3D - MID-026 - Secure Firmware Update,Hardware Security,NIST 800-53 v5,"SI-7 Software, Firmware, and Information Integrity"
Bare Metal Server,C-BARE-METAL-SERVER-CNT-03,Regular firmware updates and integrity checks,"Step 1: Assess the Current Firmware Management Practices

   1. Document all the current firmware versions installed on your bare
      metal servers.
   2. Identify the sources from which these firmware updates are received
      to ensure they are trusted.
   3. Evaluate any existing verification methods used to validate the
      authenticity of firmware updates.

Step 2: Establish a Firmware Update Schedule

   1. Research and identify the frequency of updates provided by the
      hardware vendor.
   2. Set up regular intervals (e.g., quarterly or semi-annual) for
      checking and applying updates.
   3. Incorporate emergency update procedures for critical patches or
      vulnerabilities.

Step 3: Verify the Source and Integrity of Firmware

   1. Ensure all updates are sourced directly from the manufacturer's
      official site or approved partners.
   2. Implement strong cryptographic methods like digital signatures to
      verify the integrity of downloaded firmware.
   3. Use checksums or hash-verification tools to double-check the
      integrity of the firmware files before applying updates.

Step 4: Implement Robust Integrity Verification Techniques

   1. Implement systems that automatically perform integrity checks during
      the boot process to alert any unauthorized firmware changes.
   2. Use Trusted Platform Module (TPM) chips or similar technologies to
      enhance firmware security and ensure verified boot.
   3. Deploy firmware protection tools that can alert or automatically
      revert to a known secure state in case of integrity compromise.

Step 5: Test and Monitor Firmware Updates

   1. Design a test environment to apply and verify updates before
      deployment to production servers.
   2. Ensure continuous monitoring for any anomalies or performance issues
      post-update.
   3. Maintain logs and analysis tools to track changes and revert updates
      if necessary.

Step 6: Educate and Train Personnel

   1. Organize regular training sessions to keep IT staff updated on best
      practices in firmware management and security.
   2. Develop clear documentation on the procedures for scheduling,
      applying, and verifying firmware updates.
   3. Allocate responsibilities and ensure that staff are competent in
      executing all aspects of this countermeasure.

References

    * NIST Cybersecurity Framework
      <https://www.nist.gov/cyberframework/framework>
    * Firmware Security: Key Challenges and 11 Critical Best Practices
      <https://sternumiot.com/iot-blog/firmware-security-key-challenges-and-11-critical-best-practices/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Hugo Ponthieu,,EMB3D - MID-026 - Secure Firmware Update,Hardware Security,NIST 800-53 v5,"SI-7 Software, Firmware, and Information Integrity"
Virtual Machine,C-VIRTUAL-MACHINE-CNT-06,Regularly apply patches and updates to both the operating system and applications on VMs,"To minimize security vulnerabilities, ensure that all virtual machines have 
up-to-date operating systems and applications. Regular patching prevents 
attackers from exploiting known weaknesses in outdated software.

Steps to Implement:

   1. Enable automatic updates for the operating system and critical
      applications whenever possible.
   2. Regularly check for and apply security patches from vendors,
      including OS and third-party applications.
   3. Use a centralized patch management system to automate and monitor
      updates across multiple VMs.
   4. Test patches in a staging environment before deployment to production
      to prevent compatibility issues.
   5. Schedule regular security audits to verify patch compliance and
      detect any unpatched systems.

References:

    * VMware Security Patching Guidelines
      <https://www.vmware.com/docs/patching-overview-including-critical-security-patches>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Hugo Ponthieu,,ATT&CK Enterprise - M1051 - Update Software,Operational Security,NIST 800-53 v5,"SI-7 Software, Firmware, and Information Integrity"
VPN (Virtual Private Network),C-VPN-VIRTUAL-PRIVATE-NETWORK-CNT-08,Regularly assess and update endpoint devices to maintain security posture,"Continuously evaluate the security posture of endpoint devices connected to 
the VPN and ensure they are up to date with the latest patches and updates. 
This practice reduces vulnerabilities and minimizes the risk of compromise 
that could jeopardize the VPN and broader network infrastructure.

Implement Endpoint Monitoring:

    * Deploy endpoint detection and response (EDR) solutions to monitor the
      security status of all connected devices.
    * Identify outdated software, missing patches, or misconfigured
      security settings.

Enforce Patch Management Policies:

    * Use automated patch management tools to deploy security updates to
      operating systems, VPN clients, and other critical software.
    * Prioritize high-severity patches and vulnerabilities for immediate
      remediation.

Establish Compliance Standards:

    * Define and enforce baseline security standards for all endpoints,
      including antivirus software, firewalls, and encryption.
    * Restrict VPN access for devices that do not meet these standards.

Conduct Regular Security Assessments:

    * Schedule routine vulnerability scans and configuration reviews for
      endpoint devices.
    * Validate endpoint security configurations using tools like CIS
      Benchmarks or other compliance frameworks.

Educate Users:

    * Train users on the importance of keeping their devices updated and
      secure.
    * Provide clear guidelines on recognizing and mitigating threats like
      phishing or malware.

Integrate with VPN Access Control:

    * Use network access control (NAC) systems to verify the security
      posture of endpoint devices before granting VPN access.
    * Block or quarantine non-compliant devices until issues are resolved.

By regularly assessing and maintaining the security of endpoint devices, 
developers and DevOps engineers can ensure that vulnerabilities are 
minimized, protecting the VPN and organizational network from potential 
threats.

References:

    * NIST Guidelines on Patch Management
      <https://csrc.nist.gov/publications/detail/sp/800-40/rev-3/final>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Hugo Ponthieu,,ATT&CK Enterprise - M1057 - Data Loss Prevention,Network Security,NIST 800-53 v5,CM-8 System Component Inventory
Virtual Machine,C-VIRTUAL-MACHINE-CNT-04,Regularly remove outdated snapshots and implement snapshot encryption,"To reduce security risks and prevent unauthorized data access, regularly 
delete outdated VM snapshots and encrypt active snapshots. Stale snapshots 
may contain sensitive data and introduce vulnerabilities if left 
unprotected.

Steps to Implement:

   1. Establish a policy for automatic deletion of outdated VM snapshots.
   2. Regularly audit and manually remove snapshots that are no longer
      needed.
   3. Enable encryption for snapshots to protect data at rest.
   4. Use role-based access control (RBAC) to restrict access to snapshot
      management.
   5. Monitor snapshot usage and storage to prevent unauthorized creation
      or access.

References:

    * VMware Snapshot Best Practices
      <https://kb.vmware.com/s/article/1025279>",Created by Rules Engine,Recommended,Not tested,Very high,N/A,Medium,Hugo Ponthieu,,ATT&CK Enterprise - M1051 - Update Software,Data Security,NIST 800-53 v5,SC-28 PROTECTION OF INFORMATION AT REST
PostgreSQL,C-POSTGRESQL-CNT-POSTGRES-05,Regularly update postgresql to the latest secure version,"Implement and regularly update PostgreSQL to the latest secure version to 
ensure that all known vulnerabilities are patched and that the database 
benefits from the latest security enhancements. This control minimizes the 
risk of exploitation by integrating an effective patch management process 
that monitors for new releases, tests updates in a controlled environment, 
and deploys them consistently across all systems. Developers and DevOps 
engineers should incorporate this practice into their routine maintenance 
processes, using automated tools where possible to ensure compliance with 
security best practices.

Implementation Steps:

Monitor for New Releases:
Subscribe to PostgreSQL security bulletins and regularly review release 
notes to stay informed about patches and updates.

Test Updates in Staging:
Validate new PostgreSQL versions in a controlled environment to ensure 
compatibility and stability with existing applications before production 
deployment.

Automate Deployment:
Use automated deployment tools or scripts to ensure that updates are 
applied consistently and promptly across all PostgreSQL instances.

Audit and Verify Compliance:
Regularly review version inventories and update logs to confirm that all 
systems are running the latest secure version of PostgreSQL.

References:

    * PostgreSQL Release Notes
      <https://www.postgresql.org/docs/current/release.html>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1051 - Update Software,Application Security,NIST 800-53 v5,SI-2 Flaw Remediation
Redis Server,C-REDIS-SERVER-CNT-REDIS-05,Regularly update Redis to the latest secure version,"Implement and regularly update Redis to the latest secure version to ensure 
that all vulnerabilities are promptly patched and that the system benefits 
from the latest security enhancements. This control minimizes the risk of 
exploitation from known flaws by integrating an effective patch management 
process. Developers and DevOps engineers should monitor for new releases, 
thoroughly test updates in a controlled environment, and deploy them 
systematically using automated tools to maintain a secure and resilient 
Redis deployment.

Implementation Steps:

Monitor for New Releases:
Subscribe to Redis security bulletins and follow release notes to stay 
informed about updates and patches.

Test Updates in Staging:
Validate new Redis versions in a testing environment to ensure 
compatibility and stability with your existing applications before 
production deployment.

Automate Deployment:
Use automated deployment tools or scripts to roll out updates consistently 
across all Redis instances.

Audit and Verify Compliance:
Regularly review version inventories and update logs to confirm that all 
instances are running the latest secure version of Redis.

References:

    * Redis Security Documentation
      <https://redis.io/docs/latest/operate/oss_and_stack/management/security/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1051 - Update Software,Application Security,NIST 800-53 v5,SI-2 Flaw Remediation
VPN (Virtual Private Network),C-VPN-VIRTUAL-PRIVATE-NETWORK-CNT-03,Require multifactor authentication for VPN access to enhance security,"Implement multifactor authentication (MFA) for VPN access to provide an 
additional layer of security beyond passwords. MFA significantly reduces 
the risk of unauthorized access by requiring users to verify their identity 
using two or more authentication factors, such as something they know 
(password), something they have (security token), or something they are 
(biometric).

Select an MFA Solution:

    * Choose an MFA provider compatible with your VPN solution, such as
      Duo, Okta, Microsoft Authenticator, or Google Authenticator.
    * Ensure the solution supports various factors, including push
      notifications, one-time passwords (OTPs), and biometric
      authentication.

Integrate MFA with VPN:

    * Configure your VPN server to require MFA during the authentication
      process.
    * Test the integration to verify seamless authentication without
      impacting user experience.

Enforce MFA for All Users:

    * Require all users, including administrators, to authenticate using
      MFA.
    * Disable single-factor authentication methods to prevent fallback to
      less secure options.

Educate Users:

    * Train users on how to set up and use the MFA solution.
    * Provide clear instructions on what to do if they lose access to their
      second factor (e.g., device loss).

Enable Conditional Access Policies:

    * Configure conditional access rules to enforce stricter authentication
      requirements for high-risk scenarios, such as logins from untrusted
      locations or devices.
    * Combine MFA with other security measures like IP whitelisting for
      added protection.

Monitor and Audit MFA Usage:

    * Log all authentication attempts and monitor for unusual patterns,
      such as repeated MFA failures or access from unfamiliar devices.
    * Periodically review MFA configurations to ensure they meet current
      security requirements.

By requiring multifactor authentication for VPN access, developers and 
DevOps engineers can significantly enhance the security of user 
authentication, mitigating the risks associated with password compromises.

References:

    * CISA Best Practices for MFA
      <https://www.cisa.gov/resources-tools/resources/multi-factor-authentication-mfa>",Created by Rules Engine,Recommended,Not tested,Very high,N/A,Medium,Hugo Ponthieu,,ATT&CK Enterprise - M1032 - Multi-factor Authentication,Network Security,NIST 800-53 v5,AC-17 Remote Access
DNS (Domain Name System),C-DNS-DOMAIN-NAME-SYSTEM-CNT-5,Restrict zone transfers and authenticate transfers with TSIG,"   1. Restrict Zone Transfers: Begin by configuring your DNS server to
      limit zone transfers only to known, trusted secondary servers.

          o Access your DNS server's configuration file. This is typically
            located in /etc/named.conf if you are using ISC BIND.
          o Within the DNS zone configuration block, specify the IP
            addresses of the secondary servers that are allowed to receive
            zone transfers. Use the allow-transfer directive as shown in
            the example below:

            zone ""example.com"" IN {
                type master;
                file ""named.example.com"";
                allow-transfer { 192.0.2.1; 192.0.2.2; };
            };

          o Save the configuration file and restart the DNS service for
            changes to take effect. On many systems, this can be done using
            the command: sudo systemctl restart named.
   2. Implement TSIG for Authentication: Transaction Signature (TSIG)
      ensures that DNS messages such as zone transfers are authenticated,
      protecting against unauthorized alterations and ensuring integrity.

          o Generate a secret key for TSIG using a tool like dnssec-keygen
            . For example:

            dnssec-keygen -a HMAC-SHA256 -b 256 -n HOST tsig-key.

          o This will create two files with extensions .private and .key.
            Open the .key file to retrieve the generated key string.
          o Edit the DNS server configuration file to include the TSIG key.
            Introduce the following directive, replacing YOUR_KEY_STRING 
            with your actual key:

            key ""tsig-key"" {
                algorithm hmac-sha256;
                secret ""YOUR_KEY_STRING"";
            };

          o In your DNS zone configuration, update the allow-transfer 
            directive to specify the TSIG key:

            zone ""example.com"" IN {
                type master;
                file ""named.example.com"";
                allow-transfer { key ""tsig-key""; 192.0.2.1; 192.0.2.2; };
            };

          o Configure all secondary DNS servers to validate the TSIG-signed
            transactions using the same key. This includes adding the key 
            directive with the shared secret key on each secondary server’s
            configuration.
          o Restart all DNS servers to apply the changes.
   3. Test and Monitor: After implementing these configurations, it’s
      crucial to test whether zone transfers are functioning securely and
      as expected.

          o Use tools like dig to test DNS queries and verify that zone
            transfers are only happening to authorized servers.
          o Regularly monitor DNS server logs for unauthorized attempts of
            zone transfers. Logs generally provide insights into any failed
            TSIG verification or unauthorized access attempts.

References

    * BIND 9 TSIG Key Generation
      <https://bind9.readthedocs.io/en/latest/reference.html#tsig-key-generation-and-authorization>",Created by Rules Engine,Recommended,Not tested,High,N/A,High,Hugo Ponthieu,,ATT&CK Enterprise - M1057 - Data Loss Prevention,Network Security,NIST 800-53 v5,SC-22 Architecture and Provisioning for Name/address Resolution Service
Web Framework,C-DEFAULTS,Review defaults and configuration files,"It is critical to thoroughly review and customize default settings and 
configuration files for all software components, including applications, 
operating systems, network devices, and any other IT assets. Defaults often 
prioritize convenience over security, potentially leading to 
vulnerabilities.

    * Start by identifying all components that come with default
      configuration files. This includes your web frameworks (e.g., Django,
      Express.js), databases, and any third-party services or libraries
      integrated into your application.
    * Examine the default configuration settings for each component. Pay
      special attention to network port configurations, default
      permissions, embedded cryptographic keys, tokens, or secrets, and any
      services that may be enabled by default.
    * Modify the default configurations to align with security best
      practices. Disable unnecessary services and ports, change default
      passwords and keys, and restrict user permissions to the minimum
      necessary for their role (principle of least privilege).
    * Use secure templates or guides when available. Many security
      organizations and communities provide configuration templates or
      guidelines designed to enhance security.
    * Implement version control for your configuration files. This allows
      you to track changes over time and audit configurations as needed.
    * Regularly review and update your configurations. As new threats
      emerge and software gets updated, periodically reassess your
      configurations to ensure they remain secure.
    * Automate configuration reviews and enforcement where possible. Use
      tools that can scan for misconfigurations and enforce security
      policies across your infrastructure.
    * Document all changes to default configurations. This documentation
      should include the rationale for changes, the impact on the system or
      application, and any necessary steps to revert the changes if issues
      arise.

By proactively reviewing and adjusting default configurations and 
maintaining vigilant oversight, developers can significantly reduce the 
risk of security vulnerabilities stemming from overlooked or misconfigured 
settings.",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1028 - Operating System Configuration||ATT&CK Enterprise - M1054 - Software Configuration||ATT&CK ICS - M0801 - Access Management,Application Security||Operational Security,NIST 800-53 v5,CM-6 Configuration Settings||CM-4 Impact Analyses||CM-8 System Component Inventory||CM-9 Configuration Management Plan||CM-3 Configuration Change Control||CM-11 User-installed Software||CM-7 Least Functionality||CM-1 Policy and Procedures||CM-10 Software Usage Restrictions||CM-5 Access Restrictions for Change||CM-12 Information Location||CM-14 Signed Components||CM-13 Data Action Mapping||CM-7 Least Functionality||CM-2 BASELINE CONFIGURATION
Web Framework,C-SAFEGUARD-SENSITIVE-INFORMATION,Safeguard sensitive information,"To ensure the security and confidentiality of sensitive information within 
your applications, adopt a comprehensive approach that includes data 
anonymization, encryption, and secure storage practices. Here are practical 
steps to protect sensitive data effectively:

    * Identify the sensitive information your application handles,
      including personally identifiable information (PII), financial
      details, health records, or any data that requires protection under
      regulations like GDPR. Understanding the type and location of
      sensitive data is crucial for implementing appropriate safeguards.
    * Anonymize or obfuscate sensitive data whenever possible. Techniques
      such as data masking or pseudonymization can protect user privacy and
      reduce risks if data breaches occur. Consider the context in which
      data is used to choose the most appropriate anonymization method.
    * Encrypt sensitive data both at rest and in transit. Utilize robust
      encryption standards and algorithms to ensure data confidentiality.
      For data at rest, consider file or disk encryption methods provided
      by your operating system or database. For data in transit, use
      protocols such as TLS to secure communications between your
      application and clients or services.
    * Implement secure logging and monitoring practices to track access to
      sensitive data. Ensure that logs do not contain sensitive information
      in plaintext and that access to logs is restricted. Use monitoring
      tools to detect and alert on unauthorized access attempts or
      suspicious activities involving sensitive data.
    * Strengthen network security to protect data as it moves within and
      outside your application environment. Configure firewalls to restrict
      traffic to only necessary ports and services, deploy intrusion
      detection and prevention systems (IDS/IPS) to monitor and block
      malicious activities, and segment networks to limit access to
      sensitive data.
    * Regularly review and update your data protection measures to adapt to
      new threats and comply with evolving data protection regulations.
      Stay informed about best practices and industry standards for data
      security and privacy.

By implementing these measures, developers can significantly enhance the 
protection of sensitive information in their applications, mitigating the 
risks of data breaches and regulatory non-compliance.",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1029 - Remote Data Storage||ATT&CK Enterprise - M1041 - Encrypt Sensitive Information||ATT&CK Enterprise - M1030 - Network Segmentation,Data Security,NIST 800-53 v5,SC-8 TRANSMISSION CONFIDENTIALITY AND INTEGRITY||AC-3 ACCESS ENFORCEMENT||AC-16 Security and Privacy Attributes||AC-6 LEAST PRIVILEGE||SC-13 Cryptographic Protection||AC-14 PERMITTED ACTIONS WITHOUT IDENTIFICATION OR AUTHENTICATION
React.js,C-REACT-JS-CNT-REACTJS-03,Sanitize user input on ReactJS,"To prevent injection attacks such as Cross-Site Scripting (XSS), it’s 
essential to sanitize all user input in your React.js application. This 
involves ensuring that any data provided by users (e.g., form fields, URLs, 
etc.) is properly filtered and escaped before being rendered or stored. Use 
libraries like DOMPurify or react-sanitized-html to sanitize HTML content 
and escape unsafe characters. Additionally, avoid using 
dangerouslySetInnerHTML unless absolutely necessary, and when it is used, 
ensure that the input is sanitized. Always validate and sanitize user 
inputs both on the client and server side to ensure that no malicious 
scripts are executed in the user's browser.

References

    * OWASP XSS Prevention Cheat Sheet
      <https://cheatsheetseries.owasp.org/cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1055 - Do Not Mitigate,Application Security,NIST 800-53 v5,SI-10 INFORMATION INPUT VALIDATION
RESTful Web Service,C-RESTFUL-WEB-SERVICE-CNT-08,Sanitize user inputs and escape output,"To protect your RESTful Web Service from malicious attacks, such as SQL 
injection and Cross-Site Scripting (XSS), sanitize all user inputs and 
escape all outputs. Input sanitization ensures that only valid data is 
processed by the application, while escaping output ensures that 
user-supplied data is safely displayed in a web browser or other output 
streams, preventing the execution of harmful code.

Implementation Steps:

   1. Sanitize User Inputs: Use input validation techniques to ensure that
      data received from users conforms to expected formats (e.g.,
      alphanumeric, date, email). Reject any input that doesn't meet these
      criteria or sanitize it before processing.
   2. Escape Output: Ensure that any data returned to users via web pages
      or API responses is properly escaped. For example, HTML characters
      should be escaped to prevent injected scripts from executing (e.g., <
      becomes &lt;).
   3. Use Parameterized Queries: For SQL queries, use parameterized queries
      or prepared statements to prevent SQL injection by ensuring that user
      input is treated as data and not executable code.
   4. Avoid Direct Insertion into Code: Never directly insert user inputs
      into web pages, scripts, or SQL queries. Always validate and sanitize
      them first.
   5. Utilize Existing Libraries: Leverage well-known, secure libraries or
      frameworks to handle input validation, output escaping, and
      sanitization, ensuring that your implementation follows best
      practices.

References:

    * OWASP XSS Prevention Cheat Sheet
      <https://cheatsheetseries.owasp.org/cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1038 - Execution Prevention,Application Security,NIST 800-53 v5,SI-10 INFORMATION INPUT VALIDATION
RESTful Web Service,C-RESTFUL-WEB-SERVICE-CNT-08,Sanitize user inputs and escape output,"To protect your RESTful Web Service from malicious attacks, such as SQL 
injection and Cross-Site Scripting (XSS), sanitize all user inputs and 
escape all outputs. Input sanitization ensures that only valid data is 
processed by the application, while escaping output ensures that 
user-supplied data is safely displayed in a web browser or other output 
streams, preventing the execution of harmful code.

Implementation Steps:

   1. Sanitize User Inputs: Use input validation techniques to ensure that
      data received from users conforms to expected formats (e.g.,
      alphanumeric, date, email). Reject any input that doesn't meet these
      criteria or sanitize it before processing.
   2. Escape Output: Ensure that any data returned to users via web pages
      or API responses is properly escaped. For example, HTML characters
      should be escaped to prevent injected scripts from executing (e.g., <
      becomes &lt;).
   3. Use Parameterized Queries: For SQL queries, use parameterized queries
      or prepared statements to prevent SQL injection by ensuring that user
      input is treated as data and not executable code.
   4. Avoid Direct Insertion into Code: Never directly insert user inputs
      into web pages, scripts, or SQL queries. Always validate and sanitize
      them first.
   5. Utilize Existing Libraries: Leverage well-known, secure libraries or
      frameworks to handle input validation, output escaping, and
      sanitization, ensuring that your implementation follows best
      practices.

References:

    * OWASP XSS Prevention Cheat Sheet
      <https://cheatsheetseries.owasp.org/cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Hugo Ponthieu,,ATT&CK Enterprise - M1038 - Execution Prevention,Application Security,NIST 800-53 v5,SI-10 INFORMATION INPUT VALIDATION
React.js,C-REACT-JS-CNT-REACTJS-04,Secure authentication using JSON web tokens (JWT) on ReactJS,"Implement secure authentication in your React.js application using JSON Web 
Tokens (JWT) to verify users and maintain session integrity. JWT is a 
compact, URL-safe method for representing claims to be transferred between 
two parties. To securely use JWT in React, ensure that the token is stored 
safely (e.g., in HTTP-only cookies or secure localStorage) and transmitted 
only over HTTPS. The token should be signed and include an expiration time 
to prevent unauthorized access in case the token is compromised. Use JWT 
for stateless authentication in React apps to reduce server-side session 
management complexity and enhance scalability.

References

    * Using JWT Authentication in React
      <https://levelup.gitconnected.com/jwt-authentication-in-react-a2b1b705b7a>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1018 - User Account Management,Application Security,NIST 800-53 v5,SC-23 SESSION AUTHENTICITY
API Gateway,C-API-GATEWAY-CNT-05,Securely channel all traffic information to a monitoring and/or analytics application,"Step 1: Define Monitoring Objectives

Begin by establishing clear objectives for what the continuous monitoring 
aims to achieve. Identify critical assets, potential threats, and the types 
of anomalies that need detection. Consider strategic goals such as 
improving detection speed, reducing false positives, and ensuring 
comprehensive coverage across all API endpoints.

Step 2: Select Monitoring Tools and Technologies

Evaluate and select appropriate tools and technologies for monitoring API 
traffic. Popular solutions include intrusion detection/prevention systems, 
security information and event management (SIEM) solutions, and anomaly 
detection tools. Ensure that selected solutions can integrate smoothly with 
the existing API gateway infrastructure.

Consider tools like AWS CloudWatch, Azure Monitor, or Splunk which are 
highly capable in monitoring and analyzing API traffic effectively.

Step 3: Implement Traffic Logging and Analysis

Enable comprehensive logging of API requests and responses. Configure logs 
to capture metadata such as timestamps, source IP addresses, request URLs, 
HTTP methods, and response codes. Logs should be structured in a consistent 
format to facilitate easy analysis. Utilize log management solutions to 
collect, aggregate, and store logs securely for further examination.

Step 4: Develop Automated Alerting and Response Procedures

Create automated alerts for detected anomalies or potential security 
incidents. Configure the monitoring system to trigger alerts based on 
predefined thresholds and patterns. Develop response playbooks that dictate 
actions to be taken upon receiving alerts, ensuring a swift and organized 
response to incidents.

Consider integrating automated responses that can temporarily block 
malicious IPs or throttle suspicious activity to limit potential damage.

Step 5: Conduct Regular Threat Intelligence Update

Regularly update the monitoring system with the latest threat intelligence 
data. This includes integrating real-time threat feeds that provide updates 
on new vulnerabilities, emerging attack vectors, and other pertinent threat 
information. Collaborate with threat intelligence providers to enhance 
detection capabilities and adapt quickly to changing threat landscapes.

Step 6: Perform Continuous Improvement and Testing

Regularly test and refine the monitoring and response system. Conduct 
simulated attacks and penetration testing to evaluate the effectiveness of 
the implemented measures. Gather feedback and analytics to identify areas 
for improvement. Continuous refinement ensures that the system remains 
robust against evolving threats.

Step 7: Ensure Compliance and Reporting

Ensure that all monitoring and incident response activities comply with 
relevant regulations and standards, such as GDPR, HIPAA, or PCI-DSS. 
Develop comprehensive reporting mechanisms to document incidents and 
responses, which are valuable for audits and improving security posture 
over time.

References

    * AWS CloudWatch Documentation <https://aws.amazon.com/cloudwatch/>
    * Azure Monitor Documentation
      <https://docs.microsoft.com/en-us/azure/azure-monitor/>",Created by Rules Engine,Recommended,Not tested,High,N/A,High,Hugo Ponthieu,,ATT&CK Enterprise - M1047 - Audit,Network Security,NIST 800-53 v5,SI-4 System Monitoring
DNS (Domain Name System),C-DNS-DOMAIN-NAME-SYSTEM-CNT-4,Secure resolver configurations and conduct regular audits,"To enhance the security of DNS resolvers and prevent unauthorized 
modifications, it is essential to securely configure DNS resolvers and 
establish a routine auditing process. Here is a step-by-step guide to 
achieving this:

   1. Secure DNS Resolver Configuration:
          o Access Control Lists (ACLs): Implement ACLs to restrict which
            IP addresses are allowed to query or make changes to the DNS
            server. Ensure that only trusted devices have access.
          o Disable Recursion: For authoritative DNS servers, disable
            recursion to prevent them from being used in DNS amplification
            attacks.
          o Rate Limiting: Set rate limits on DNS queries to mitigate the
            risk of denial-of-service attacks.
          o Enable DNSSEC: Ensure DNS Security Extensions (DNSSEC) are
            enabled to provide authenticity and integrity of DNS responses
            through digital signatures.
   2. Implement Secure Update Mechanisms:
          o Use TSIG: Employ Transaction Signatures (TSIG) for securely
            authenticating updates to DNS records between authorized
            clients and the DNS server.
          o Regularly Update Software: Keep your DNS resolver software
            up-to-date with the latest security patches to protect against
            vulnerabilities.
   3. Conduct Regular DNS Audits:
          o Schedule Regular Audits: Set up a schedule to perform periodic
            audits of DNS records and configurations, ensuring that they
            match organizational policies and are free from unauthorized
            changes.
          o Use DNS Monitoring Tools: Deploy DNS monitoring solutions that
            can alert administrators to rogue or unexpected DNS changes in
            real time.
   4. Review and Harden Configurations:
          o Configuration Management: Make use of version control and
            configuration management tools to track changes and manage DNS
            configurations securely.
          o Least Privilege Principle: Ensure that only administrators with
            specified roles and responsibilities can make changes to DNS
            records.

References

    * DNS Flag Day 2020 - Official Site <https://dnsflagday.net/>
    * RFC 2535 - Domain Name System Security Extensions
      <https://www.ietf.org/rfc/rfc2535.txt>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Hugo Ponthieu,,ATT&CK Enterprise - M1025 - Privileged Process Integrity,Network Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
Kubernetes Cluster,C-KUBERNETES-CLUSTER-CNT-02,Service account token authentication should not be used for users,"CIS Benchmark Recommendation id: 3.1.2
Profile Applicability: Level 1 - Master Node

Description: Kubernetes provides service account tokens which are intended 
for use by workloads running in the Kubernetes cluster, for authentication 
to the API server. These tokens are not designed for use by end-users and 
do not provide for features such as revocation or expiry, making them 
insecure. A newer version of the feature (Bound service account token 
volumes) does introduce expiry but still does not allow for specific 
revocation.

Rationale: With any authentication mechanism the ability to revoke 
credentials if they are compromised or no longer required, is a key 
control. Service account token authentication does not allow for this due 
to the use of JWT tokens as an underlying technology.

Impact: External mechanisms for authentication generally require additional 
software to be deployed.

Audit: Review user access to the cluster and ensure that users are not 
making use of service account token authentication.

Remediation: Alternative mechanisms provided by Kubernetes such as the use 
of OIDC should be implemented in place of service account tokens.

Default Value: Service account token authentication is enabled by default.

References:
N/A",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1018 - User Account Management,Application Security,NIST 800-53 v5,IA-5 AUTHENTICATOR MANAGEMENT
API Gateway,C-API-GATEWAY-CNT-03,The API gateway should have a connector to an artifact that can generate an access token for the client request,"To enhance the security of the API gateway, it's crucial to implement a 
robust token generation mechanism. This process will ensure that only 
authorized clients can access secure resources. Here's a step-by-step guide 
to implement token generation for API client verification:

    * Choose a Token Standard:

Determine the type of token that fits your security requirements. Common 
choices are JSON Web Tokens (JWT), OAuth tokens, or custom tokens. For most 
modern applications, JWT is preferred due to its compact size and ease of 
use across platforms.

    * Set Up a Secure Token Generation Service:

Implement or integrate a token generation service. This service should 
handle the creation, signing, and expiration of tokens. When using JWT, 
consider a library like JWT.io <https://jwt.io/libraries> for signing and 
verification across different programming languages.

    * Define Token Claims:

Decide on the necessary information (claims) the token should carry, such 
as issuer, subject, audience, and expiration. Ensure that these claims are 
minimal to protect against data leaks if a token is exposed.

    * Generate and Distribute Tokens:

Upon a successful authentication request, generate a token using your 
chosen library and send it securely to the client. Tokens should be sent 
via HTTPS to prevent interception.

    * Implement Token Validation:

At the API gateway, every incoming request should be checked for a valid 
token. Use your token service to validate its signature and claims. Reject 
requests with invalid or expired tokens.

    * Log and Monitor Token Activity:

Create logs for issuing, renewing, and rejecting tokens. Monitor these logs 
actively to detect any suspicious activities that could indicate an attempt 
to breach security.

    * Plan for Token Revocation:

Implement a mechanism to revoke tokens before their natural expiration if a 
security threat is detected or if a client logs out. Blacklist or 
short-lived token approaches can be beneficial.

Security Considerations:

    * Ensure your signing keys are securely stored, possibly using a
      hardware security module or a service like AWS KMS.
    * Use strong, commonly-accepted algorithms for signing tokens, such as
      RS256.
    * Regularly audit the token handling procedures for vulnerabilities.

References

    * OAuth 2.0 Authorization Framework <https://oauth.net/2/>
    * Introduction to JSON Web Tokens <https://jwt.io/introduction/>
    * Secure your Java APIs with JWT
      <https://developer.okta.com/blog/2018/10/31/jwts-with-java>
    * Learn About JSON Web Tokens
      <https://auth0.com/learn/json-web-tokens/>
    * RFC 7519: JSON Web Token (JWT) <https://tools.ietf.org/html/rfc7519>",Created by Rules Engine,Recommended,Not tested,High,N/A,High,Hugo Ponthieu,,ATT&CK Enterprise - M1027 - Password Policies,Application Security,NIST 800-53 v5,IA-9 Service Identification and Authentication
Kubernetes Cluster,C-KUBERNETES-CLUSTER-CNT-23,The default namespace should not be used,"CIS Benchmark Recommendation id: 5.7.4

Profile Applicability: Level 2 - Master Node

Description: Kubernetes provides a default namespace, where objects are 
placed if no namespace is specified for them. Placing objects in this 
namespace makes application of RBAC and other controls more difficult.

Rationale: Resources in a Kubernetes cluster should be segregated by 
namespace, to allow for security controls to be applied at that level and 
to make it easier to manage resources.

Impact: None

Audit: Run this command to list objects in default namespace
kubectl get $(kubectl api-resources --verbs=list --namespaced=true -o name 
| paste -sd, -) --ignore-not-found -n default
The only entries there should be system managed resources such as the 
Kubernetes service

Remediation: Ensure that namespaces are created to allow for appropriate 
segregation of Kubernetes resources and that all new resources are created 
in a specific namespace.

Default Value: Unless a namespace is specific on object creation, the 
default namespace will be used

References:
N/A",Created by Rules Engine,Recommended,Not tested,High,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1056 - Pre-compromise,Cloud Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
RESTful Web Service,C-RESTFUL-WEB-SERVICE-CNT-11,Use anti-CSRF tokens,"To prevent Cross-Site Request Forgery (CSRF) attacks in your RESTful Web 
Service, implement anti-CSRF tokens. These tokens ensure that requests made 
to the server are intentional and originated from a legitimate user. By 
requiring a unique token to be included with each sensitive request (such 
as form submissions or state-changing actions), you can prevent attackers 
from tricking authenticated users into performing unintended actions on the 
service.

Implementation Steps:

   1. Generate Unique Tokens: Generate a unique anti-CSRF token for each
      user session or for each state-changing request. Store the token
      securely on the server and associate it with the user’s session.
   2. Include Tokens in Requests: Include the anti-CSRF token in every form
      submission or sensitive request. The token should be sent in HTTP
      headers (preferably the X-CSRF-Token header) or as a hidden form
      field.
   3. Validate Tokens on the Server: For every incoming request that
      performs sensitive actions, validate the provided anti-CSRF token by
      comparing it with the one stored on the server for the user’s
      session.
   4. Expire Tokens After Use: Ensure that each token is used only once and
      is expired after a successful request to prevent reuse.
   5. Integrate with Session Management: Ensure that the anti-CSRF token is
      tied to the user’s session and invalidated when the session expires
      or when the user logs out.

References:

    * OWASP CSRF Prevention Cheat Sheet
      <https://cheatsheetseries.owasp.org/cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1057 - Data Loss Prevention,Application Security,NIST 800-53 v5,SI-10 INFORMATION INPUT VALIDATION
RESTful Web Service,C-RESTFUL-WEB-SERVICE-CNT-11,Use anti-CSRF tokens,"To prevent Cross-Site Request Forgery (CSRF) attacks in your RESTful Web 
Service, implement anti-CSRF tokens. These tokens ensure that requests made 
to the server are intentional and originated from a legitimate user. By 
requiring a unique token to be included with each sensitive request (such 
as form submissions or state-changing actions), you can prevent attackers 
from tricking authenticated users into performing unintended actions on the 
service.

Implementation Steps:

   1. Generate Unique Tokens: Generate a unique anti-CSRF token for each
      user session or for each state-changing request. Store the token
      securely on the server and associate it with the user’s session.
   2. Include Tokens in Requests: Include the anti-CSRF token in every form
      submission or sensitive request. The token should be sent in HTTP
      headers (preferably the X-CSRF-Token header) or as a hidden form
      field.
   3. Validate Tokens on the Server: For every incoming request that
      performs sensitive actions, validate the provided anti-CSRF token by
      comparing it with the one stored on the server for the user’s
      session.
   4. Expire Tokens After Use: Ensure that each token is used only once and
      is expired after a successful request to prevent reuse.
   5. Integrate with Session Management: Ensure that the anti-CSRF token is
      tied to the user’s session and invalidated when the session expires
      or when the user logs out.

References:

    * OWASP CSRF Prevention Cheat Sheet
      <https://cheatsheetseries.owasp.org/cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Hugo Ponthieu,,ATT&CK Enterprise - M1057 - Data Loss Prevention,Application Security,NIST 800-53 v5,SI-10 INFORMATION INPUT VALIDATION
Web Framework,C-CSRF,Use anti-CSRF tokens and built-in mechanisms,"To safeguard your application against Cross-Site Request Forgery (CSRF) 
attacks, implement anti-CSRF tokens along with the built-in security 
mechanisms provided by your development framework or libraries. Here are 
actionable steps to effectively mitigate CSRF risks:

    * Integrate anti-CSRF tokens into web forms and any request that could
      change the state on the server. Generate a unique, random token for
      each user session and embed it in HTML forms or AJAX requests. When
      the form is submitted or the request made, the server must check that
      the token matches the one associated with the user's session.
    * Ensure that all actions changing the state—such as posting data or
      updating user settings—include a validation of the anti-CSRF token.
      This step is crucial for forms, but also for AJAX calls and any other
      requests that might alter server data.
    * Use cryptographically secure methods to generate anti-CSRF tokens.
      This ensures that tokens are sufficiently random, making it
      practically impossible for attackers to predict or duplicate them.
    * Implement a policy for token expiration. Tokens should be refreshed
      at regular intervals and especially upon user authentication events
      to minimize the window during which an old token could be exploited.
    * Utilize the SameSite cookie attribute to add an extra layer of CSRF
      protection. Setting this attribute correctly can prevent the browser
      from sending cookies with cross-site requests initiated by
      third-party websites.
    * Consider verifying the HTTP Referer header as an additional check to
      ensure requests are coming from your site. While not foolproof due to
      potential manipulation, this check can add another hurdle for
      attackers attempting CSRF.
    * Take advantage of the CSRF protection features built into your
      development framework. Frameworks like Django and Express often
      provide easy-to-use mechanisms for generating and validating
      anti-CSRF tokens, along with other recommendations for secure
      application development.

By following these guidelines, developers can significantly reduce the risk 
of CSRF attacks, protecting both the application and its users from 
unauthorized actions performed by attackers.",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1021 - Restrict Web-Based Content,Application Security,NIST 800-53 v5,SI-10 INFORMATION INPUT VALIDATION||AC-12 SESSION TERMINATION||IA-2 Identification and Authentication (organizational Users)
AWS S3 (Simple Storage Service),C-AWS-S3-CNT-12,Use AWS CloudTrail,"AWS CloudTrail provides a record of actions taken by a user, a role, or an 
AWS service in Amazon S3. You can use information collected by CloudTrail 
to determine the following:

    * The request that was made to Amazon S3
    * The IP address from which the request was made
    * Who made the request
    * When the request was made
    * Additional details about the request

For example, you can identify CloudTrail entries for PUT actions that 
affect data access, in particular PutBucketAcl, PutObjectAcl, 
PutBucketPolicy, and PutBucketWebsite.

When you set up your AWS account, CloudTrail is enabled by default. You can 
view recent events in the CloudTrail console. To create an ongoing record 
of activity and events for your Amazon S3 buckets, you can create a trail 
in the CloudTrail console. For more information, see Logging data events
<https://docs.aws.amazon.com/awscloudtrail/latest/userguide/logging-data-events-with-cloudtrail.html> 
in the AWS CloudTrail User Guide.

When you create a trail, you can configure CloudTrail to log data events. 
Data events are records of resource operations performed on or within a 
resource. In Amazon S3, data events record object-level API activity for 
individual buckets. CloudTrail supports a subset of Amazon S3 object-level 
API operations, such as GetObject, DeleteObject, and PutObject. For more 
information about how CloudTrail works with Amazon S3, see Logging Amazon 
S3 API calls using AWS CloudTrail
<https://docs.aws.amazon.com/AmazonS3/latest/userguide/cloudtrail-logging.html> 
. In the Amazon S3 console, you can also configure your S3 buckets to 
Enabling CloudTrail event logging for S3 buckets and objects
<https://docs.aws.amazon.com/AmazonS3/latest/userguide/enable-cloudtrail-logging-for-s3.html> 
.

AWS Config provides a managed rule (cloudtrail-s3-dataevents-enabled) that 
you can use to confirm that at least one CloudTrail trail is logging data 
events for your S3 buckets. For more information, see 
cloudtrail-s3-dataevents-enabled
<https://docs.aws.amazon.com/config/latest/developerguide/cloudtrail-s3-dataevents-enabled.html> 
in the AWS Config Developer Guide.",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1047 - Audit,Cloud Security,NIST 800-53 v5,"AU-6 Audit Record Review, Analysis, and Reporting"
React.js,C-REACT-JS-CNT-REACTJS-01,Use HTTPS in ReactJS,"Ensure that all communication between your React.js application and its 
users is conducted over HTTPS (HyperText Transfer Protocol Secure). This 
ensures that data transmitted is encrypted, protecting sensitive 
information such as user credentials, payment details, and session tokens 
from interception by attackers. Set up SSL/TLS certificates for your web 
server and configure your React app to enforce HTTPS for all requests. 
Additionally, redirect all HTTP traffic to HTTPS to ensure secure 
communication across all endpoints. It is important to check that external 
resources, like APIs or third-party services, also support and enforce 
HTTPS.

References

    * React and HTTPS
      <https://create-react-app.dev/docs/using-https-in-development/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1041 - Encrypt Sensitive Information,Application Security,NIST 800-53 v5,SC-8 TRANSMISSION CONFIDENTIALITY AND INTEGRITY
RESTful Web Service,C-RESTFUL-WEB-SERVICE-CNT-03,Use HTTPS to encrypt API communication,"To ensure the confidentiality and integrity of data transmitted between 
clients and your RESTful Web Service, enforce HTTPS (Hypertext Transfer 
Protocol Secure) for all API communication. HTTPS uses SSL/TLS encryption 
to protect data in transit, preventing attackers from intercepting, 
tampering with, or eavesdropping on sensitive information such as 
authentication credentials or user data.

Implementation Steps:

   1. Configure SSL/TLS Certificates: Obtain and install a valid SSL/TLS
      certificate for your domain, ensuring the server is properly
      configured to support secure HTTPS communication.
   2. Force HTTPS: Redirect all HTTP traffic to HTTPS, ensuring that all
      requests to the API are encrypted. This can be done via HTTP Strict
      Transport Security (HSTS) headers.
   3. Use Strong Cipher Suites: Configure the server to support strong
      cryptographic algorithms and cipher suites for TLS, and disable weak
      or deprecated ones (e.g., SSL 2.0, RC4).
   4. Verify Certificate Validity: Regularly check that your SSL/TLS
      certificate is valid, not expired, and issued by a trusted
      Certificate Authority (CA).
   5. Enforce Secure Cookies: Ensure that cookies containing session data
      or authentication tokens are marked as Secure and HttpOnly,
      preventing them from being transmitted over non-secure channels.

References:

    * OWASP Transport Layer Protection Cheat Sheet
      <https://cheatsheetseries.owasp.org/cheatsheets/Transport_Layer_Protection_Cheat_Sheet.html>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1041 - Encrypt Sensitive Information,Application Security,NIST 800-53 v5,SC-8 TRANSMISSION CONFIDENTIALITY AND INTEGRITY
RESTful Web Service,C-RESTFUL-WEB-SERVICE-CNT-03,Use HTTPS to encrypt API communication,"To ensure the confidentiality and integrity of data transmitted between 
clients and your RESTful Web Service, enforce HTTPS (Hypertext Transfer 
Protocol Secure) for all API communication. HTTPS uses SSL/TLS encryption 
to protect data in transit, preventing attackers from intercepting, 
tampering with, or eavesdropping on sensitive information such as 
authentication credentials or user data.

Implementation Steps:

   1. Configure SSL/TLS Certificates: Obtain and install a valid SSL/TLS
      certificate for your domain, ensuring the server is properly
      configured to support secure HTTPS communication.
   2. Force HTTPS: Redirect all HTTP traffic to HTTPS, ensuring that all
      requests to the API are encrypted. This can be done via HTTP Strict
      Transport Security (HSTS) headers.
   3. Use Strong Cipher Suites: Configure the server to support strong
      cryptographic algorithms and cipher suites for TLS, and disable weak
      or deprecated ones (e.g., SSL 2.0, RC4).
   4. Verify Certificate Validity: Regularly check that your SSL/TLS
      certificate is valid, not expired, and issued by a trusted
      Certificate Authority (CA).
   5. Enforce Secure Cookies: Ensure that cookies containing session data
      or authentication tokens are marked as Secure and HttpOnly,
      preventing them from being transmitted over non-secure channels.

References:

    * OWASP Transport Layer Protection Cheat Sheet
      <https://cheatsheetseries.owasp.org/cheatsheets/Transport_Layer_Protection_Cheat_Sheet.html>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Hugo Ponthieu,,ATT&CK Enterprise - M1041 - Encrypt Sensitive Information,Application Security,NIST 800-53 v5,SC-8 TRANSMISSION CONFIDENTIALITY AND INTEGRITY
Virtual Machine,C-VIRTUAL-MACHINE-CNT-02,Use hypervisor security features to ensure proper isolation and segmentation of VMs,"To prevent lateral movement and unauthorized access between virtual 
machines, leverage built-in hypervisor security features to enforce 
isolation and segmentation. Proper VM isolation mitigates the risk of 
attackers exploiting vulnerabilities to compromise other VMs in the same 
environment.

Steps to Implement:

   1. Enable and configure VM segmentation using hypervisor security
      policies.
   2. Use virtual network segmentation (e.g., VLANs, micro-segmentation) to
      separate critical workloads.
   3. Restrict inter-VM communication unless explicitly required.
   4. Enable Secure Boot and hardware-assisted security features to protect
      VM integrity.
   5. Regularly audit VM and hypervisor configurations to identify
      misconfigurations or security gaps.

References:

    * VMware vSphere Security Guide
      <https://docs.vmware.com/en/VMware-vSphere/6.7/com.vmware.vsphere.security.doc/GUID-52188148-C579-4F6A-8335-CFBCE0DD2167.html>",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Hugo Ponthieu,,ATT&CK Enterprise - M1050 - Exploit Protection,Network Security,NIST 800-53 v5,SC-7 Boundary Protection
AWS S3 (Simple Storage Service),C-AWS-S3-CNT-04,Use IAM roles for applications and AWS services that require Amazon S3 access,"In order for applications running on Amazon EC2 or other AWS services to 
access Amazon S3 resources, they must include valid AWS credentials in 
their AWS API requests. We recommend not storing AWS credentials directly 
in the application or Amazon EC2 instance. These are long-term credentials 
that are not automatically rotated and could have a significant business 
impact if they are compromised.

Instead, use an IAM role to manage temporary credentials for applications 
or services that need to access Amazon S3. When you use a role, you don't 
have to distribute long-term credentials (such as a username and password 
or access keys) to an Amazon EC2 instance or AWS service, such as AWS 
Lambda. The role supplies temporary permissions that applications can use 
when they make calls to other AWS resources.

For more information, see the following topics in the IAM User Guide:

    * IAM Roles
      <https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles.html>
    * Common Scenarios for Roles: Users, Applications, and Services
      <https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_common-scenarios.html>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1035 - Limit Access to Resource Over Network,Cloud Security,NIST 800-53 v5,AC-6 LEAST PRIVILEGE
RESTful Web Service,C-RESTFUL-WEB-SERVICE-CNT-07,"Use input validation, signing, and hashing","To protect your RESTful Web Service from malicious input, data tampering, 
and unauthorized modifications, implement input validation, signing, and 
hashing techniques. Input validation ensures that only well-formed and 
expected data is processed, preventing injection attacks. Signing ensures 
the integrity of data by attaching a secure signature, while hashing 
protects sensitive data (e.g., passwords) by transforming it into 
irreversible values that can’t be read even if accessed.

Implementation Steps:

   1. Input Validation: Ensure all incoming data conforms to expected
      formats (e.g., alphanumeric, email, date), rejecting or sanitizing
      any input that doesn’t meet the required specifications to prevent
      injection attacks like SQL or XSS.
   2. Data Signing: Use cryptographic signing (e.g., HMAC, RSA) to ensure
      the integrity and authenticity of data sent between the client and
      server, preventing tampering or forgery of requests.
   3. Hashing Sensitive Data: Use strong cryptographic hash functions
      (e.g., SHA-256) to securely store sensitive information such as
      passwords or API keys. Ensure that salted hashes are used to mitigate
      rainbow table attacks.
   4. Regularly Update Validation and Hashing Algorithms: Stay current with
      the latest best practices in cryptography and data validation,
      regularly reviewing and updating the algorithms to guard against
      emerging vulnerabilities.
   5. Audit and Monitor: Regularly monitor and log any suspicious
      activities related to data input or authentication processes to
      detect potential attacks early.

References:

    * OWASP Input Validation Cheat Sheet
      <https://cheatsheetseries.owasp.org/cheatsheets/Input_Validation_Cheat_Sheet.html>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1038 - Execution Prevention,Application Security,NIST 800-53 v5,SI-10 INFORMATION INPUT VALIDATION
RESTful Web Service,C-RESTFUL-WEB-SERVICE-CNT-07,"Use input validation, signing, and hashing","To protect your RESTful Web Service from malicious input, data tampering, 
and unauthorized modifications, implement input validation, signing, and 
hashing techniques. Input validation ensures that only well-formed and 
expected data is processed, preventing injection attacks. Signing ensures 
the integrity of data by attaching a secure signature, while hashing 
protects sensitive data (e.g., passwords) by transforming it into 
irreversible values that can’t be read even if accessed.

Implementation Steps:

   1. Input Validation: Ensure all incoming data conforms to expected
      formats (e.g., alphanumeric, email, date), rejecting or sanitizing
      any input that doesn’t meet the required specifications to prevent
      injection attacks like SQL or XSS.
   2. Data Signing: Use cryptographic signing (e.g., HMAC, RSA) to ensure
      the integrity and authenticity of data sent between the client and
      server, preventing tampering or forgery of requests.
   3. Hashing Sensitive Data: Use strong cryptographic hash functions
      (e.g., SHA-256) to securely store sensitive information such as
      passwords or API keys. Ensure that salted hashes are used to mitigate
      rainbow table attacks.
   4. Regularly Update Validation and Hashing Algorithms: Stay current with
      the latest best practices in cryptography and data validation,
      regularly reviewing and updating the algorithms to guard against
      emerging vulnerabilities.
   5. Audit and Monitor: Regularly monitor and log any suspicious
      activities related to data input or authentication processes to
      detect potential attacks early.

References:

    * OWASP Input Validation Cheat Sheet
      <https://cheatsheetseries.owasp.org/cheatsheets/Input_Validation_Cheat_Sheet.html>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Hugo Ponthieu,,ATT&CK Enterprise - M1038 - Execution Prevention,Application Security,NIST 800-53 v5,SI-10 INFORMATION INPUT VALIDATION
RESTful Web Service,C-RESTFUL-WEB-SERVICE-CNT-02,Use parameterized queries and ORM frameworks,"To prevent SQL injection attacks and ensure secure database interactions, 
use parameterized queries and Object-Relational Mapping (ORM) frameworks. 
Parameterized queries ensure that user input is treated as data and not 
executable code, preventing attackers from injecting malicious SQL code. 
ORM frameworks abstract direct SQL execution and provide a secure, 
high-level interface for interacting with the database, reducing the 
likelihood of introducing vulnerabilities.

Implementation Steps:

   1. Use Parameterized Queries: Always use parameterized queries (or
      prepared statements) to bind user inputs to database queries. This
      ensures that inputs are treated as data and prevents SQL injection.
   2. Leverage ORM Frameworks: Use ORM frameworks (e.g., Hibernate, Entity
      Framework) to interact with the database, as they automatically
      handle query generation securely and reduce the risk of direct SQL
      injection vulnerabilities.
   3. Validate Inputs: Even when using parameterized queries or ORMs,
      always validate user input to ensure it conforms to expected formats
      and data types, further mitigating injection risks.
   4. Minimize Direct SQL Queries: Avoid using raw SQL queries or string
      concatenation when dealing with user input, opting instead for
      parameterized queries or ORM methods.
   5. Regularly Audit Database Access: Periodically review database access
      patterns and ensure that all interactions with the database follow
      secure practices, including using parameterized queries and ORM
      frameworks.

References:

    * OWASP SQL Injection Prevention Cheat Sheet
      <https://cheatsheetseries.owasp.org/cheatsheets/SQL_Injection_Prevention_Cheat_Sheet.html>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1038 - Execution Prevention,Data Security,NIST 800-53 v5,SI-10 INFORMATION INPUT VALIDATION
RESTful Web Service,C-RESTFUL-WEB-SERVICE-CNT-02,Use parameterized queries and ORM frameworks,"To prevent SQL injection attacks and ensure secure database interactions, 
use parameterized queries and Object-Relational Mapping (ORM) frameworks. 
Parameterized queries ensure that user input is treated as data and not 
executable code, preventing attackers from injecting malicious SQL code. 
ORM frameworks abstract direct SQL execution and provide a secure, 
high-level interface for interacting with the database, reducing the 
likelihood of introducing vulnerabilities.

Implementation Steps:

   1. Use Parameterized Queries: Always use parameterized queries (or
      prepared statements) to bind user inputs to database queries. This
      ensures that inputs are treated as data and prevents SQL injection.
   2. Leverage ORM Frameworks: Use ORM frameworks (e.g., Hibernate, Entity
      Framework) to interact with the database, as they automatically
      handle query generation securely and reduce the risk of direct SQL
      injection vulnerabilities.
   3. Validate Inputs: Even when using parameterized queries or ORMs,
      always validate user input to ensure it conforms to expected formats
      and data types, further mitigating injection risks.
   4. Minimize Direct SQL Queries: Avoid using raw SQL queries or string
      concatenation when dealing with user input, opting instead for
      parameterized queries or ORM methods.
   5. Regularly Audit Database Access: Periodically review database access
      patterns and ensure that all interactions with the database follow
      secure practices, including using parameterized queries and ORM
      frameworks.

References:

    * OWASP SQL Injection Prevention Cheat Sheet
      <https://cheatsheetseries.owasp.org/cheatsheets/SQL_Injection_Prevention_Cheat_Sheet.html>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,High,Hugo Ponthieu,,ATT&CK Enterprise - M1038 - Execution Prevention,Data Security,NIST 800-53 v5,SI-10 INFORMATION INPUT VALIDATION
PostgreSQL,C-POSTGRESQL-CNT-POSTGRES-02,Use parameterized queries and validate inputs,"Implement and regularly update secure coding practices for PostgreSQL by 
using parameterized queries and validating inputs to prevent injection 
attacks and ensure data integrity. This control ensures that all 
user-supplied data is properly sanitized and that SQL statements are 
constructed safely, reducing the risk of SQL injection and unauthorized 
data manipulation. Developers and DevOps engineers should integrate input 
validation and parameterized query techniques into their development 
workflows and conduct regular code reviews to maintain robust security 
practices.

Implementation Steps:

Adopt Parameterized Queries:
Ensure that all database queries are constructed using parameterized 
queries or prepared statements to separate query logic from data inputs, 
preventing injection of malicious SQL.

Validate and Sanitize Inputs:
Integrate input validation routines to check user-supplied data against 
expected formats and sanitize any potentially dangerous characters or 
patterns.

Integrate Secure Coding Practices:
Incorporate secure coding guidelines into the development process and use 
automated tools to scan for injection vulnerabilities and improper input 
handling.

Conduct Regular Code Reviews and Testing:
Perform periodic code reviews and security testing (e.g., penetration 
testing and static analysis) to verify that input validation and 
parameterization are consistently applied.

References:

    * OWASP SQL Injection Prevention Cheat Sheet
      <https://cheatsheetseries.owasp.org/cheatsheets/SQL_Injection_Prevention_Cheat_Sheet.html>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1035 - Limit Access to Resource Over Network,Application Security,NIST 800-53 v5,SI-10 INFORMATION INPUT VALIDATION
AWS S3 (Simple Storage Service),C-AWS-S3-CNT-15,Use S3 Storage Lens,"S3 Storage Lens is a cloud-storage analytics feature that you can use to 
gain organization-wide visibility into object-storage usage and activity. 
S3 Storage Lens also analyzes metrics to deliver contextual recommendations 
that you can use to optimize storage costs and apply best practices for 
protecting your data.

With S3 Storage Lens, you can use metrics to generate summary insights, 
such as finding out how much storage you have across your entire 
organization or which are the fastest-growing buckets and prefixes. You can 
also use S3 Storage Lens metrics to identify cost-optimization 
opportunities, implement data-protection and access-management best 
practices, and improve the performance of application workloads.

For example, you can identify buckets that don't have S3 Lifecycle rules to 
abort incomplete multipart uploads that are more than 7 days old. You can 
also identify buckets that aren't following data-protection best practices, 
such as using S3 Replication or S3 Versioning. For more information, see 
Understanding Amazon S3 Storage Lens
<https://docs.aws.amazon.com/AmazonS3/latest/userguide/storage_lens_basics_metrics_recommendations.html> 
.",Created by Rules Engine,Recommended,Not tested,High,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1047 - Audit,Cloud Security,NIST 800-53 v5,AU-3 Content of Audit Records
Backend,C-WEB-APPLICATION-SERVER-SIDE-CNT-07,Use secure data formats and strict whitelisting for deserialization,"To prevent deserialization vulnerabilities, ensure that your web 
application uses secure data formats, such as JSON, and applies strict 
whitelisting to limit the types of objects that can be deserialized. This 
minimizes the risk of malicious code execution or object manipulation 
during deserialization. By enforcing tight control over deserialized data 
and limiting the allowed object types, you reduce the attack surface and 
prevent attackers from injecting malicious objects that could compromise 
the server.

Implementation Steps:

   1. Use Secure Data Formats: Always prefer secure, text-based formats
      like JSON over binary formats to reduce the risk of deserialization
      attacks.
   2. Implement Whitelisting: Configure deserialization routines to only
      allow specific, trusted object types. Any unsupported object type
      should be rejected immediately.
   3. Sanitize Input: Apply rigorous validation and sanitization to all
      input before deserialization to ensure it does not contain harmful
      data.
   4. Monitor for Malicious Input: Continuously monitor incoming data for
      patterns indicating potential deserialization attacks, such as
      malformed objects.

References:

    * OWASP Deserialization Cheat Sheet
      <https://cheatsheetseries.owasp.org/cheatsheets/Deserialization_Cheat_Sheet.html>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1038 - Execution Prevention,Application Security,NIST 800-53 v5,SI-10 INFORMATION INPUT VALIDATION
Fronend,C-WEB-APPLICATION-SERVER-SIDE-CNT-07,Use secure data formats and strict whitelisting for deserialization,"To prevent deserialization vulnerabilities, ensure that your web 
application uses secure data formats, such as JSON, and applies strict 
whitelisting to limit the types of objects that can be deserialized. This 
minimizes the risk of malicious code execution or object manipulation 
during deserialization. By enforcing tight control over deserialized data 
and limiting the allowed object types, you reduce the attack surface and 
prevent attackers from injecting malicious objects that could compromise 
the server.

Implementation Steps:

   1. Use Secure Data Formats: Always prefer secure, text-based formats
      like JSON over binary formats to reduce the risk of deserialization
      attacks.
   2. Implement Whitelisting: Configure deserialization routines to only
      allow specific, trusted object types. Any unsupported object type
      should be rejected immediately.
   3. Sanitize Input: Apply rigorous validation and sanitization to all
      input before deserialization to ensure it does not contain harmful
      data.
   4. Monitor for Malicious Input: Continuously monitor incoming data for
      patterns indicating potential deserialization attacks, such as
      malformed objects.

References:

    * OWASP Deserialization Cheat Sheet
      <https://cheatsheetseries.owasp.org/cheatsheets/Deserialization_Cheat_Sheet.html>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1038 - Execution Prevention,Application Security,NIST 800-53 v5,SI-10 INFORMATION INPUT VALIDATION
Backend,C-WEB-APPLICATION-SERVER-SIDE-CNT-05,Use TLS for communications and protect stored data with encryption,"To secure data during transmission and at rest, ensure that all 
communications are protected using Transport Layer Security (TLS), and that 
stored data is encrypted using strong encryption algorithms. Additionally, 
implement robust key management practices to safeguard encryption keys and 
ensure that only authorized users and systems can access sensitive data.

Implementation Steps:

   1. Enforce TLS for All Communications: Configure all communication
      channels, including APIs, web traffic, and data transfers, to use TLS
      (preferably TLS 1.2 or higher) to protect data in transit.
   2. Encrypt Stored Data: Use strong encryption algorithms (e.g., AES-256)
      to encrypt sensitive data at rest, ensuring that unauthorized users
      cannot access or manipulate it.
   3. Implement Key Management Practices: Use a centralized key management
      system (KMS) to securely generate, store, and rotate encryption keys.
      Enforce access controls to ensure that only authorized systems can
      access encryption keys.
   4. Regularly Update and Rotate Keys: Set up automated key rotation
      policies to periodically update encryption keys and minimize the risk
      of key compromise.

References:

    * OWASP Transport Layer Security (TLS) Cheat Sheet
      <https://cheatsheetseries.owasp.org/cheatsheets/Transport_Layer_Security_Cheat_Sheet.html>",Created by Rules Engine,Recommended,Not tested,High,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1041 - Encrypt Sensitive Information,Data Security,NIST 800-53 v5,SC-8 TRANSMISSION CONFIDENTIALITY AND INTEGRITY
Fronend,C-WEB-APPLICATION-SERVER-SIDE-CNT-05,Use TLS for communications and protect stored data with encryption,"To secure data during transmission and at rest, ensure that all 
communications are protected using Transport Layer Security (TLS), and that 
stored data is encrypted using strong encryption algorithms. Additionally, 
implement robust key management practices to safeguard encryption keys and 
ensure that only authorized users and systems can access sensitive data.

Implementation Steps:

   1. Enforce TLS for All Communications: Configure all communication
      channels, including APIs, web traffic, and data transfers, to use TLS
      (preferably TLS 1.2 or higher) to protect data in transit.
   2. Encrypt Stored Data: Use strong encryption algorithms (e.g., AES-256)
      to encrypt sensitive data at rest, ensuring that unauthorized users
      cannot access or manipulate it.
   3. Implement Key Management Practices: Use a centralized key management
      system (KMS) to securely generate, store, and rotate encryption keys.
      Enforce access controls to ensure that only authorized systems can
      access encryption keys.
   4. Regularly Update and Rotate Keys: Set up automated key rotation
      policies to periodically update encryption keys and minimize the risk
      of key compromise.

References:

    * OWASP Transport Layer Security (TLS) Cheat Sheet
      <https://cheatsheetseries.owasp.org/cheatsheets/Transport_Layer_Security_Cheat_Sheet.html>",Created by Rules Engine,Recommended,Not tested,High,N/A,High,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1041 - Encrypt Sensitive Information,Data Security,NIST 800-53 v5,SC-8 TRANSMISSION CONFIDENTIALITY AND INTEGRITY
Web Framework,C-UPTODATE,Use up-to-date framework and well-tested routines and dependencies,"To enhance the security and reliability of your software applications, it 
is crucial to use the most recent versions of frameworks, libraries, and 
well-tested routines. The software landscape is continually evolving, with 
new vulnerabilities being discovered and exploited. Keeping your components 
updated is a proactive measure to mitigate security risks while benefiting 
from the latest features and improvements.

    * Regularly update and patch the frameworks, libraries, and
      dependencies your applications rely on. Subscribe to security
      advisories and release notes related to these components to stay
      informed about new updates and vulnerabilities. Apply security
      patches promptly to address known vulnerabilities.
    * Leverage automated tools and services designed to scan dependencies
      for vulnerabilities regularly. These tools can help identify outdated
      components or known security flaws that need attention.
    * Follow recommended versioning practices for frameworks and libraries
      to ensure compatibility and stability of your application while
      incorporating the latest security patches and features.
    * Select frameworks and libraries that prioritize security. Research
      and choose components that are widely recognized for their strong
      security measures and active maintenance.
    * Incorporate automated testing into your development process.
      Automated tests help verify that updates to frameworks, libraries,
      and your own code do not introduce new security vulnerabilities or
      regressions.
    * Prepare fallback and rollback plans for updates. Document and test
      these strategies to quickly revert changes if an update causes
      unforeseen issues or conflicts within your application.
    * Implement continuous monitoring solutions to detect and respond to
      abnormal behavior or security incidents that may arise from
      vulnerabilities in frameworks or dependencies. This ongoing vigilance
      helps ensure that potential security threats are identified and
      addressed promptly.

By adhering to these practices, developers can significantly reduce the 
risk of security vulnerabilities in their applications and maintain a high 
standard of software quality and reliability.",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1051 - Update Software||ATT&CK Enterprise - M1047 - Audit,Application Security,NIST 800-53 v5,SA-10 Developer Configuration Management||SA-11 Developer Testing and Evaluation
React.js,C-REACT-JS-CNT-REACTJS-02,Use virtual document object model (DOM) on ReactJS,"Leverage React's Virtual DOM to enhance performance and security in your 
application. The Virtual DOM is an abstraction that minimizes direct 
interaction with the actual DOM, which helps reduce potential attack 
vectors and increases rendering efficiency. By using the Virtual DOM, React 
ensures that updates to the UI are done in a controlled manner, reducing 
the chances of malicious DOM manipulations. This method also protects 
against potential Cross-Site Scripting (XSS) attacks that exploit direct 
DOM access. Ensure that your React components are optimized to use the 
Virtual DOM to safely manage state changes, without directly manipulating 
the actual DOM, and always validate user inputs before rendering.

References

    * Understanding Virtual DOM in React
      <https://adhithiravi.medium.com/react-virtual-dom-explained-in-simple-english-fc2d0b277bc5>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1057 - Data Loss Prevention,Application Security,NIST 800-53 v5,CM-10 Software Usage Restrictions
Web Framework,C-VALIDATE-INPUTS,Validate all user inputs including using built-in mechanisms,"Ensuring the integrity and safety of your application requires thorough 
verification and sanitization of all user-provided data before it is 
processed. Utilize both built-in validation mechanisms of your development 
frameworks and trusted libraries to effectively validate user inputs. 
Follow these steps to implement robust input validation:

    * Check that each piece of input data conforms to the expected data
      type. For example, verify that numeric inputs are integers or floats
      as appropriate, strings contain text, and date inputs correspond to
      actual dates.
    * Enforce input length restrictions to prevent excessively large data
      from being processed, which could lead to performance issues or
      buffer overflow vulnerabilities.
    * Use specific format validation for data types that follow a
      particular structure, such as email addresses, phone numbers, and
      dates. Ensure that these inputs precisely match the required format.
    * Adopt a whitelist approach for validating input, where only inputs
      matching known safe patterns are accepted. This is especially useful
      for fields that accept a limited range of values.
    * Restrict or safely handle special characters, particularly in
      contexts where they may be interpreted as executable or control
      characters in commands, SQL queries, or HTML content.
    * Employ regular expressions to validate complex input patterns
      efficiently. Regular expressions can be powerful tools for matching
      inputs to specific format requirements.
    * Design error messages to be clear and helpful without revealing
      sensitive information about the application's internal workings or
      data validation processes.
    * Sanitize inputs by stripping out or encoding potentially malicious
      characters. This is crucial for preventing injection attacks and
      other forms of input-based vulnerabilities.

By diligently validating and sanitizing user inputs, you safeguard your 
application against a wide array of common security threats, including 
injection attacks and data corruption. Leveraging the validation features 
provided by your development framework can simplify this process and 
enhance security.",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Low,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1047 - Audit||ATT&CK ICS - M0818 - Validate Program Inputs,Application Security||Data Security,NIST 800-53 v5,SI-10 INFORMATION INPUT VALIDATION||SA-10 Developer Configuration Management
Kubernetes worker node (kubernetes-components),C-KUBERNETES-WORKER-NODE-CNT-14,Verify that the --read-only-port argument is set to 0,"CIS Benchmark Recommendation id: 4.2.4

Profile Applicability: Level 1 - Worker Node

Description: Disable the read-only port.

Rationale: The Kubelet process provides a read-only API in addition to the 
main Kubelet API. Unauthenticated access is provided to this read-only API 
which could possibly retrieve potentially sensitive information about the 
cluster.

Impact: Removal of the read-only port will require that any service which 
made use of it will need to be re-configured to use the main Kubelet API.

Audit: Run the following command on each node: 
ps -ef | grep kubelet

Verify that the --read-only-port argument exists and is set to 0. If the 
--read-only-port argument is not present, check that there is a Kubelet 
config file specified by --config. Check that if there is a readOnlyPort 
entry in the file, it is set to 0.

Remediation: If using a Kubelet config file, edit the file to set 
readOnlyPort to 0. If using command line arguments, edit the kubelet 
service file /etc/kubernetes/kubelet.conf on each worker node and set the 
below parameter in KUBELET_SYSTEM_PODS_ARGS variable. 
--read-only-port=0

Based on your system, restart the kubelet service. For example: 
systemctl daemon-reload 
systemctl restart kubelet.service

Default Value: By default, --read-only-port is set to 10255/TCP. However, 
if a config file is specified by --config the default value for 
readOnlyPort is 0.

References:

   1. <https://kubernetes.io/docs/admin/kubelet/>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1035 - Limit Access to Resource Over Network,Network Security,NIST 800-53 v5,SC-7 Boundary Protection
Kubernetes worker node (kubernetes-components),C-KUBERNETES-WORKER-NODE-CNT-21,Verify that the RotateKubeletServerCertificate argument is set to true,"CIS Benchmark Recommendation id: 4.2.11
Profile Applicability: Level 1 - Worker Node
Description:Enable kubelet server certificate rotation.
Rationale: RotateKubeletServerCertificate causes the kubelet to both 
request a serving certificate after bootstrapping its client credentials 
and rotate the certificate as its existing credentials expire. This 
automated periodic rotation ensures that there are no downtimes due to 
expired certificates and thus addressing availability in the CIA security 
triad. Note: This recommendation only applies if you let kubelets get their 
certificates from the API server. In case your kubelet certificates come 
from an outside authority/tool (e.g. Vault) then you need to take care of 
rotation yourself.
Impact: None
Audit: Ignore this check if serverTLSBootstrap is true in the kubelet 
config file or if the --rotateserver-certificates parameter is set on 
kubelet Run the following command on each node: 

ps -ef | grep kubelet
Verify that RotateKubeletServerCertificate argument exists and is set to 
true.
Remediation: Edit the kubelet service file /etc/kubernetes/kubelet.conf on 
each worker node and set the below parameter in KUBELET_CERTIFICATE_ARGS 
variable. --feature-gates=RotateKubeletServerCertificate=true
Based on your system, restart the kubelet service. For example: 

systemctl daemon-reload
systemctl restart kubelet.service
Default Value: By default, kubelet server certificate rotation is enabled.
References:

   1. <https://github.com/kubernetes/kubernetes/pull/45059>
   2. 
      <https://kubernetes.io/docs/admin/kubelet-tls-bootstrapping/#kubelet-configuration>",Created by Rules Engine,Recommended,Not tested,Medium,N/A,Medium,Thééééééééo Tchilinguirianriaunriuanrn,,ATT&CK Enterprise - M1041 - Encrypt Sensitive Information,Application Security,NIST 800-53 v5,SC-13 Cryptographic Protection